{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30507fc9",
   "metadata": {},
   "source": [
    "# Langkah 1 : Lakukan cloning dari baseline acuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e4e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DIALKI'...\n",
      "remote: Enumerating objects: 89, done.\u001b[K\n",
      "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
      "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
      "remote: Total 89 (delta 32), reused 69 (delta 21), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (89/89), 56.14 KiB | 1.94 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ellenmellon/DIALKI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887de1e",
   "metadata": {},
   "source": [
    "# Langkah 2 : Buat enviroment dan aktivasi environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48a49eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'DIALKI'\n",
      "/workspace/dialki/DIALKI\n"
     ]
    }
   ],
   "source": [
    "cd DIALKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33985740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dialki/DIALKI\n"
     ]
    }
   ],
   "source": [
    "cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb25487",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9539dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /opt/conda\n",
      "dialki                   /opt/conda/envs/dialki\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d23b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate dialki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40836774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipykernel\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.5.1~ --> anaconda::ca-certificates-2022.4.26-h06a4308_0\n",
      "  certifi            conda-forge::certifi-2022.5.18.1-py38~ --> anaconda::certifi-2021.10.8-py38h06a4308_2\n",
      "  conda              conda-forge::conda-4.12.0-py38h578d9b~ --> anaconda::conda-4.12.0-py38h06a4308_0\n",
      "  openssl            conda-forge::openssl-1.1.1o-h166bdaf_0 --> anaconda::openssl-1.1.1n-h7f8727e_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fea0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ipykernel install --user --name=dialki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ee26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find kernel spec(s): dialki\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec uninstall -y dialki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2967cd",
   "metadata": {},
   "source": [
    "# Langkah 3 : Install Library APEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eec50b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'apex' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fd5e4",
   "metadata": {},
   "source": [
    "Pertama-tama install cuda toolkit yang sesuai dengan nvcc. Nvcc sistem menggunakan cuda 11.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5366be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Wed_Jul_14_19:41:19_PDT_2021\r\n",
      "Cuda compilation tools, release 11.4, V11.4.100\r\n",
      "Build cuda_11.4.r11.4/compiler.30188945_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ketika dilakukan install cudatoolkit 10.2, library apex masih tidak bisa diinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdb6997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/linux-64::conda-build==3.21.4=py38h578d9bd_0\n",
      "  - conda-forge/noarch::click==7.1.2=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::spacy==3.1.1=py38hfc89cab_0\n",
      "  - conda-forge/linux-64::pyyaml==5.4.1=py38h497a2fe_0\n",
      "  - conda-forge/noarch::backports==1.0=py_2\n",
      "  - conda-forge/noarch::six==1.16.0=pyh6c4a22f_0\n",
      "  - conda-forge/linux-64::scipy==1.6.3=py38h7b17777_0\n",
      "  - conda-forge/noarch::colorama==0.4.4=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::cffi==1.14.6=py38ha65f79e_0\n",
      "  - conda-forge/linux-64::numpy==1.21.2=py38he2449b9_0\n",
      "  - conda-forge/noarch::wcwidth==0.2.5=pyh9f0ad1d_2\n",
      "  - conda-forge/noarch::ipython_genutils==0.2.0=py_1\n",
      "  - conda-forge/noarch::dataclasses==0.8=pyhc8e2a94_3\n",
      "  - conda-forge/noarch::pexpect==4.8.0=pyh9f0ad1d_2\n",
      "  - conda-forge/noarch::pickleshare==0.7.5=py_1003\n",
      "  - conda-forge/noarch::backcall==0.2.0=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::python==3.8.10=h49503c6_1_cpython\n",
      "  - conda-forge/linux-64::ipython==7.26.0=py38he5a9106_0\n",
      "  - conda-forge/noarch::backports.functools_lru_cache==1.6.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::cmake==3.21.1=h8897547_0\n",
      "  - conda-forge/noarch::typer==0.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::python_abi==3.8=2_cp38\n",
      "  - conda-forge/noarch::glob2==0.7=py_0\n",
      "  - conda-forge/linux-64::mock==4.0.3=py38h578d9bd_1\n",
      "  - conda-forge/noarch::shellingham==1.4.0=pyh44b312d_0\n",
      "  - conda-forge/linux-64::llvmlite==0.35.0=py38h4630a5e_1\n",
      "  - conda-forge/linux-64::numba==0.52.0=py38h51da96c_0\n",
      "  - conda-forge/noarch::ptyprocess==0.7.0=pyhd3deb0d_0\n",
      "  - anaconda/linux-64::ipykernel==6.4.1=py38h06a4308_1\n",
      "  - conda-forge/linux-64::debugpy==1.6.0=py38hfa26641_0\n",
      "  - conda-forge/linux-64::chardet==4.0.0=py38h578d9bd_3\n",
      "  - conda-forge/noarch::pygments==2.12.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::matplotlib-inline==0.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::wasabi==0.9.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flit-core==3.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::python-libarchive-c==4.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::wheel==0.37.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pathy==0.6.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pycparser==2.21=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyzmq==23.0.0=py38hfc09fa9_0\n",
      "  - conda-forge/noarch::pandocfilters==1.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.27.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytz==2022.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::traitlets==5.2.1.post0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::tinycss2==1.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pydantic==1.8.2=py38h497a2fe_2\n",
      "  - conda-forge/noarch::pkginfo==1.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pysocks==1.7.1=py38h578d9bd_5\n",
      "  - conda-forge/noarch::send2trash==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::cython-blis==0.7.7=py38h71d37f0_1\n",
      "  - conda-forge/noarch::typing-extensions==4.2.0=hd8ed1ab_1\n",
      "  - conda-forge/noarch::attrs==21.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::murmurhash==1.0.7=py38hfa26641_0\n",
      "  - conda-forge/noarch::python-fastjsonschema==2.15.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::thinc==8.0.15=py38h514daf8_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.6.0=py38h578d9bd_0\n",
      "  - anaconda/linux-64::nest-asyncio==1.5.5=py38h06a4308_0\n",
      "  - conda-forge/noarch::idna==3.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipywidgets==7.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbformat==5.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::psutil==5.9.1=py38h0a891b7_0\n",
      "  - conda-forge/linux-64::cryptography==37.0.2=py38h2b5fc30_0\n",
      "  - conda-forge/noarch::webencodings==0.5.1=py_1\n",
      "  - conda-forge/noarch::jupyterlab_widgets==1.1.0=pyhd8ed1ab_0\n",
      "  - anaconda/noarch::python-dateutil==2.8.2=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::bleach==5.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::catalogue==2.0.6=py38h578d9bd_2\n",
      "  - conda-forge/noarch::typing_extensions==4.2.0=pyha770c72_1\n",
      "  - conda-forge/linux-64::cymem==2.0.6=py38hfa26641_3\n",
      "  - conda-forge/linux-64::markupsafe==2.1.1=py38h0a891b7_1\n",
      "  - conda-forge/linux-64::tornado==6.1=py38h0a891b7_3\n",
      "  - conda-forge/noarch::jupyter_client==7.3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::brotlipy==0.7.0=py38h0a891b7_1004\n",
      "  - conda-forge/noarch::pip==22.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prompt-toolkit==3.0.29=pyha770c72_0\n",
      "  - conda-forge/noarch::parso==0.8.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::defusedxml==0.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::soupsieve==2.3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::setuptools==62.3.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::jupyterlab_pygments==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::preshed==3.0.6=py38hfa26641_2\n",
      "  - conda-forge/noarch::decorator==5.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.6.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jedi==0.18.1=py38h578d9bd_1\n",
      "  - anaconda/linux-64::entrypoints==0.4=py38h06a4308_0\n",
      "  - conda-forge/linux-64::mistune==0.8.4=py38h497a2fe_1005\n",
      "  - conda-forge/linux-64::certifi==2022.5.18.1=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pyparsing==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::terminado==0.15.0=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::jupyter_core==4.10.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::nbconvert==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::zipp==3.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::ruamel_yaml==0.15.80=py38h0a891b7_1007\n",
      "  - conda-forge/noarch::spacy-legacy==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::srsly==2.4.3=py38hfa26641_1\n",
      "  - conda-forge/linux-64::argon2-cffi-bindings==21.2.0=py38h0a891b7_2\n",
      "  - conda-forge/noarch::notebook==6.4.11=pyha770c72_0\n",
      "  - conda-forge/linux-64::pyrsistent==0.18.1=py38h0a891b7_1\n",
      "  - conda-forge/noarch::beautifulsoup4==4.11.1=pyha770c72_0\n",
      "  - conda-forge/noarch::urllib3==1.26.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jsonschema==4.5.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.12.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::packaging==21.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::importlib-metadata==4.11.4=py38h578d9bd_0\n",
      "  - conda-forge/noarch::importlib_resources==5.7.1=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::pycosat==0.6.3=py38h0a891b7_1010\n",
      "  - conda-forge/noarch::jinja2==3.1.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::py-lief==0.11.5=py38h709712a_1\n",
      "  - conda-forge/noarch::pyopenssl==22.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::filelock==3.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prometheus_client==0.14.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.8.1=py38h0a891b7_1\n",
      "  - conda-forge/noarch::charset-normalizer==2.0.12=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::tqdm==4.64.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::smart_open==5.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::argon2-cffi==21.3.0=pyhd8ed1ab_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=10.2\n",
      "    - pytorch==1.10.1\n",
      "    - torchaudio==0.10.1\n",
      "    - torchvision==0.11.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cudatoolkit-10.2.89        |      h713d32c_10       449.7 MB  conda-forge\n",
      "    giflib-5.2.1               |       h36c2ea0_2          77 KB  conda-forge\n",
      "    lerc-3.0                   |       h9c3ff4c_0         216 KB  conda-forge\n",
      "    libdeflate-1.10            |       h7f98852_0          77 KB  conda-forge\n",
      "    libtiff-4.4.0              |       h0fcbabc_0         606 KB  conda-forge\n",
      "    libwebp-1.2.2              |       h3452ae3_0          85 KB  conda-forge\n",
      "    libxcb-1.13                |    h7f98852_1004         391 KB  conda-forge\n",
      "    pillow-9.1.1               |   py38h0ee0e06_1        44.8 MB  conda-forge\n",
      "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
      "    pytorch-1.10.1             |py3.8_cuda10.2_cudnn7.6.5_0       768.4 MB  pytorch\n",
      "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
      "    torchaudio-0.10.1          |       py38_cu102         4.5 MB  pytorch\n",
      "    torchvision-0.11.2         |       py38_cu102        30.1 MB  pytorch\n",
      "    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n",
      "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.27 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               conda-forge/linux-64::blas-1.0-mkl\n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.2.89-h713d32c_10\n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0\n",
      "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
      "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2\n",
      "  gmp                conda-forge/linux-64::gmp-6.2.1-h58526e2_0\n",
      "  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1\n",
      "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_1\n",
      "  lame               conda-forge/linux-64::lame-3.100-h7f98852_1001\n",
      "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
      "  lerc               conda-forge/linux-64::lerc-3.0-h9c3ff4c_0\n",
      "  libdeflate         conda-forge/linux-64::libdeflate-1.10-h7f98852_0\n",
      "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
      "  libtiff            conda-forge/linux-64::libtiff-4.4.0-h0fcbabc_0\n",
      "  libwebp            conda-forge/linux-64::libwebp-1.2.2-h3452ae3_0\n",
      "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.2-h7f98852_1\n",
      "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004\n",
      "  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0\n",
      "  openh264           conda-forge/linux-64::openh264-2.1.1-h780b84a_0\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
      "  pillow             conda-forge/linux-64::pillow-9.1.1-py38h0ee0e06_1\n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
      "  pytorch            pytorch/linux-64::pytorch-1.10.1-py3.8_cuda10.2_cudnn7.6.5_0\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda\n",
      "  torchaudio         pytorch/linux-64::torchaudio-0.10.1-py38_cu102\n",
      "  torchvision        pytorch/linux-64::torchvision-0.11.2-py38_cu102\n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  libblas                         3.9.0-11_linux64_openblas --> 3.8.0-14_mkl\n",
      "  libcblas                        3.9.0-11_linux64_openblas --> 3.8.0-14_mkl\n",
      "  liblapack                       3.9.0-11_linux64_openblas --> 3.8.0-14_mkl\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libwebp-1.2.2        | 85 KB     | ##################################### | 100% \n",
      "libxcb-1.13          | 391 KB    | ##################################### | 100% \n",
      "libdeflate-1.10      | 77 KB     | ##################################### | 100% \n",
      "xorg-libxau-1.0.9    | 13 KB     | ##################################### | 100% \n",
      "xorg-libxdmcp-1.1.3  | 19 KB     | ##################################### | 100% \n",
      "pillow-9.1.1         | 44.8 MB   | ##################################### | 100% \n",
      "pthread-stubs-0.4    | 5 KB      | ##################################### | 100% \n",
      "torchaudio-0.10.1    | 4.5 MB    | ##################################### | 100% \n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \n",
      "giflib-5.2.1         | 77 KB     | ##################################### | 100% \n",
      "cudatoolkit-10.2.89  | 449.7 MB  | ##################################### | 100% \n",
      "lerc-3.0             | 216 KB    | ##################################### | 100% \n",
      "torchvision-0.11.2   | 30.1 MB   | ##################################### | 100% \n",
      "libtiff-4.4.0        | 606 KB    | ##################################### | 100% \n",
      "pytorch-1.10.1       | 768.4 MB  | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4333c0",
   "metadata": {},
   "source": [
    "Dilakukan unistall ulang terhadap torch dan apex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ecd8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 1.10.1\n",
      "Uninstalling torch-1.10.1:\n",
      "  Successfully uninstalled torch-1.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f2d47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are missing from the target environment:\n",
      "  - apex\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda uninstall apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfbe47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/linux-64::conda-build==3.21.4=py38h578d9bd_0\n",
      "  - conda-forge/noarch::click==7.1.2=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::spacy==3.1.1=py38hfc89cab_0\n",
      "  - conda-forge/linux-64::pyyaml==5.4.1=py38h497a2fe_0\n",
      "  - conda-forge/noarch::backports==1.0=py_2\n",
      "  - conda-forge/noarch::six==1.16.0=pyh6c4a22f_0\n",
      "  - conda-forge/linux-64::scipy==1.6.3=py38h7b17777_0\n",
      "  - conda-forge/noarch::colorama==0.4.4=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::cffi==1.14.6=py38ha65f79e_0\n",
      "  - conda-forge/linux-64::numpy==1.21.2=py38he2449b9_0\n",
      "  - conda-forge/noarch::wcwidth==0.2.5=pyh9f0ad1d_2\n",
      "  - conda-forge/noarch::ipython_genutils==0.2.0=py_1\n",
      "  - conda-forge/noarch::dataclasses==0.8=pyhc8e2a94_3\n",
      "  - conda-forge/noarch::pexpect==4.8.0=pyh9f0ad1d_2\n",
      "  - conda-forge/noarch::pickleshare==0.7.5=py_1003\n",
      "  - conda-forge/noarch::backcall==0.2.0=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::python==3.8.10=h49503c6_1_cpython\n",
      "  - conda-forge/linux-64::ipython==7.26.0=py38he5a9106_0\n",
      "  - conda-forge/noarch::backports.functools_lru_cache==1.6.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::cmake==3.21.1=h8897547_0\n",
      "  - conda-forge/noarch::typer==0.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::python_abi==3.8=2_cp38\n",
      "  - conda-forge/noarch::glob2==0.7=py_0\n",
      "  - conda-forge/linux-64::mock==4.0.3=py38h578d9bd_1\n",
      "  - conda-forge/noarch::shellingham==1.4.0=pyh44b312d_0\n",
      "  - conda-forge/linux-64::llvmlite==0.35.0=py38h4630a5e_1\n",
      "  - conda-forge/linux-64::numba==0.52.0=py38h51da96c_0\n",
      "  - conda-forge/noarch::ptyprocess==0.7.0=pyhd3deb0d_0\n",
      "  - anaconda/linux-64::ipykernel==6.4.1=py38h06a4308_1\n",
      "  - pytorch/linux-64::pytorch==1.10.1=py3.8_cuda11.3_cudnn8.2.0_0\n",
      "  - conda-forge/linux-64::debugpy==1.6.0=py38hfa26641_0\n",
      "  - pytorch/linux-64::torchaudio==0.10.1=py38_cu113\n",
      "  - conda-forge/linux-64::chardet==4.0.0=py38h578d9bd_3\n",
      "  - conda-forge/noarch::pygments==2.12.0=pyhd8ed1ab_0\n",
      "  - pytorch/linux-64::torchvision==0.11.2=py38_cu113\n",
      "  - conda-forge/noarch::matplotlib-inline==0.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::wasabi==0.9.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flit-core==3.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::python-libarchive-c==4.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::wheel==0.37.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pathy==0.6.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pycparser==2.21=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyzmq==23.0.0=py38hfc09fa9_0\n",
      "  - conda-forge/noarch::pandocfilters==1.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.27.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytz==2022.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::traitlets==5.2.1.post0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::tinycss2==1.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pydantic==1.8.2=py38h497a2fe_2\n",
      "  - conda-forge/noarch::pkginfo==1.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pillow==9.1.1=py38h0ee0e06_1\n",
      "  - conda-forge/linux-64::pysocks==1.7.1=py38h578d9bd_5\n",
      "  - conda-forge/noarch::send2trash==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::cython-blis==0.7.7=py38h71d37f0_1\n",
      "  - conda-forge/noarch::typing-extensions==4.2.0=hd8ed1ab_1\n",
      "  - conda-forge/noarch::attrs==21.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::murmurhash==1.0.7=py38hfa26641_0\n",
      "  - conda-forge/noarch::python-fastjsonschema==2.15.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::thinc==8.0.15=py38h514daf8_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.6.0=py38h578d9bd_0\n",
      "  - anaconda/linux-64::nest-asyncio==1.5.5=py38h06a4308_0\n",
      "  - conda-forge/noarch::idna==3.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipywidgets==7.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbformat==5.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::psutil==5.9.1=py38h0a891b7_0\n",
      "  - conda-forge/linux-64::cryptography==37.0.2=py38h2b5fc30_0\n",
      "  - conda-forge/noarch::webencodings==0.5.1=py_1\n",
      "  - conda-forge/noarch::jupyterlab_widgets==1.1.0=pyhd8ed1ab_0\n",
      "  - anaconda/noarch::python-dateutil==2.8.2=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::bleach==5.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::catalogue==2.0.6=py38h578d9bd_2\n",
      "  - conda-forge/noarch::typing_extensions==4.2.0=pyha770c72_1\n",
      "  - conda-forge/linux-64::cymem==2.0.6=py38hfa26641_3\n",
      "  - conda-forge/linux-64::markupsafe==2.1.1=py38h0a891b7_1\n",
      "  - conda-forge/linux-64::tornado==6.1=py38h0a891b7_3\n",
      "  - conda-forge/noarch::jupyter_client==7.3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::brotlipy==0.7.0=py38h0a891b7_1004\n",
      "  - conda-forge/noarch::pip==22.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prompt-toolkit==3.0.29=pyha770c72_0\n",
      "  - conda-forge/noarch::parso==0.8.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::defusedxml==0.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::soupsieve==2.3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::setuptools==62.3.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::jupyterlab_pygments==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::preshed==3.0.6=py38hfa26641_2\n",
      "  - conda-forge/noarch::decorator==5.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.6.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jedi==0.18.1=py38h578d9bd_1\n",
      "  - anaconda/linux-64::entrypoints==0.4=py38h06a4308_0\n",
      "  - conda-forge/linux-64::mistune==0.8.4=py38h497a2fe_1005\n",
      "  - conda-forge/linux-64::certifi==2022.5.18.1=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pyparsing==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::terminado==0.15.0=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::jupyter_core==4.10.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::nbconvert==6.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::zipp==3.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::ruamel_yaml==0.15.80=py38h0a891b7_1007\n",
      "  - conda-forge/noarch::spacy-legacy==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::srsly==2.4.3=py38hfa26641_1\n",
      "  - conda-forge/linux-64::argon2-cffi-bindings==21.2.0=py38h0a891b7_2\n",
      "  - conda-forge/noarch::notebook==6.4.11=pyha770c72_0\n",
      "  - conda-forge/linux-64::pyrsistent==0.18.1=py38h0a891b7_1\n",
      "  - conda-forge/noarch::beautifulsoup4==4.11.1=pyha770c72_0\n",
      "  - conda-forge/noarch::urllib3==1.26.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jsonschema==4.5.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.12.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::packaging==21.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::importlib-metadata==4.11.4=py38h578d9bd_0\n",
      "  - conda-forge/noarch::importlib_resources==5.7.1=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::pycosat==0.6.3=py38h0a891b7_1010\n",
      "  - conda-forge/noarch::jinja2==3.1.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::py-lief==0.11.5=py38h709712a_1\n",
      "  - conda-forge/noarch::pyopenssl==22.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::filelock==3.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prometheus_client==0.14.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.8.1=py38h0a891b7_1\n",
      "  - conda-forge/noarch::charset-normalizer==2.0.12=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::tqdm==4.64.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::smart_open==5.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::argon2-cffi==21.3.0=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cffi-1.15.0                |   py38h3931269_0         226 KB  conda-forge\n",
      "    cmake-3.23.2               |       h5432695_0        16.3 MB  conda-forge\n",
      "    libffi-3.4.2               |       h7f98852_5          57 KB  conda-forge\n",
      "    libnsl-2.0.0               |       h7f98852_0          31 KB  conda-forge\n",
      "    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n",
      "    python-3.8.13              |h582c2e5_0_cpython        25.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        41.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  cffi                                1.14.6-py38ha65f79e_0 --> 1.15.0-py38h3931269_0\n",
      "  cmake                                   3.21.1-h8897547_0 --> 3.23.2-h5432695_0\n",
      "  libffi                                     3.3-h58526e2_2 --> 3.4.2-h7f98852_5\n",
      "  python                          3.8.10-h49503c6_1_cpython --> 3.8.13-h582c2e5_0_cpython\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libuuid-2.32.1       | 28 KB     | ##################################### | 100% \n",
      "libffi-3.4.2         | 57 KB     | ##################################### | 100% \n",
      "python-3.8.13        | 25.1 MB   | ##################################### | 100% \n",
      "cmake-3.23.2         | 16.3 MB   | ##################################### | 100% \n",
      "cffi-1.15.0          | 226 KB    | ##################################### | 100% \n",
      "libnsl-2.0.0         | 31 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53eb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dialki/DIALKI/apex\n"
     ]
    }
   ],
   "source": [
    "cd apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b49e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dialki/DIALKI/apex\n"
     ]
    }
   ],
   "source": [
    "cd apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19c27bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "print(CUDA_HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00f27d",
   "metadata": {},
   "source": [
    "Install Cuda toolkit 11.3 yang sesuai dengan build cuda dalam nvcc yaitu cuda toolkit 11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ad53652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=11.3\n",
      "    - pytorch==1.10.1\n",
      "    - torchaudio==0.10.1\n",
      "    - torchvision==0.11.2\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  cudatoolkit                           10.2.89-h713d32c_10 --> 11.3.1-h9edb442_10\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pytorch                1.10.1-py3.8_cuda10.2_cudnn7.6.5_0 --> 1.10.1-py3.8_cuda11.3_cudnn8.2.0_0\n",
      "  torchaudio                              0.10.1-py38_cu102 --> 0.10.1-py38_cu113\n",
      "  torchvision                             0.11.2-py38_cu102 --> 0.11.2-py38_cu113\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 cudatoolkit=11.3 -c pytorch -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2856b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af00d3d",
   "metadata": {},
   "source": [
    "Install Apex library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "844b7860",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing pip 22.1.1 from /opt/conda/lib/python3.8/site-packages/pip (python 3.8)\n",
      "Processing /workspace/dialki/DIALKI/apex\n",
      "  Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.10.1\n",
      "\n",
      "\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/dependency_links.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-gqstsqhi/apex.egg-info/SOURCES.txt'\n",
      "  /workspace/dialki/DIALKI/apex/setup.py:123: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Attempting uninstall: apex\n",
      "    Found existing installation: apex 0.1\n",
      "    Uninstalling apex-0.1:\n",
      "      Removing file or directory /opt/conda/lib/python3.8/site-packages/apex-0.1.dist-info/\n",
      "      Removing file or directory /opt/conda/lib/python3.8/site-packages/apex/\n",
      "      Successfully uninstalled apex-0.1\n",
      "  Running command Running setup.py install for apex\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.10.1\n",
      "\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/setup.py:123: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  running install\n",
      "  /opt/conda/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/utils/cpp_extension.py:782: UserWarning: The detected CUDA version (11.4) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n",
      "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "  building 'apex_C' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  ninja: no work to do.\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/flatten_unflatten.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-38/apex_C.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'amp_C' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/3] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/amp_C_frontend.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/amp_C_frontend.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [2/3] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  [3/3] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/amp_C_frontend.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_adagrad.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_adam.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_axpby_kernel.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_l2norm_kernel.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_l2norm_kernel_mp.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_l2norm_scale_kernel.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_lamb.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_lamb_mp.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_lamb_stage_1.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_lamb_stage_2.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_novograd.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_scale_kernel.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/multi_tensor_sgd_kernel.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/amp_C.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'syncbn' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/syncbn.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/syncbn.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/welford.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/syncbn.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/welford.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/syncbn.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'fused_layer_norm_cuda' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/layer_norm_cuda.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                                          ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "        |                                                                ^~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "        |                        ^~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:157:3: note: in expansion of macro CHECK_INPUT\n",
      "    157 |   CHECK_INPUT(input);\n",
      "        |   ^~~~~~~~~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                                          ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "        |                                                                ^~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "        |                        ^~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:178:3: note: in expansion of macro CHECK_INPUT\n",
      "    178 |   CHECK_INPUT(input);\n",
      "        |   ^~~~~~~~~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                                          ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "        |                                                                ^~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "        |                        ^~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:179:3: note: in expansion of macro CHECK_INPUT\n",
      "    179 |   CHECK_INPUT(gamma);\n",
      "        |   ^~~~~~~~~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "        |                                          ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "        |                                                                ^~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:180:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    180 |   CHECK_INPUT(beta);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm_affine_mixed_dtypes(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:202:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    202 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:244:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    244 |   CHECK_INPUT(dout);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:245:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    245 |   CHECK_INPUT(mean);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:246:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    246 |   CHECK_INPUT(invvar);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:247:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    247 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:270:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    270 |   CHECK_INPUT(dout);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:271:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    271 |   CHECK_INPUT(mean);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:272:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    272 |   CHECK_INPUT(invvar);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:273:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    273 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:274:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    274 |   CHECK_INPUT(gamma);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    145 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    147 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:275:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    275 |   CHECK_INPUT(beta);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> rms_norm(at::Tensor, c10::IntArrayRef, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:313:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    313 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> rms_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:332:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    332 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:333:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    333 |   CHECK_INPUT(gamma);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> rms_norm_affine_mixed_dtypes(at::Tensor, c10::IntArrayRef, at::Tensor, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:353:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    353 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function at::Tensor rms_norm_gradient(at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:390:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    390 |   CHECK_INPUT(dout);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:391:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    391 |   CHECK_INPUT(invvar);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:392:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    392 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> rms_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, double):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:413:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    413 |   CHECK_INPUT(dout);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:414:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    414 |   CHECK_INPUT(invvar);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:415:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    415 |   CHECK_INPUT(input);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/DeviceType.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:7,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                                          ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\r\n",
      "    197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "        |                                                                ^~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\r\n",
      "    441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro TORCH_CHECK\r\n",
      "    301 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro CHECK_CUDA\r\n",
      "    303 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "        |                        ^~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:416:3: note: in expansion of macro CHECK_INPUT\r\n",
      "    416 |   CHECK_INPUT(gamma);\r\n",
      "        |   ^~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/layer_norm_cuda_kernel.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/layer_norm_cuda.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/layer_norm_cuda_kernel.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/fused_layer_norm_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'mlp_cuda' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/mlp.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/mlp.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
      "     57 |   for (int i = 0; i < num_layers; i++) {\n",
      "        |                   ~~^~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:64:77: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "        |                                                                             ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:65:86: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
      "        |                                                                                      ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:67:59: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
      "        |                                                           ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |                                                      ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\n",
      "        |                            ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
      "        |                                                        ^\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
      "        |                                                        ^\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
      "     72 |     for (int i = 0; i < num_layers; i++) {\n",
      "        |                     ~~^~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
      "     78 |     auto result = mlp_fp<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
      "     72 |     for (int i = 0; i < num_layers; i++) {\n",
      "        |                     ~~^~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
      "     78 |     auto result = mlp_fp<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
      "     72 |     for (int i = 0; i < num_layers; i++) {\n",
      "        |                     ~~^~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
      "     78 |     auto result = mlp_fp<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
      "    115 |   for (int i = 0; i < num_layers; i++) {\n",
      "        |                   ~~^~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\r\n",
      "    120 |   for (int i = 0; i < inputs.size(); i++) {\r\n",
      "        |                   ~~^~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:121:67: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\r\n",
      "        |                                                                   ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |                                                      ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\r\n",
      "        |                            ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\r\n",
      "    126 |     for (int i = 0; i < num_layers; i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\r\n",
      "    130 |     for (int i = 0; i < inputs.size(); i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:138:99: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\r\n",
      "        |                                                                                                   ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    140 |     auto result = mlp_bp<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\r\n",
      "    126 |     for (int i = 0; i < num_layers; i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\r\n",
      "    130 |     for (int i = 0; i < inputs.size(); i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:138:99: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\r\n",
      "        |                                                                                                   ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    140 |     auto result = mlp_bp<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\r\n",
      "    126 |     for (int i = 0; i < num_layers; i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\r\n",
      "    130 |     for (int i = 0; i < inputs.size(); i++) {\r\n",
      "        |                     ~~^~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:138:99: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\r\n",
      "        |                                                                                                   ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\n",
      "    140 |     auto result = mlp_bp<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/mlp_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/mlp.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/mlp_cuda.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/mlp_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'fused_dense_cuda' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/fused_dense.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In function at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:30:63: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     30 |   auto out = at::empty({batch_size, out_features}, input.type());\n",
      "        |                                                               ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:33:55: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "        |                                                       ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:50: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |                                                  ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\n",
      "        |                            ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
      "        |                                                        ^\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
      "        |                                                        ^\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "        |                       ^~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
      "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "        |               ^~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
      "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
      "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "        |               ^~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
      "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
      "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "        |               ^~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
      "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "        |          ^~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     66 |     return __VA_ARGS__();                                                        \\\n",
      "        |            ^~~~~~~~~~~\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor):\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:64:69: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n",
      "        |                                                                     ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:68:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     68 |   auto d_bias = at::empty({out_features}, input.type());\n",
      "        |                                                      ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:70:66: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
      "        |                                                                  ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:73:55: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "        |                                                       ^\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n",
      "    194 |   DeprecatedTypeProperties & type() const {\n",
      "        |                              ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:50: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
      "        |                                                  ^\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\n",
      "        |                            ^~~~\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\r\n",
      "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\r\n",
      "        |               ^~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\r\n",
      "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\r\n",
      "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\r\n",
      "        |               ^~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\r\n",
      "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\r\n",
      "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\r\n",
      "        |               ^~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\r\n",
      "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:106:70: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\r\n",
      "        |                                                                      ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:107:70: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\r\n",
      "        |                                                                      ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:108:67: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\r\n",
      "        |                                                                   ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:111:55: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\r\n",
      "        |                                                       ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:50: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |                                                  ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\r\n",
      "        |                            ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor):\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:149:73: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\r\n",
      "        |                                                                         ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:150:74: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\r\n",
      "        |                                                                          ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:151:58: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\r\n",
      "        |                                                          ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:152:55: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    152 |   auto d_bias2 = at::empty({out_features}, input.type());\r\n",
      "        |                                                       ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:153:66: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\r\n",
      "        |                                                                  ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:154:72: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\r\n",
      "        |                                                                        ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:157:55: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\r\n",
      "        |                                                       ^\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:50: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |                                                  ^\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    276 |     const auto& the_type = TYPE;                                               \\\r\n",
      "        |                            ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Tensor.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:9,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\r\n",
      "    194 |   DeprecatedTypeProperties & type() const {\r\n",
      "        |                              ^~~~\r\n",
      "  In file included from /opt/conda/lib/python3.8/site-packages/torch/include/ATen/ATen.h:13,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\r\n",
      "                   from /opt/conda/lib/python3.8/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                   from /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:1:\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "    278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\r\n",
      "        |                                                        ^\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\r\n",
      "    176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "        |                       ^~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:162:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:162:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp: In lambda function:\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:162:10: warning: unused variable result [-Wunused-variable]\r\n",
      "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\r\n",
      "        |          ^~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\r\n",
      "     66 |     return __VA_ARGS__();                                                        \\\r\n",
      "        |            ^~~~~~~~~~~\r\n",
      "  /opt/conda/lib/python3.8/site-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\r\n",
      "    283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\r\n",
      "        |       ^~~~~~~~~~~~~~~~~~~~\r\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\r\n",
      "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\r\n",
      "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
      "\n",
      "  /workspace/dialki/DIALKI/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
      "\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/fused_dense.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/fused_dense_cuda.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/fused_dense_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
      "  creating /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_upper_triang_masked_softmax.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/scaled_upper_triang_masked_softmax_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'scaled_masked_softmax_cuda' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/2] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/scaled_masked_softmax.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [2/2] /usr/local/cuda/bin/nvcc  -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_masked_softmax.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/scaled_masked_softmax_cuda.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/scaled_masked_softmax_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  building 'fused_weight_gradient_mlp_cuda' extension\n",
      "  Emitting ninja build file /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/build.ninja...\n",
      "  Compiling objects...\n",
      "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  [1/3] c++ -MMD -MF /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [2/3] /usr/local/cuda/bin/nvcc  -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  [3/3] /usr/local/cuda/bin/nvcc  -I/workspace/dialki/DIALKI/apex/csrc -I/opt/conda/lib/python3.8/site-packages/torch/include -I/opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.8/site-packages/torch/include/TH -I/opt/conda/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.8 -c -c /workspace/dialki/DIALKI/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o /workspace/dialki/DIALKI/apex/build/temp.linux-x86_64-cpython-38/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/opt/conda/lib/python3.8/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-cpython-38/fused_weight_gradient_mlp_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  running install_lib\n",
      "  copying build/lib.linux-x86_64-cpython-38/syncbn.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/scaler.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/amp.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/utils.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/compat.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/handle.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/__version__.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/_amp_state.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/lists/torch_overrides.py -> /opt/conda/lib/python3.8/site-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/lists/tensor_overrides.py -> /opt/conda/lib/python3.8/site-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/lists/functional_overrides.py -> /opt/conda/lib/python3.8/site-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/lists/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/opt.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/_process_optimizer.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/_initialize.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/wrap.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/frontend.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/amp/rnn_compat.py -> /opt/conda/lib/python3.8/site-packages/apex/amp\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/amp/grad_scaler.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/amp\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/amp/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/amp\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/_data/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/_data/_batchsampler.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/utils.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/parallel_state.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/utils.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/mappings.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/random.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/layers.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/memory.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/cross_entropy.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/tensor_parallel/data.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/log_util.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/functional/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/functional/fused_softmax.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/enums.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/microbatches.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/schedules/common.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/schedules/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/utils.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/_timers.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/pipeline_parallel/p2p_communication.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/arguments.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/distributed_test_base.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/standalone_gpt.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/global_vars.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/commons.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/transformer/testing/standalone_bert.py -> /opt/conda/lib/python3.8/site-packages/apex/transformer/testing\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/fused_dense\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fused_dense/fused_dense.py -> /opt/conda/lib/python3.8/site-packages/apex/fused_dense\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fused_dense/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/fused_dense\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/optimized_sync_batchnorm_kernel.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/LARC.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/sync_batchnorm.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/sync_batchnorm_kernel.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/multiproc.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/optimized_sync_batchnorm.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/parallel/distributed.py -> /opt/conda/lib/python3.8/site-packages/apex/parallel\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_adam.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_novograd.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_mixed_precision_lamb.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_lamb.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_adagrad.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/optimizers/fused_sgd.py -> /opt/conda/lib/python3.8/site-packages/apex/optimizers\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/normalization\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/normalization/fused_layer_norm.py -> /opt/conda/lib/python3.8/site-packages/apex/normalization\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/normalization/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/normalization\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/reparameterization\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/reparameterization/reparameterization.py -> /opt/conda/lib/python3.8/site-packages/apex/reparameterization\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/reparameterization/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/reparameterization\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/reparameterization/weight_norm.py -> /opt/conda/lib/python3.8/site-packages/apex/reparameterization\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/multi_tensor_apply\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/multi_tensor_apply/multi_tensor_apply.py -> /opt/conda/lib/python3.8/site-packages/apex/multi_tensor_apply\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/multi_tensor_apply/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/multi_tensor_apply\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/layer_norm\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/layer_norm/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/layer_norm\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/layer_norm/layer_norm.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/layer_norm\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/xentropy\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/xentropy/softmax_xentropy.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/xentropy\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/xentropy/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/xentropy\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/focal_loss\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/focal_loss/focal_loss.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/focal_loss\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/focal_loss/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/focal_loss\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/permutation_lib.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/asp.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/sparse_masklib.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/sparsity/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/distributed_fused_adam.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/fused_adam.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/fused_lamb.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/distributed_fused_lamb.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/fp16_optimizer.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/optimizers/fused_sgd.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/bottleneck/bottleneck_module_test.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/bottleneck/test.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/bottleneck/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/bottleneck/bottleneck.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/bottleneck/halo_exchangers.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/peer_memory/peer_halo_exchange_module_tests.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/peer_memory/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/peer_memory/peer_memory.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/conv_bias_relu/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/conv_bias_relu/conv_bias_relu.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/conv_bias_relu\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/fmha\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/fmha/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/fmha\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/fmha/fmha.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/fmha\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/self_multihead_attn.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/transducer\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/transducer/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/transducer\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/transducer/transducer.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/transducer\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/contrib/groupbn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/groupbn/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/groupbn\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/contrib/groupbn/batch_norm.py -> /opt/conda/lib/python3.8/site-packages/apex/contrib/groupbn\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/pyprof\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/pyprof/nvtx\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/nvtx/nvmarker.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/nvtx\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/nvtx/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/nvtx\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/pointwise.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/output.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/pooling.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/normalization.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/__main__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/optim.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/embedding.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/softmax.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/randomSample.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/prof.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/reduction.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/misc.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/index_slice_join_mutate.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/loss.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/dropout.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/usage.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/recurrentCell.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/activation.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/convert.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/base.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/utility.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/data.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/conv.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/blas.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/prof/linear.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/parse.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/__main__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/nvvp.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/db.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/pyprof/parse/kernel.py -> /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/_autocast_utils.py -> /opt/conda/lib/python3.8/site-packages/apex\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/RNN\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/RNN/models.py -> /opt/conda/lib/python3.8/site-packages/apex/RNN\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/RNN/RNNBackend.py -> /opt/conda/lib/python3.8/site-packages/apex/RNN\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/RNN/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/RNN\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/RNN/cells.py -> /opt/conda/lib/python3.8/site-packages/apex/RNN\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/fp16_utils\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fp16_utils/fp16util.py -> /opt/conda/lib/python3.8/site-packages/apex/fp16_utils\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fp16_utils/fp16_optimizer.py -> /opt/conda/lib/python3.8/site-packages/apex/fp16_utils\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fp16_utils/loss_scaler.py -> /opt/conda/lib/python3.8/site-packages/apex/fp16_utils\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/fp16_utils/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/fp16_utils\r\n",
      "  creating /opt/conda/lib/python3.8/site-packages/apex/mlp\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/mlp/__init__.py -> /opt/conda/lib/python3.8/site-packages/apex/mlp\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex/mlp/mlp.py -> /opt/conda/lib/python3.8/site-packages/apex/mlp\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/apex_C.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/fused_weight_gradient_mlp_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/mlp_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/scaled_upper_triang_masked_softmax_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/scaled_masked_softmax_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/fused_layer_norm_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/amp_C.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  copying build/lib.linux-x86_64-cpython-38/fused_dense_cuda.cpython-38-x86_64-linux-gnu.so -> /opt/conda/lib/python3.8/site-packages\r\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/scaler.py to scaler.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/amp.py to amp.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/compat.py to compat.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/handle.py to handle.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/__version__.py to __version__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/lists/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/opt.py to opt.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py to _initialize.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/wrap.py to wrap.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/frontend.py to frontend.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/amp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/_data/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/parallel_state.py to parallel_state.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/random.py to random.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/layers.py to layers.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/memory.py to memory.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/tensor_parallel/data.py to data.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/log_util.py to log_util.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/functional/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/enums.py to enums.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/microbatches.py to microbatches.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/arguments.py to arguments.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/global_vars.py to global_vars.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/commons.py to commons.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fused_dense/fused_dense.py to fused_dense.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fused_dense/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/LARC.py to LARC.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/multiproc.py to multiproc.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/parallel/distributed.py to distributed.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/normalization/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/reparameterization/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/focal_loss/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/asp.py to asp.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck/bottleneck_module_test.py to bottleneck_module_test.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck/test.py to test.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory/peer_halo_exchange_module_tests.py to peer_halo_exchange_module_tests.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/fmha/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/fmha/fmha.py to fmha.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/transducer/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/transducer/transducer.py to transducer.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/output.py to output.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/pooling.py to pooling.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/normalization.py to normalization.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/__main__.py to __main__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/optim.py to optim.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/embedding.py to embedding.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/softmax.py to softmax.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/prof.py to prof.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/reduction.py to reduction.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/misc.py to misc.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/loss.py to loss.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/dropout.py to dropout.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/usage.py to usage.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/activation.py to activation.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/convert.py to convert.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/base.py to base.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/utility.py to utility.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/data.py to data.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/conv.py to conv.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/blas.py to blas.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/prof/linear.py to linear.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/parse.py to parse.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/__main__.py to __main__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/db.py to db.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/pyprof/parse/kernel.py to kernel.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/_autocast_utils.py to _autocast_utils.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/RNN/models.py to models.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/RNN/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/RNN/cells.py to cells.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/mlp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /opt/conda/lib/python3.8/site-packages/apex/mlp/mlp.py to mlp.cpython-38.pyc\n",
      "  /opt/conda/lib/python3.8/site-packages/apex/mlp/mlp.py:40: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    if activation is 'none':\n",
      "  /opt/conda/lib/python3.8/site-packages/apex/mlp/mlp.py:42: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    elif activation is 'relu':\n",
      "  /opt/conda/lib/python3.8/site-packages/apex/mlp/mlp.py:44: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    elif activation is 'sigmoid':\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "  writing top-level names to apex.egg-info/top_level.txt\n",
      "  reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  Copying apex.egg-info to /opt/conda/lib/python3.8/site-packages/apex-0.1-py3.8.egg-info\n",
      "  running install_scripts\n",
      "  writing list of installed files to '/tmp/pip-record-rr4540cm/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "Successfully installed apex-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae10df",
   "metadata": {},
   "source": [
    "# Langkah 3 : Lakukan preprocessing dan encoding dengan Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea2a6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253e2456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dialdoc/pretrained_models/allenai/longformer-base-4096 exists!\n",
      "Preprocess train data from ./dialdoc/data: chunk    19 finished!: 100%|| 21/21 \n",
      "Preprocess   dev data from ./dialdoc/data: chunk     3 finished!: 100%|| 4/4 [0\n"
     ]
    }
   ],
   "source": [
    "!bash run_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2c1fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess train data from ./dialdoc/data: chunk    19 finished!: 100%|| 21/21 \n",
      "Preprocess   dev data from ./dialdoc/data: chunk     3 finished!: 100%|| 4/4 [0\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/gen_data_cls_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f3f4d",
   "metadata": {},
   "source": [
    "# Lakukan training sistem usulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0b36a",
   "metadata": {},
   "source": [
    "Lakukan training dengan pretrained language model Longformer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed25d8",
   "metadata": {},
   "source": [
    "Beberapa kali percobaan training di bawah ini beberapa kali gagal karena warning resource memory allocated. Maka eksperimen mencoba mengubah max_sequence_Length dari 4096, menjadi turun lagi. Hingga akhirnya pada ukuran 512 tidak muncul error lagi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8df7d",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd25d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/opt/conda/lib/python3.8/site-packages/amp_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20getCurrentCUDAStreamEa')\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.68\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9672\n",
      "    -              passage loss: 1.9788\n",
      "    -         history_span loss: 8.9125\n",
      "    -      history_passage loss: 1.9849\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8968\n",
      "    -             emb_val other: 0.27500805\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.70\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9911\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 2.0306\n",
      "    -         history_span loss: 8.7206\n",
      "    -      history_passage loss: 2.0218\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7717\n",
      "    -             emb_val other: 0.27521792\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.410.205\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.70\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 1.9537\n",
      "    -         history_span loss: 8.9064\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8369\n",
      "    -             emb_val other: 0.27694809\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.70\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9754\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9355\n",
      "    -              passage loss: 1.9933\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9848\n",
      "    -             emb_val other: 0.27582633\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.822.411\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.70\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9824\n",
      "    -                  end loss: 3.9621\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 8.9321\n",
      "    -      history_passage loss: 2.0000\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9298\n",
      "    -             emb_val other: 0.27613178\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.71\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9965\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0179\n",
      "    -         history_span loss: 8.8718\n",
      "    -      history_passage loss: 2.0276\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9206\n",
      "    -             emb_val other: 0.27621183\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1242.621\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd95492",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df78e312",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/opt/conda/lib/python3.8/site-packages/amp_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20getCurrentCUDAStreamEa')\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.72\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9672\n",
      "    -              passage loss: 1.9788\n",
      "    -         history_span loss: 8.9125\n",
      "    -      history_passage loss: 1.9849\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8968\n",
      "    -             emb_val other: 0.27500805\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.73\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9911\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 2.0306\n",
      "    -         history_span loss: 8.7206\n",
      "    -      history_passage loss: 2.0218\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7717\n",
      "    -             emb_val other: 0.27521792\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.420.210\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.72\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 1.9537\n",
      "    -         history_span loss: 8.9064\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8369\n",
      "    -             emb_val other: 0.27694809\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.72\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9754\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9355\n",
      "    -              passage loss: 1.9933\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9848\n",
      "    -             emb_val other: 0.27582633\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.844.422\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.72\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9824\n",
      "    -                  end loss: 3.9621\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 8.9321\n",
      "    -      history_passage loss: 2.0000\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9298\n",
      "    -             emb_val other: 0.27613178\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.72\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9965\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0179\n",
      "    -         history_span loss: 8.8718\n",
      "    -      history_passage loss: 2.0276\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9206\n",
      "    -             emb_val other: 0.27621183\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1266.633\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.100e-05; train time per batch = 1.72\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9898\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9455\n",
      "    -              passage loss: 1.9885\n",
      "    -         history_span loss: 9.0812\n",
      "    -      history_passage loss: 1.9949\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0656\n",
      "    -             emb_val other: 0.27510697\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.72\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9843\n",
      "    -                  end loss: 3.9488\n",
      "    -                 span loss: 7.9331\n",
      "    -              passage loss: 1.9685\n",
      "    -         history_span loss: 9.0705\n",
      "    -      history_passage loss: 1.9712\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9975\n",
      "    -             emb_val other: 0.27600601\n",
      "    -         eff_perturb other: 0.00000188\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1688.844\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.72\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9910\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9423\n",
      "    -              passage loss: 2.0029\n",
      "    -         history_span loss: 8.8212\n",
      "    -      history_passage loss: 1.9955\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8180\n",
      "    -             emb_val other: 0.27558291\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=3.000e-05; train time per batch = 1.72\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9934\n",
      "    -                  end loss: 3.9574\n",
      "    -                 span loss: 7.9509\n",
      "    -              passage loss: 2.0153\n",
      "    -         history_span loss: 9.0389\n",
      "    -      history_passage loss: 2.0037\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0627\n",
      "    -             emb_val other: 0.27453122\n",
      "    -         eff_perturb other: 0.00000167\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.29\n",
      "Eval step 200 / 993; eval time per batch = 0.29\n",
      "Eval step 300 / 993; eval time per batch = 0.29\n",
      "Eval step 400 / 993; eval time per batch = 0.30\n",
      "Eval step 500 / 993; eval time per batch = 0.27\n",
      "Eval step 600 / 993; eval time per batch = 0.26\n",
      "Eval step 700 / 993; eval time per batch = 0.25\n",
      "Eval step 800 / 993; eval time per batch = 0.25\n",
      "Eval step 900 / 993; eval time per batch = 0.25\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "New best EM 1.59 on dev\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2000.1000\n",
      "New best F1 14.25 on dev\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.2000.1000\n",
      "Best F1 14.25 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2002.1001\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.998e-05; train time per batch = 1.72\n",
      "Train: global step = 1100; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9951\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 1.9951\n",
      "    -         history_span loss: 8.9557\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9410\n",
      "    -             emb_val other: 0.27518237\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.997e-05; train time per batch = 1.72\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9974\n",
      "    -                  end loss: 3.9536\n",
      "    -                 span loss: 7.9509\n",
      "    -              passage loss: 1.9858\n",
      "    -         history_span loss: 8.8484\n",
      "    -      history_passage loss: 1.9927\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8309\n",
      "    -             emb_val other: 0.27537417\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2428.1214\n",
      "Epoch: 0: Step: 1300/9807; Global_step=1300; lr=2.995e-05; train time per batch = 1.72\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9488\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 2.0272\n",
      "    -         history_span loss: 9.1193\n",
      "    -      history_passage loss: 2.0099\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1542\n",
      "    -             emb_val other: 0.27624610\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 1400/9807; Global_step=1400; lr=2.994e-05; train time per batch = 1.72\n",
      "Train: global step = 1400; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9900\n",
      "    -                  end loss: 3.9699\n",
      "    -                 span loss: 7.9599\n",
      "    -              passage loss: 1.9850\n",
      "    -         history_span loss: 9.0196\n",
      "    -      history_passage loss: 1.9948\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0162\n",
      "    -             emb_val other: 0.27555823\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2856.1428\n",
      "Epoch: 0: Step: 1500/9807; Global_step=1500; lr=2.992e-05; train time per batch = 1.72\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0006\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 1.9625\n",
      "    -         history_span loss: 8.9026\n",
      "    -      history_passage loss: 1.9677\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8411\n",
      "    -             emb_val other: 0.27497324\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 0: Step: 1600/9807; Global_step=1600; lr=2.991e-05; train time per batch = 1.71\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9558\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 1.9683\n",
      "    -         history_span loss: 8.9711\n",
      "    -      history_passage loss: 1.9598\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8999\n",
      "    -             emb_val other: 0.27510819\n",
      "    -         eff_perturb other: 0.00000167\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3280.1640\n",
      "Epoch: 0: Step: 1700/9807; Global_step=1700; lr=2.989e-05; train time per batch = 1.72\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9788\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9293\n",
      "    -              passage loss: 2.0271\n",
      "    -         history_span loss: 9.1879\n",
      "    -      history_passage loss: 2.0088\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2085\n",
      "    -             emb_val other: 0.27624339\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 1800/9807; Global_step=1800; lr=2.988e-05; train time per batch = 1.71\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9885\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9528\n",
      "    -              passage loss: 1.9697\n",
      "    -         history_span loss: 9.2221\n",
      "    -      history_passage loss: 1.9749\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1735\n",
      "    -             emb_val other: 0.27577439\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3702.1851\n",
      "Epoch: 0: Step: 1900/9807; Global_step=1900; lr=2.986e-05; train time per batch = 1.74\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9863\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 2.0161\n",
      "    -         history_span loss: 8.9585\n",
      "    -      history_passage loss: 2.0089\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9720\n",
      "    -             emb_val other: 0.27690363\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Epoch: 0: Step: 2000/9807; Global_step=2000; lr=2.985e-05; train time per batch = 1.81\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9938\n",
      "    -                  end loss: 3.9516\n",
      "    -                 span loss: 7.9454\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 9.1212\n",
      "    -      history_passage loss: 1.9937\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1221\n",
      "    -             emb_val other: 0.27557227\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.59\n",
      "Eval step 200 / 993; eval time per batch = 0.44\n",
      "Eval step 300 / 993; eval time per batch = 0.40\n",
      "Eval step 400 / 993; eval time per batch = 0.37\n",
      "Eval step 500 / 993; eval time per batch = 0.34\n",
      "Eval step 600 / 993; eval time per batch = 0.31\n",
      "Eval step 700 / 993; eval time per batch = 0.29\n",
      "Eval step 800 / 993; eval time per batch = 0.29\n",
      "Eval step 900 / 993; eval time per batch = 0.28\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.2000.1000\n",
      "Best F1 14.25 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4002.2001\n",
      "Epoch: 0: Step: 2100/9807; Global_step=2100; lr=2.983e-05; train time per batch = 1.81\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9760\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9331\n",
      "    -              passage loss: 1.9787\n",
      "    -         history_span loss: 8.8957\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8610\n",
      "    -             emb_val other: 0.27672687\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reader.py\", line 964, in <module>\n",
      "    main()\n",
      "  File \"train_reader.py\", line 953, in main\n",
      "    trainer.run_train()\n",
      "  File \"train_reader.py\", line 302, in run_train\n",
      "    self._train_epoch(epoch, train_dataloader)\n",
      "  File \"train_reader.py\", line 537, in _train_epoch\n",
      "    losses, others = self._training_step(batch)\n",
      "  File \"train_reader.py\", line 838, in _training_step\n",
      "    logits, others = self.reader(batch, self.global_step)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py\", line 511, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 254, in forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 267, in adv_forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_teacher.forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/perturbation.py\", line 64, in forward\n",
      "    adv_logits, _ = model(batch, global_step, fwd_type='inputs_embeds', inputs_embeds=embed+noise, end_task_only=True)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 183, in forward\n",
      "    sequence_output, _pooled_output, _hidden_states = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workspace/dialki/DIALKI/models/hf_models_longformer.py\", line 109, in forward\n",
      "    sequence_output, pooled_output = super().forward(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1703, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1285, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1209, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1145, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 665, in forward\n",
      "    attn_output = self._sliding_chunks_matmul_attn_probs_value(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 900, in _sliding_chunks_matmul_attn_probs_value\n",
      "    chunked_attn_probs = self._pad_and_diagonalize(chunked_attn_probs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 751, in _pad_and_diagonalize\n",
      "    chunked_hidden_states = nn.functional.pad(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 3552, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 31.72 GiB total capacity; 17.16 GiB already allocated; 39.88 MiB free; 17.45 GiB reserved in total by PyTorch)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 261, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 256, in main\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode,\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'train_reader.py', '--local_rank=0', '--pretrained_model_cfg', './dialdoc/pretrained_models/allenai/longformer-base-4096', '--seed', '42', '--learning_rate', '3e-5', '--eval_step', '1000', '--do_lower_case', '--eval_top_docs', '20', '--warmup_steps', '1000', '--max_seq_len', '512', '--batch_size', '2', '--passages_per_question', '8', '--num_train_epochs', '20', '--dev_batch_size', '4', '--max_answer_length', '5', '--passages_per_question_predict', '20', '--train_file', './dialdoc/cache/cls_longformerlongformerlongformer/train', '--dev_file', './dialdoc/cache/cls_longformerlongformerlongformer/dev', '--output_dir', './dialdoc/exp', '--gradient_accumulation_steps', '1', '--ignore_token_type', '--decision_function', '1', '--hist_loss_weight', '1.0', '--fp16', '--fp16_opt_level', 'O2', '--data_name', 'dialdoc', '--adv_loss_type', 'js', '--adv_loss_weight', '5', '--use_z_attn']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23652b",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01ec6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/opt/conda/lib/python3.8/site-packages/amp_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20getCurrentCUDAStreamEa')\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reader_longformer.py\", line 968, in <module>\n",
      "    main()\n",
      "  File \"train_reader_longformer.py\", line 957, in main\n",
      "    trainer.run_train()\n",
      "  File \"train_reader_longformer.py\", line 306, in run_train\n",
      "    self._train_epoch(epoch, train_dataloader)\n",
      "  File \"train_reader_longformer.py\", line 584, in _train_epoch\n",
      "    torch.cuda.empty_cache()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py\", line 87, in empty_cache\n",
      "    torch._C._cuda_emptyCache()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06389a",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "817fd6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/opt/conda/lib/python3.8/site-packages/amp_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20getCurrentCUDAStreamEa')\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.74\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9672\n",
      "    -              passage loss: 1.9788\n",
      "    -         history_span loss: 8.9125\n",
      "    -      history_passage loss: 1.9849\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8968\n",
      "    -             emb_val other: 0.27500805\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.75\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9911\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 2.0306\n",
      "    -         history_span loss: 8.7206\n",
      "    -      history_passage loss: 2.0218\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7717\n",
      "    -             emb_val other: 0.27521792\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.416.208\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.73\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 1.9537\n",
      "    -         history_span loss: 8.9064\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8369\n",
      "    -             emb_val other: 0.27694809\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.74\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9754\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9355\n",
      "    -              passage loss: 1.9933\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9848\n",
      "    -             emb_val other: 0.27582633\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.832.416\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.73\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9824\n",
      "    -                  end loss: 3.9621\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 8.9321\n",
      "    -      history_passage loss: 2.0000\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9298\n",
      "    -             emb_val other: 0.27613178\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.74\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9965\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0179\n",
      "    -         history_span loss: 8.8718\n",
      "    -      history_passage loss: 2.0276\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9206\n",
      "    -             emb_val other: 0.27621183\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1246.623\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.100e-05; train time per batch = 1.74\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9898\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9455\n",
      "    -              passage loss: 1.9885\n",
      "    -         history_span loss: 9.0812\n",
      "    -      history_passage loss: 1.9949\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0656\n",
      "    -             emb_val other: 0.27510697\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.74\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9843\n",
      "    -                  end loss: 3.9488\n",
      "    -                 span loss: 7.9331\n",
      "    -              passage loss: 1.9685\n",
      "    -         history_span loss: 9.0705\n",
      "    -      history_passage loss: 1.9712\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9975\n",
      "    -             emb_val other: 0.27600601\n",
      "    -         eff_perturb other: 0.00000188\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1662.831\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.74\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9910\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9423\n",
      "    -              passage loss: 2.0029\n",
      "    -         history_span loss: 8.8212\n",
      "    -      history_passage loss: 1.9955\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8180\n",
      "    -             emb_val other: 0.27558291\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Eval step 200 / 993; eval time per batch = 0.29\n",
      "Eval step 300 / 993; eval time per batch = 0.30\n",
      "Eval step 400 / 993; eval time per batch = 0.30\n",
      "Eval step 500 / 993; eval time per batch = 0.28\n",
      "Eval step 600 / 993; eval time per batch = 0.26\n",
      "Eval step 700 / 993; eval time per batch = 0.25\n",
      "Eval step 800 / 993; eval time per batch = 0.25\n",
      "Eval step 900 / 993; eval time per batch = 0.25\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.10000.5000\n",
      "Best F1 14.25 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2002.1001\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.998e-05; train time per batch = 1.74\n",
      "Train: global step = 1100; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9951\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 1.9951\n",
      "    -         history_span loss: 8.9557\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9410\n",
      "    -             emb_val other: 0.27518237\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.997e-05; train time per batch = 1.74\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9974\n",
      "    -                  end loss: 3.9536\n",
      "    -                 span loss: 7.9509\n",
      "    -              passage loss: 1.9858\n",
      "    -         history_span loss: 8.8484\n",
      "    -      history_passage loss: 1.9927\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8309\n",
      "    -             emb_val other: 0.27537417\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2414.1207\n",
      "Epoch: 0: Step: 1300/9807; Global_step=1300; lr=2.995e-05; train time per batch = 1.74\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9488\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 2.0272\n",
      "    -         history_span loss: 9.1193\n",
      "    -      history_passage loss: 2.0099\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1542\n",
      "    -             emb_val other: 0.27624610\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 1400/9807; Global_step=1400; lr=2.994e-05; train time per batch = 1.74\n",
      "Train: global step = 1400; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9900\n",
      "    -                  end loss: 3.9699\n",
      "    -                 span loss: 7.9599\n",
      "    -              passage loss: 1.9850\n",
      "    -         history_span loss: 9.0196\n",
      "    -      history_passage loss: 1.9948\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0162\n",
      "    -             emb_val other: 0.27555823\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2824.1412\n",
      "Epoch: 0: Step: 1500/9807; Global_step=1500; lr=2.992e-05; train time per batch = 1.74\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0006\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 1.9625\n",
      "    -         history_span loss: 8.9026\n",
      "    -      history_passage loss: 1.9677\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8411\n",
      "    -             emb_val other: 0.27497324\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 0: Step: 1600/9807; Global_step=1600; lr=2.991e-05; train time per batch = 1.74\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9558\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 1.9683\n",
      "    -         history_span loss: 8.9711\n",
      "    -      history_passage loss: 1.9598\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8999\n",
      "    -             emb_val other: 0.27510819\n",
      "    -         eff_perturb other: 0.00000167\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3242.1621\n",
      "Epoch: 0: Step: 1700/9807; Global_step=1700; lr=2.989e-05; train time per batch = 1.74\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9788\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9293\n",
      "    -              passage loss: 2.0271\n",
      "    -         history_span loss: 9.1879\n",
      "    -      history_passage loss: 2.0088\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2085\n",
      "    -             emb_val other: 0.27624339\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 1800/9807; Global_step=1800; lr=2.988e-05; train time per batch = 1.74\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9885\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9528\n",
      "    -              passage loss: 1.9697\n",
      "    -         history_span loss: 9.2221\n",
      "    -      history_passage loss: 1.9749\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1735\n",
      "    -             emb_val other: 0.27577439\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3668.1834\n",
      "Epoch: 0: Step: 1900/9807; Global_step=1900; lr=2.986e-05; train time per batch = 1.74\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9863\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 2.0161\n",
      "    -         history_span loss: 8.9585\n",
      "    -      history_passage loss: 2.0089\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9720\n",
      "    -             emb_val other: 0.27690363\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Epoch: 0: Step: 2000/9807; Global_step=2000; lr=2.985e-05; train time per batch = 1.74\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9938\n",
      "    -                  end loss: 3.9516\n",
      "    -                 span loss: 7.9454\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 9.1212\n",
      "    -      history_passage loss: 1.9937\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1221\n",
      "    -             emb_val other: 0.27557227\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.29\n",
      "Eval step 200 / 993; eval time per batch = 0.29\n",
      "Eval step 300 / 993; eval time per batch = 0.30\n",
      "Eval step 400 / 993; eval time per batch = 0.30\n",
      "Eval step 500 / 993; eval time per batch = 0.28\n",
      "Eval step 600 / 993; eval time per batch = 0.26\n",
      "Eval step 700 / 993; eval time per batch = 0.25\n",
      "Eval step 800 / 993; eval time per batch = 0.25\n",
      "Eval step 900 / 993; eval time per batch = 0.25\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.10000.5000\n",
      "Best F1 14.25 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4002.2001\n",
      "Epoch: 0: Step: 2100/9807; Global_step=2100; lr=2.983e-05; train time per batch = 1.74\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9760\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9331\n",
      "    -              passage loss: 1.9787\n",
      "    -         history_span loss: 8.8957\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8610\n",
      "    -             emb_val other: 0.27672687\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 0: Step: 2200/9807; Global_step=2200; lr=2.982e-05; train time per batch = 1.73\n",
      "Train: global step = 2200; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9979\n",
      "    -                  end loss: 3.9462\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 9.1578\n",
      "    -      history_passage loss: 1.9678\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.0849\n",
      "    -             emb_val other: 0.27556866\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4434.2217\n",
      "Epoch: 0: Step: 2300/9807; Global_step=2300; lr=2.980e-05; train time per batch = 1.73\n",
      "Train: global step = 2300; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9906\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9585\n",
      "    -              passage loss: 1.9988\n",
      "    -         history_span loss: 9.0270\n",
      "    -      history_passage loss: 2.0083\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0477\n",
      "    -             emb_val other: 0.27711460\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 0: Step: 2400/9807; Global_step=2400; lr=2.978e-05; train time per batch = 1.74\n",
      "Train: global step = 2400; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9880\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9400\n",
      "    -              passage loss: 2.0367\n",
      "    -         history_span loss: 9.1176\n",
      "    -      history_passage loss: 2.0390\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0056\n",
      "    -                total loss: 21.1937\n",
      "    -             emb_val other: 0.27535355\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4860.2430\n",
      "Epoch: 0: Step: 2500/9807; Global_step=2500; lr=2.977e-05; train time per batch = 1.73\n",
      "Train: global step = 2500; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9872\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9436\n",
      "    -              passage loss: 1.9273\n",
      "    -         history_span loss: 9.0656\n",
      "    -      history_passage loss: 1.9311\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9215\n",
      "    -             emb_val other: 0.27623966\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Epoch: 0: Step: 2600/9807; Global_step=2600; lr=2.975e-05; train time per batch = 1.73\n",
      "Train: global step = 2600; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9935\n",
      "    -                  end loss: 3.9498\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9469\n",
      "    -         history_span loss: 8.8043\n",
      "    -      history_passage loss: 1.9536\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 20.6987\n",
      "    -             emb_val other: 0.27680880\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5292.2646\n",
      "Epoch: 0: Step: 2700/9807; Global_step=2700; lr=2.974e-05; train time per batch = 1.73\n",
      "Train: global step = 2700; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9579\n",
      "    -                 span loss: 7.9448\n",
      "    -              passage loss: 1.9889\n",
      "    -         history_span loss: 8.9048\n",
      "    -      history_passage loss: 1.9734\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.8689\n",
      "    -             emb_val other: 0.27684560\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 0: Step: 2800/9807; Global_step=2800; lr=2.972e-05; train time per batch = 1.73\n",
      "Train: global step = 2800; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0047\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9654\n",
      "    -              passage loss: 1.9888\n",
      "    -         history_span loss: 8.9343\n",
      "    -      history_passage loss: 1.9982\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9417\n",
      "    -             emb_val other: 0.27710137\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5706.2853\n",
      "Epoch: 0: Step: 2900/9807; Global_step=2900; lr=2.971e-05; train time per batch = 1.73\n",
      "Train: global step = 2900; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9986\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9499\n",
      "    -              passage loss: 1.9978\n",
      "    -         history_span loss: 9.1657\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.1680\n",
      "    -             emb_val other: 0.27474937\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 3000/9807; Global_step=3000; lr=2.969e-05; train time per batch = 1.73\n",
      "Train: global step = 3000; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9965\n",
      "    -                  end loss: 3.9445\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 1.9823\n",
      "    -         history_span loss: 9.0566\n",
      "    -      history_passage loss: 1.9821\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0162\n",
      "    -             emb_val other: 0.27621496\n",
      "    -         eff_perturb other: 0.00000196\n",
      "\n",
      "Validation: Epoch: 0 Step: 3000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.29\n",
      "Eval step 200 / 993; eval time per batch = 0.30\n",
      "Eval step 300 / 993; eval time per batch = 0.30\n",
      "Eval step 400 / 993; eval time per batch = 0.30\n",
      "Eval step 500 / 993; eval time per batch = 0.28\n",
      "Eval step 600 / 993; eval time per batch = 0.26\n",
      "Eval step 700 / 993; eval time per batch = 0.25\n",
      "Eval step 800 / 993; eval time per batch = 0.25\n",
      "Eval step 900 / 993; eval time per batch = 0.25\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.10000.5000\n",
      "Best F1 14.25 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6002.3001\n",
      "Epoch: 0: Step: 3100/9807; Global_step=3100; lr=2.968e-05; train time per batch = 1.73\n",
      "Train: global step = 3100; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9523\n",
      "    -                 span loss: 7.9439\n",
      "    -              passage loss: 1.9851\n",
      "    -         history_span loss: 9.0005\n",
      "    -      history_passage loss: 2.0052\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9884\n",
      "    -             emb_val other: 0.27595016\n",
      "    -         eff_perturb other: 0.00000116\n",
      "\n",
      "Epoch: 0: Step: 3200/9807; Global_step=3200; lr=2.966e-05; train time per batch = 1.73\n",
      "Train: global step = 3200; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0001\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9527\n",
      "    -              passage loss: 2.0043\n",
      "    -         history_span loss: 8.8555\n",
      "    -      history_passage loss: 2.0132\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8794\n",
      "    -             emb_val other: 0.27658123\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6410.3205\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb88c4",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a45e43e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   ./dialdoc/exp/dialki.0.820.410\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files ./dialdoc/exp/dialki.0.820.410\n",
      "Reading saved model from ./dialdoc/exp/dialki.0.820.410\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Loading checkpoint @epoch = 0, offset = 820, global_step = 410, \n",
      "Loading model weights from saved state ...\n",
      "Loading saved optimizer state ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "Loading scheduler state ...\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 820\n",
      "Updated step of the epoch 0 (dataloader) = step 410\n",
      "Total remaining updates = 195730.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.497e-05; train time per batch = 1.71\n",
      "Train: global step = 510; step = 510\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9925\n",
      "    -                  end loss: 3.9538\n",
      "    -                 span loss: 7.9463\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 8.8631\n",
      "    -      history_passage loss: 2.0024\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8753\n",
      "    -             emb_val other: 0.27677786\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.797e-05; train time per batch = 1.72\n",
      "Train: global step = 610; step = 610\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0025\n",
      "    -                  end loss: 3.9555\n",
      "    -                 span loss: 7.9580\n",
      "    -              passage loss: 2.0181\n",
      "    -         history_span loss: 8.7523\n",
      "    -      history_passage loss: 2.0215\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0059\n",
      "    -                total loss: 20.8106\n",
      "    -             emb_val other: 0.27599204\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1222.611\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.097e-05; train time per batch = 1.71\n",
      "Train: global step = 710; step = 710\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9530\n",
      "    -                 span loss: 7.9498\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 9.0822\n",
      "    -      history_passage loss: 1.9967\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0898\n",
      "    -             emb_val other: 0.27517644\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.397e-05; train time per batch = 1.70\n",
      "Train: global step = 810; step = 810\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9979\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9500\n",
      "    -              passage loss: 1.9837\n",
      "    -         history_span loss: 9.0603\n",
      "    -      history_passage loss: 1.9724\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.0194\n",
      "    -             emb_val other: 0.27594420\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1628.814\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.697e-05; train time per batch = 1.70\n",
      "Train: global step = 910; step = 910\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0115\n",
      "    -                  end loss: 3.9449\n",
      "    -                 span loss: 7.9564\n",
      "    -              passage loss: 2.0038\n",
      "    -         history_span loss: 8.9229\n",
      "    -      history_passage loss: 2.0039\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9404\n",
      "    -             emb_val other: 0.27564102\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=2.997e-05; train time per batch = 1.70\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.29\n",
      "Eval step 200 / 993; eval time per batch = 0.29\n",
      "Eval step 300 / 993; eval time per batch = 0.30\n",
      "Eval step 400 / 993; eval time per batch = 0.30\n",
      "Eval step 500 / 993; eval time per batch = 0.28\n",
      "Eval step 600 / 993; eval time per batch = 0.26\n",
      "Eval step 700 / 993; eval time per batch = 0.25\n",
      "Eval step 800 / 993; eval time per batch = 0.25\n",
      "Eval step 900 / 993; eval time per batch = 0.25\n",
      "eval_top_docs = 20\n",
      "F1 = 14.25\n",
      "Passage@1 = 16.26; Passage@2 = 33.70; Passage@3 = 45.92; \n",
      "Rank 1 passage: EM@1 = 1.59; EM@2 = 2.69; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.05; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.57; EM@3 = 3.52; \n",
      "\n",
      "New best EM 1.59 on dev\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2000.1000\n",
      "New best F1 14.25 on dev\n",
      "Curr EM 1.59\n",
      "Curr F1 14.25\n",
      "Best EM 1.59 path = dialki.0.2000.1000\n",
      "Best F1 14.25 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2002.1001\n",
      "Train: global step = 1010; step = 1010\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9994\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9557\n",
      "    -              passage loss: 2.0058\n",
      "    -         history_span loss: 9.3074\n",
      "    -      history_passage loss: 1.9973\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.3206\n",
      "    -             emb_val other: 0.27413410\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.998e-05; train time per batch = 1.70\n",
      "Train: global step = 1110; step = 1110\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9903\n",
      "    -                  end loss: 3.9613\n",
      "    -                 span loss: 7.9516\n",
      "    -              passage loss: 1.9925\n",
      "    -         history_span loss: 8.9470\n",
      "    -      history_passage loss: 1.9948\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9415\n",
      "    -             emb_val other: 0.27563789\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.997e-05; train time per batch = 1.70\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2404.1202\n",
      "Train: global step = 1210; step = 1210\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9523\n",
      "    -                 span loss: 7.9554\n",
      "    -              passage loss: 1.9884\n",
      "    -         history_span loss: 9.0337\n",
      "    -      history_passage loss: 1.9787\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 21.0080\n",
      "    -             emb_val other: 0.27531463\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aee1dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#torch.device(\"cuda:0\")\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4b1bc",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a9fd429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.52\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "^C\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 28335 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reader_longformer.py\", line 969, in <module>\n",
      "    main()\n",
      "  File \"train_reader_longformer.py\", line 958, in main\n",
      "    trainer.run_train()\n",
      "  File \"train_reader_longformer.py\", line 307, in run_train\n",
      "    self._train_epoch(epoch, train_dataloader)\n",
      "  File \"train_reader_longformer.py\", line 584, in _train_epoch\n",
      "    gc.collect()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca724d",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e76d6f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.52\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.51\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.430.215\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.50\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.50\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.866.433\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.50\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.50\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9485\n",
      "    -                 span loss: 7.9449\n",
      "    -              passage loss: 2.0085\n",
      "    -         history_span loss: 9.0040\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0251\n",
      "    -             emb_val other: 0.27603605\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1302.651\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.49\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1738.869\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.49\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=3.000e-05; train time per batch = 1.49\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "New best EM 1.64 on dev\n",
      "New best F1 14.27 on dev\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2054.1027\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.998e-05; train time per batch = 1.49\n",
      "Train: global step = 1100; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9966\n",
      "    -                  end loss: 3.9467\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9663\n",
      "    -         history_span loss: 8.8642\n",
      "    -      history_passage loss: 1.9765\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8058\n",
      "    -             emb_val other: 0.27565560\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.997e-05; train time per batch = 1.48\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9398\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 9.0099\n",
      "    -      history_passage loss: 1.9759\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9501\n",
      "    -             emb_val other: 0.27486575\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2488.1244\n",
      "Epoch: 0: Step: 1300/9807; Global_step=1300; lr=2.995e-05; train time per batch = 1.48\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9893\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 9.1465\n",
      "    -      history_passage loss: 1.9884\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1118\n",
      "    -             emb_val other: 0.27678522\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 0: Step: 1400/9807; Global_step=1400; lr=2.994e-05; train time per batch = 1.48\n",
      "Train: global step = 1400; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9559\n",
      "    -              passage loss: 2.0031\n",
      "    -         history_span loss: 8.8815\n",
      "    -      history_passage loss: 1.9935\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8926\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2914.1457\n",
      "Epoch: 0: Step: 1500/9807; Global_step=1500; lr=2.992e-05; train time per batch = 1.48\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9631\n",
      "    -                 span loss: 7.9515\n",
      "    -              passage loss: 1.9745\n",
      "    -         history_span loss: 8.9667\n",
      "    -      history_passage loss: 1.9744\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27560320\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 0: Step: 1600/9807; Global_step=1600; lr=2.991e-05; train time per batch = 1.48\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9380\n",
      "    -             emb_val other: 0.27449915\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3344.1672\n",
      "Epoch: 0: Step: 1700/9807; Global_step=1700; lr=2.989e-05; train time per batch = 1.48\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9833\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 2.0281\n",
      "    -         history_span loss: 8.8943\n",
      "    -      history_passage loss: 2.0275\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9579\n",
      "    -             emb_val other: 0.27573657\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 1800/9807; Global_step=1800; lr=2.988e-05; train time per batch = 1.48\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0051\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9573\n",
      "    -              passage loss: 2.0185\n",
      "    -         history_span loss: 9.1309\n",
      "    -      history_passage loss: 1.9999\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1602\n",
      "    -             emb_val other: 0.27481243\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3770.1885\n",
      "Epoch: 0: Step: 1900/9807; Global_step=1900; lr=2.986e-05; train time per batch = 1.48\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9947\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9821\n",
      "    -         history_span loss: 8.9765\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9583\n",
      "    -             emb_val other: 0.27541786\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 0: Step: 2000/9807; Global_step=2000; lr=2.985e-05; train time per batch = 1.48\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9504\n",
      "    -              passage loss: 2.0042\n",
      "    -         history_span loss: 9.1781\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1936\n",
      "    -             emb_val other: 0.27660093\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4086.2043\n",
      "Epoch: 0: Step: 2100/9807; Global_step=2100; lr=2.983e-05; train time per batch = 1.48\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.8982\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9148\n",
      "    -             emb_val other: 0.27517632\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 0: Step: 2200/9807; Global_step=2200; lr=2.982e-05; train time per batch = 1.48\n",
      "Train: global step = 2200; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 1.9627\n",
      "    -         history_span loss: 9.1273\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0661\n",
      "    -             emb_val other: 0.27609926\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4514.2257\n",
      "Epoch: 0: Step: 2300/9807; Global_step=2300; lr=2.980e-05; train time per batch = 1.48\n",
      "Train: global step = 2300; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9649\n",
      "    -                 span loss: 7.9566\n",
      "    -              passage loss: 1.9820\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9759\n",
      "    -             emb_val other: 0.27716950\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 2400/9807; Global_step=2400; lr=2.978e-05; train time per batch = 1.48\n",
      "Train: global step = 2400; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 8.8510\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7985\n",
      "    -             emb_val other: 0.27587956\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4948.2474\n",
      "Epoch: 0: Step: 2500/9807; Global_step=2500; lr=2.977e-05; train time per batch = 1.48\n",
      "Train: global step = 2500; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0134\n",
      "    -         history_span loss: 9.0348\n",
      "    -      history_passage loss: 2.0062\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0602\n",
      "    -             emb_val other: 0.27547652\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Epoch: 0: Step: 2600/9807; Global_step=2600; lr=2.975e-05; train time per batch = 1.48\n",
      "Train: global step = 2600; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9932\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9891\n",
      "    -         history_span loss: 9.4932\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4753\n",
      "    -             emb_val other: 0.27565563\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5380.2690\n",
      "Epoch: 0: Step: 2700/9807; Global_step=2700; lr=2.974e-05; train time per batch = 1.48\n",
      "Train: global step = 2700; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9389\n",
      "    -              passage loss: 2.0001\n",
      "    -         history_span loss: 9.0556\n",
      "    -      history_passage loss: 2.0041\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0514\n",
      "    -             emb_val other: 0.27616084\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 0: Step: 2800/9807; Global_step=2800; lr=2.972e-05; train time per batch = 1.48\n",
      "Train: global step = 2800; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0017\n",
      "    -                  end loss: 3.9473\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 9.0647\n",
      "    -      history_passage loss: 2.0273\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1264\n",
      "    -             emb_val other: 0.27552190\n",
      "    -         eff_perturb other: 0.00000165\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5800.2900\n",
      "Epoch: 0: Step: 2900/9807; Global_step=2900; lr=2.971e-05; train time per batch = 1.48\n",
      "Train: global step = 2900; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9992\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9593\n",
      "    -              passage loss: 2.0177\n",
      "    -         history_span loss: 8.7420\n",
      "    -      history_passage loss: 2.0118\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7847\n",
      "    -             emb_val other: 0.27503952\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 0: Step: 3000/9807; Global_step=3000; lr=2.969e-05; train time per batch = 1.48\n",
      "Train: global step = 3000; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9958\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 2.0304\n",
      "    -         history_span loss: 9.3055\n",
      "    -      history_passage loss: 2.0239\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.3652\n",
      "    -             emb_val other: 0.27447194\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Validation: Epoch: 0 Step: 3000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6108.3054\n",
      "Epoch: 0: Step: 3100/9807; Global_step=3100; lr=2.968e-05; train time per batch = 1.48\n",
      "Train: global step = 3100; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 1.9869\n",
      "    -         history_span loss: 8.9978\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9847\n",
      "    -             emb_val other: 0.27495521\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 3200/9807; Global_step=3200; lr=2.966e-05; train time per batch = 1.48\n",
      "Train: global step = 3200; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9674\n",
      "    -                 span loss: 7.9642\n",
      "    -              passage loss: 1.9887\n",
      "    -         history_span loss: 9.2446\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2444\n",
      "    -             emb_val other: 0.27625531\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6522.3261\n",
      "Epoch: 0: Step: 3300/9807; Global_step=3300; lr=2.965e-05; train time per batch = 1.48\n",
      "Train: global step = 3300; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9840\n",
      "    -                  end loss: 3.9533\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9677\n",
      "    -         history_span loss: 8.9238\n",
      "    -      history_passage loss: 1.9604\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8442\n",
      "    -             emb_val other: 0.27471855\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 0: Step: 3400/9807; Global_step=3400; lr=2.963e-05; train time per batch = 1.48\n",
      "Train: global step = 3400; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9465\n",
      "    -              passage loss: 2.0172\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0076\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0573\n",
      "    -             emb_val other: 0.27665561\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6940.3470\n",
      "Epoch: 0: Step: 3500/9807; Global_step=3500; lr=2.962e-05; train time per batch = 1.48\n",
      "Train: global step = 3500; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9990\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.8350\n",
      "    -      history_passage loss: 1.9761\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7858\n",
      "    -             emb_val other: 0.27657977\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 3600/9807; Global_step=3600; lr=2.960e-05; train time per batch = 1.48\n",
      "Train: global step = 3600; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9547\n",
      "    -              passage loss: 1.9921\n",
      "    -         history_span loss: 9.0610\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0550\n",
      "    -             emb_val other: 0.27563903\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7340.3670\n",
      "Epoch: 0: Step: 3700/9807; Global_step=3700; lr=2.958e-05; train time per batch = 1.48\n",
      "Train: global step = 3700; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9919\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9424\n",
      "    -              passage loss: 1.9793\n",
      "    -         history_span loss: 9.1845\n",
      "    -      history_passage loss: 1.9659\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1248\n",
      "    -             emb_val other: 0.27591288\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 0: Step: 3800/9807; Global_step=3800; lr=2.957e-05; train time per batch = 1.48\n",
      "Train: global step = 3800; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9619\n",
      "    -              passage loss: 2.0212\n",
      "    -         history_span loss: 9.0758\n",
      "    -      history_passage loss: 2.0128\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1252\n",
      "    -             emb_val other: 0.27534035\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7748.3874\n",
      "Epoch: 0: Step: 3900/9807; Global_step=3900; lr=2.955e-05; train time per batch = 1.48\n",
      "Train: global step = 3900; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9317\n",
      "    -              passage loss: 1.9946\n",
      "    -         history_span loss: 9.1520\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1251\n",
      "    -             emb_val other: 0.27604371\n",
      "    -         eff_perturb other: 0.00000214\n",
      "\n",
      "Epoch: 0: Step: 4000/9807; Global_step=4000; lr=2.954e-05; train time per batch = 1.48\n",
      "Train: global step = 4000; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9801\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.9339\n",
      "    -      history_passage loss: 2.0019\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9427\n",
      "    -             emb_val other: 0.27633986\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Validation: Epoch: 0 Step: 4000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8050.4025\n",
      "Epoch: 0: Step: 4100/9807; Global_step=4100; lr=2.952e-05; train time per batch = 1.48\n",
      "Train: global step = 4100; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0003\n",
      "    -                  end loss: 3.9589\n",
      "    -                 span loss: 7.9592\n",
      "    -              passage loss: 2.0324\n",
      "    -         history_span loss: 8.7146\n",
      "    -      history_passage loss: 2.0309\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7907\n",
      "    -             emb_val other: 0.27648199\n",
      "    -         eff_perturb other: 0.00000116\n",
      "\n",
      "Epoch: 0: Step: 4200/9807; Global_step=4200; lr=2.951e-05; train time per batch = 1.48\n",
      "Train: global step = 4200; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9418\n",
      "    -              passage loss: 1.9919\n",
      "    -         history_span loss: 9.0778\n",
      "    -      history_passage loss: 2.0034\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0680\n",
      "    -             emb_val other: 0.27577877\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8464.4232\n",
      "Epoch: 0: Step: 4300/9807; Global_step=4300; lr=2.949e-05; train time per batch = 1.48\n",
      "Train: global step = 4300; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9517\n",
      "    -              passage loss: 2.0130\n",
      "    -         history_span loss: 8.9824\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0011\n",
      "    -             emb_val other: 0.27624288\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 4400/9807; Global_step=4400; lr=2.948e-05; train time per batch = 1.48\n",
      "Train: global step = 4400; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0000\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0291\n",
      "    -      history_passage loss: 2.0129\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0644\n",
      "    -             emb_val other: 0.27622613\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8870.4435\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reader_longformer.py\", line 969, in <module>\n",
      "    main()\n",
      "  File \"train_reader_longformer.py\", line 958, in main\n",
      "    trainer.run_train()\n",
      "  File \"train_reader_longformer.py\", line 307, in run_train\n",
      "    self._train_epoch(epoch, train_dataloader)\n",
      "  File \"train_reader_longformer.py\", line 542, in _train_epoch\n",
      "    losses, others = self._training_step(batch)\n",
      "  File \"train_reader_longformer.py\", line 843, in _training_step\n",
      "    logits, others = self.reader(batch, self.global_step)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 254, in forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 267, in adv_forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_teacher.forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/perturbation.py\", line 64, in forward\n",
      "    adv_logits, _ = model(batch, global_step, fwd_type='inputs_embeds', inputs_embeds=embed+noise, end_task_only=True)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 183, in forward\n",
      "    sequence_output, _pooled_output, _hidden_states = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/dialki/DIALKI/models/hf_models_longformer.py\", line 109, in forward\n",
      "    sequence_output, pooled_output = super().forward(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1703, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1285, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1209, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1145, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 643, in forward\n",
      "    attn_probs = attn_probs.type_as(attn_scores)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 31.72 GiB total capacity; 18.22 GiB already allocated; 29.88 MiB free; 18.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 28511) of binary: /opt/conda/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 723, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 719, in main\n",
      "    run(args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 710, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_reader_longformer.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2022-06-05_06:45:58\n",
      "  host      : wawat\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 28511)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f6e94",
   "metadata": {},
   "source": [
    "Mengecek nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4816d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc\r\n"
     ]
    }
   ],
   "source": [
    "!activate dialki\n",
    "\n",
    "torch.version.cuda\n",
    "!which nvcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70351b01",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb3d0ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   ./dialdoc/exp/dialki.0.8870.4435\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files ./dialdoc/exp/dialki.0.8870.4435\n",
      "Reading saved model from ./dialdoc/exp/dialki.0.8870.4435\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Loading checkpoint @epoch = 0, offset = 8870, global_step = 4435, \n",
      "Loading model weights from saved state ...\n",
      "Loading saved optimizer state ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "Loading scheduler state ...\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 8870\n",
      "Updated step of the epoch 0 (dataloader) = step 4435\n",
      "Total remaining updates = 191705.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 65/9807; Global_step=4500; lr=2.946e-05; train time per batch = 1.66\n",
      "Train: global step = 4535; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.274.4572\n",
      "Epoch: 0: Step: 165/9807; Global_step=4600; lr=2.945e-05; train time per batch = 1.78\n",
      "Train: global step = 4635; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 0: Step: 265/9807; Global_step=4700; lr=2.943e-05; train time per batch = 1.70\n",
      "Train: global step = 4735; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.648.4759\n",
      "Epoch: 0: Step: 365/9807; Global_step=4800; lr=2.942e-05; train time per batch = 1.63\n",
      "Train: global step = 4835; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 465/9807; Global_step=4900; lr=2.940e-05; train time per batch = 1.61\n",
      "Train: global step = 4935; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1062.4966\n",
      "Epoch: 0: Step: 565/9807; Global_step=5000; lr=2.939e-05; train time per batch = 1.61\n",
      "Validation: Epoch: 0 Step: 565/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.28\n",
      "Eval step 200 / 993; eval time per batch = 0.29\n",
      "Eval step 300 / 993; eval time per batch = 0.29\n",
      "Eval step 400 / 993; eval time per batch = 0.29\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.25\n",
      "Eval step 700 / 993; eval time per batch = 0.24\n",
      "Eval step 800 / 993; eval time per batch = 0.24\n",
      "Eval step 900 / 993; eval time per batch = 0.24\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.1130.5000\n",
      "Best F1 14.27 path = dialki.0.1130.5000\n",
      "Train: global step = 5035; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9485\n",
      "    -                 span loss: 7.9449\n",
      "    -              passage loss: 2.0085\n",
      "    -         history_span loss: 9.0040\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0251\n",
      "    -             emb_val other: 0.27603605\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 665/9807; Global_step=5100; lr=2.937e-05; train time per batch = 1.59\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1346.5108\n",
      "Train: global step = 5135; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9981\n",
      "    -                  end loss: 3.9470\n",
      "    -                 span loss: 7.9450\n",
      "    -              passage loss: 1.9715\n",
      "    -         history_span loss: 9.0247\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9632\n",
      "    -             emb_val other: 0.27524096\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 765/9807; Global_step=5200; lr=2.935e-05; train time per batch = 1.57\n",
      "Train: global step = 5235; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 865/9807; Global_step=5300; lr=2.934e-05; train time per batch = 1.56\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1786.5328\n",
      "Train: global step = 5335; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 965/9807; Global_step=5400; lr=2.932e-05; train time per batch = 1.55\n",
      "Train: global step = 5435; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 1065/9807; Global_step=5500; lr=2.931e-05; train time per batch = 1.55\n",
      "Train: global step = 5535; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9966\n",
      "    -                  end loss: 3.9467\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9663\n",
      "    -         history_span loss: 8.8642\n",
      "    -      history_passage loss: 1.9765\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8058\n",
      "    -             emb_val other: 0.27565560\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2224.5547\n",
      "Epoch: 0: Step: 1165/9807; Global_step=5600; lr=2.929e-05; train time per batch = 1.54\n",
      "Train: global step = 5635; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9398\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 9.0099\n",
      "    -      history_passage loss: 1.9759\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9501\n",
      "    -             emb_val other: 0.27486575\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 1265/9807; Global_step=5700; lr=2.928e-05; train time per batch = 1.54\n",
      "Train: global step = 5735; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9893\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 9.1465\n",
      "    -      history_passage loss: 1.9884\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1118\n",
      "    -             emb_val other: 0.27678522\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2670.5770\n",
      "Epoch: 0: Step: 1365/9807; Global_step=5800; lr=2.926e-05; train time per batch = 1.53\n",
      "Train: global step = 5835; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9559\n",
      "    -              passage loss: 2.0031\n",
      "    -         history_span loss: 8.8815\n",
      "    -      history_passage loss: 1.9935\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8926\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 1465/9807; Global_step=5900; lr=2.925e-05; train time per batch = 1.53\n",
      "Train: global step = 5935; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9631\n",
      "    -                 span loss: 7.9515\n",
      "    -              passage loss: 1.9745\n",
      "    -         history_span loss: 8.9667\n",
      "    -      history_passage loss: 1.9744\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27560320\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3048.5959\n",
      "Epoch: 0: Step: 1565/9807; Global_step=6000; lr=2.923e-05; train time per batch = 1.53\n",
      "Validation: Epoch: 0 Step: 1565/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.1130.5000\n",
      "Best F1 14.27 path = dialki.0.1130.5000\n",
      "Train: global step = 6035; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9380\n",
      "    -             emb_val other: 0.27449915\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3310.6090\n",
      "Epoch: 0: Step: 1665/9807; Global_step=6100; lr=2.922e-05; train time per batch = 1.54\n",
      "Train: global step = 6135; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9833\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 2.0281\n",
      "    -         history_span loss: 8.8943\n",
      "    -      history_passage loss: 2.0275\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9579\n",
      "    -             emb_val other: 0.27573657\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 1765/9807; Global_step=6200; lr=2.920e-05; train time per batch = 1.54\n",
      "Train: global step = 6235; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0051\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9573\n",
      "    -              passage loss: 2.0185\n",
      "    -         history_span loss: 9.1309\n",
      "    -      history_passage loss: 1.9999\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1602\n",
      "    -             emb_val other: 0.27481243\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 1865/9807; Global_step=6300; lr=2.919e-05; train time per batch = 1.53\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3734.6302\n",
      "Train: global step = 6335; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9947\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9821\n",
      "    -         history_span loss: 8.9765\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9583\n",
      "    -             emb_val other: 0.27541786\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 0: Step: 1965/9807; Global_step=6400; lr=2.917e-05; train time per batch = 1.53\n",
      "Train: global step = 6435; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9504\n",
      "    -              passage loss: 2.0042\n",
      "    -         history_span loss: 9.1781\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1936\n",
      "    -             emb_val other: 0.27660093\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 0: Step: 2065/9807; Global_step=6500; lr=2.915e-05; train time per batch = 1.53\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4170.6520\n",
      "Train: global step = 6535; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.8982\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9148\n",
      "    -             emb_val other: 0.27517632\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 0: Step: 2165/9807; Global_step=6600; lr=2.914e-05; train time per batch = 1.53\n",
      "Train: global step = 6635; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 1.9627\n",
      "    -         history_span loss: 9.1273\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0661\n",
      "    -             emb_val other: 0.27609926\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Epoch: 0: Step: 2265/9807; Global_step=6700; lr=2.912e-05; train time per batch = 1.52\n",
      "Train: global step = 6735; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9649\n",
      "    -                 span loss: 7.9566\n",
      "    -              passage loss: 1.9820\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9759\n",
      "    -             emb_val other: 0.27716950\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4602.6736\n",
      "Epoch: 0: Step: 2365/9807; Global_step=6800; lr=2.911e-05; train time per batch = 1.52\n",
      "Train: global step = 6835; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 8.8510\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7985\n",
      "    -             emb_val other: 0.27587956\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 0: Step: 2465/9807; Global_step=6900; lr=2.909e-05; train time per batch = 1.52\n",
      "Train: global step = 6935; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0134\n",
      "    -         history_span loss: 9.0348\n",
      "    -      history_passage loss: 2.0062\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0602\n",
      "    -             emb_val other: 0.27547652\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5034.6952\n",
      "Epoch: 0: Step: 2565/9807; Global_step=7000; lr=2.908e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 0 Step: 2565/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.1130.5000\n",
      "Best F1 14.27 path = dialki.0.1130.5000\n",
      "Train: global step = 7035; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9932\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9891\n",
      "    -         history_span loss: 9.4932\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4753\n",
      "    -             emb_val other: 0.27565563\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 2665/9807; Global_step=7100; lr=2.906e-05; train time per batch = 1.52\n",
      "^C\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 28684 closing signal SIGINT\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0317c",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec9385d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.55\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.54\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.580.290\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.53\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.52\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.51\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1170.585\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.51\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9485\n",
      "    -                 span loss: 7.9449\n",
      "    -              passage loss: 2.0085\n",
      "    -         history_span loss: 9.0040\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0251\n",
      "    -             emb_val other: 0.27603605\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.100e-05; train time per batch = 1.50\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9981\n",
      "    -                  end loss: 3.9470\n",
      "    -                 span loss: 7.9450\n",
      "    -              passage loss: 1.9715\n",
      "    -         history_span loss: 9.0247\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9632\n",
      "    -             emb_val other: 0.27524096\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.50\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1720.860\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.50\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=3.000e-05; train time per batch = 1.52\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.28\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.25\n",
      "Eval step 700 / 993; eval time per batch = 0.24\n",
      "Eval step 800 / 993; eval time per batch = 0.24\n",
      "Eval step 900 / 993; eval time per batch = 0.24\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "^C\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 30204 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reader_longformer.py\", line 969, in <module>\n",
      "    main()\n",
      "  File \"train_reader_longformer.py\", line 958, in main\n",
      "    trainer.run_train()\n",
      "  File \"train_reader_longformer.py\", line 307, in run_train\n",
      "    self._train_epoch(epoch, train_dataloader)\n",
      "  File \"train_reader_longformer.py\", line 542, in _train_epoch\n",
      "    losses, others = self._training_step(batch)\n",
      "  File \"train_reader_longformer.py\", line 843, in _training_step\n",
      "    logits, others = self.reader(batch, self.global_step)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 254, in forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 267, in adv_forward\n",
      "    adv_logits, emb_val, eff_perturb = self.adv_teacher.forward(\n",
      "  File \"/workspace/dialki/DIALKI/models/perturbation.py\", line 64, in forward\n",
      "    adv_logits, _ = model(batch, global_step, fwd_type='inputs_embeds', inputs_embeds=embed+noise, end_task_only=True)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/apex/amp/_initialize.py\", line 196, in new_fwd\n",
      "    output = old_fwd(*applier(args, input_caster),\n",
      "  File \"/workspace/dialki/DIALKI/models/reader.py\", line 183, in forward\n",
      "    sequence_output, _pooled_output, _hidden_states = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/dialki/DIALKI/models/hf_models_longformer.py\", line 109, in forward\n",
      "    sequence_output, pooled_output = super().forward(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1703, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1285, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1209, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1145, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 665, in forward\n",
      "    attn_output = self._sliding_chunks_matmul_attn_probs_value(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 900, in _sliding_chunks_matmul_attn_probs_value\n",
      "    chunked_attn_probs = self._pad_and_diagonalize(chunked_attn_probs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py\", line 751, in _pad_and_diagonalize\n",
      "    chunked_hidden_states = nn.functional.pad(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 4174, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28dd49",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f35b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196140.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.51\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.50\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.570.285\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.51\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.51\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.51\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1152.576\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.51\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9485\n",
      "    -                 span loss: 7.9449\n",
      "    -              passage loss: 2.0085\n",
      "    -         history_span loss: 9.0040\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0251\n",
      "    -             emb_val other: 0.27603605\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.100e-05; train time per batch = 1.50\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9981\n",
      "    -                  end loss: 3.9470\n",
      "    -                 span loss: 7.9450\n",
      "    -              passage loss: 1.9715\n",
      "    -         history_span loss: 9.0247\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9632\n",
      "    -             emb_val other: 0.27524096\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.49\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1752.876\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.49\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=3.000e-05; train time per batch = 1.49\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2178.1089\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.998e-05; train time per batch = 1.49\n",
      "Train: global step = 1100; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9966\n",
      "    -                  end loss: 3.9467\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9663\n",
      "    -         history_span loss: 8.8642\n",
      "    -      history_passage loss: 1.9765\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8058\n",
      "    -             emb_val other: 0.27565560\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.997e-05; train time per batch = 1.49\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9398\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 9.0099\n",
      "    -      history_passage loss: 1.9759\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9501\n",
      "    -             emb_val other: 0.27486575\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 1300/9807; Global_step=1300; lr=2.995e-05; train time per batch = 1.49\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9893\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 9.1465\n",
      "    -      history_passage loss: 1.9884\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1118\n",
      "    -             emb_val other: 0.27678522\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2774.1387\n",
      "Epoch: 0: Step: 1400/9807; Global_step=1400; lr=2.994e-05; train time per batch = 1.49\n",
      "Train: global step = 1400; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9559\n",
      "    -              passage loss: 2.0031\n",
      "    -         history_span loss: 8.8815\n",
      "    -      history_passage loss: 1.9935\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8926\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 1500/9807; Global_step=1500; lr=2.992e-05; train time per batch = 1.49\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9631\n",
      "    -                 span loss: 7.9515\n",
      "    -              passage loss: 1.9745\n",
      "    -         history_span loss: 8.9667\n",
      "    -      history_passage loss: 1.9744\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27560320\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 0: Step: 1600/9807; Global_step=1600; lr=2.991e-05; train time per batch = 1.49\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9380\n",
      "    -             emb_val other: 0.27449915\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3360.1680\n",
      "Epoch: 0: Step: 1700/9807; Global_step=1700; lr=2.989e-05; train time per batch = 1.49\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9833\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 2.0281\n",
      "    -         history_span loss: 8.8943\n",
      "    -      history_passage loss: 2.0275\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9579\n",
      "    -             emb_val other: 0.27573657\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 1800/9807; Global_step=1800; lr=2.988e-05; train time per batch = 1.49\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0051\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9573\n",
      "    -              passage loss: 2.0185\n",
      "    -         history_span loss: 9.1309\n",
      "    -      history_passage loss: 1.9999\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1602\n",
      "    -             emb_val other: 0.27481243\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 1900/9807; Global_step=1900; lr=2.986e-05; train time per batch = 1.49\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9947\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9821\n",
      "    -         history_span loss: 8.9765\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9583\n",
      "    -             emb_val other: 0.27541786\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3942.1971\n",
      "Epoch: 0: Step: 2000/9807; Global_step=2000; lr=2.985e-05; train time per batch = 1.49\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9504\n",
      "    -              passage loss: 2.0042\n",
      "    -         history_span loss: 9.1781\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1936\n",
      "    -             emb_val other: 0.27660093\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 2100/9807; Global_step=2100; lr=2.983e-05; train time per batch = 1.49\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.8982\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9148\n",
      "    -             emb_val other: 0.27517632\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4370.2185\n",
      "Epoch: 0: Step: 2200/9807; Global_step=2200; lr=2.982e-05; train time per batch = 1.48\n",
      "Train: global step = 2200; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 1.9627\n",
      "    -         history_span loss: 9.1273\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0661\n",
      "    -             emb_val other: 0.27609926\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Epoch: 0: Step: 2300/9807; Global_step=2300; lr=2.980e-05; train time per batch = 1.48\n",
      "Train: global step = 2300; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9649\n",
      "    -                 span loss: 7.9566\n",
      "    -              passage loss: 1.9820\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9759\n",
      "    -             emb_val other: 0.27716950\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 2400/9807; Global_step=2400; lr=2.978e-05; train time per batch = 1.48\n",
      "Train: global step = 2400; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 8.8510\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7985\n",
      "    -             emb_val other: 0.27587956\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4956.2478\n",
      "Epoch: 0: Step: 2500/9807; Global_step=2500; lr=2.977e-05; train time per batch = 1.48\n",
      "Train: global step = 2500; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0134\n",
      "    -         history_span loss: 9.0348\n",
      "    -      history_passage loss: 2.0062\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0602\n",
      "    -             emb_val other: 0.27547652\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Epoch: 0: Step: 2600/9807; Global_step=2600; lr=2.975e-05; train time per batch = 1.48\n",
      "Train: global step = 2600; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9932\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9891\n",
      "    -         history_span loss: 9.4932\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4753\n",
      "    -             emb_val other: 0.27565563\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 2700/9807; Global_step=2700; lr=2.974e-05; train time per batch = 1.48\n",
      "Train: global step = 2700; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9389\n",
      "    -              passage loss: 2.0001\n",
      "    -         history_span loss: 9.0556\n",
      "    -      history_passage loss: 2.0041\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0514\n",
      "    -             emb_val other: 0.27616084\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5538.2769\n",
      "Epoch: 0: Step: 2800/9807; Global_step=2800; lr=2.972e-05; train time per batch = 1.48\n",
      "Train: global step = 2800; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0017\n",
      "    -                  end loss: 3.9473\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 9.0647\n",
      "    -      history_passage loss: 2.0273\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1264\n",
      "    -             emb_val other: 0.27552190\n",
      "    -         eff_perturb other: 0.00000165\n",
      "\n",
      "Epoch: 0: Step: 2900/9807; Global_step=2900; lr=2.971e-05; train time per batch = 1.48\n",
      "Train: global step = 2900; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9992\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9593\n",
      "    -              passage loss: 2.0177\n",
      "    -         history_span loss: 8.7420\n",
      "    -      history_passage loss: 2.0118\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7847\n",
      "    -             emb_val other: 0.27503952\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 0: Step: 3000/9807; Global_step=3000; lr=2.969e-05; train time per batch = 1.48\n",
      "Train: global step = 3000; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9958\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 2.0304\n",
      "    -         history_span loss: 9.3055\n",
      "    -      history_passage loss: 2.0239\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.3652\n",
      "    -             emb_val other: 0.27447194\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Validation: Epoch: 0 Step: 3000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6002.3001\n",
      "Epoch: 0: Step: 3100/9807; Global_step=3100; lr=2.968e-05; train time per batch = 1.48\n",
      "Train: global step = 3100; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 1.9869\n",
      "    -         history_span loss: 8.9978\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9847\n",
      "    -             emb_val other: 0.27495521\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 3200/9807; Global_step=3200; lr=2.966e-05; train time per batch = 1.48\n",
      "Train: global step = 3200; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9674\n",
      "    -                 span loss: 7.9642\n",
      "    -              passage loss: 1.9887\n",
      "    -         history_span loss: 9.2446\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2444\n",
      "    -             emb_val other: 0.27625531\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6592.3296\n",
      "Epoch: 0: Step: 3300/9807; Global_step=3300; lr=2.965e-05; train time per batch = 1.48\n",
      "Train: global step = 3300; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9840\n",
      "    -                  end loss: 3.9533\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9677\n",
      "    -         history_span loss: 8.9238\n",
      "    -      history_passage loss: 1.9604\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8442\n",
      "    -             emb_val other: 0.27471855\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 0: Step: 3400/9807; Global_step=3400; lr=2.963e-05; train time per batch = 1.48\n",
      "Train: global step = 3400; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9465\n",
      "    -              passage loss: 2.0172\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0076\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0573\n",
      "    -             emb_val other: 0.27665561\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 0: Step: 3500/9807; Global_step=3500; lr=2.962e-05; train time per batch = 1.48\n",
      "Train: global step = 3500; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9990\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.8350\n",
      "    -      history_passage loss: 1.9761\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7858\n",
      "    -             emb_val other: 0.27657977\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7184.3592\n",
      "Epoch: 0: Step: 3600/9807; Global_step=3600; lr=2.960e-05; train time per batch = 1.48\n",
      "Train: global step = 3600; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9547\n",
      "    -              passage loss: 1.9921\n",
      "    -         history_span loss: 9.0610\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0550\n",
      "    -             emb_val other: 0.27563903\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Epoch: 0: Step: 3700/9807; Global_step=3700; lr=2.958e-05; train time per batch = 1.48\n",
      "Train: global step = 3700; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9919\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9424\n",
      "    -              passage loss: 1.9793\n",
      "    -         history_span loss: 9.1845\n",
      "    -      history_passage loss: 1.9659\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1248\n",
      "    -             emb_val other: 0.27591288\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 0: Step: 3800/9807; Global_step=3800; lr=2.957e-05; train time per batch = 1.48\n",
      "Train: global step = 3800; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9619\n",
      "    -              passage loss: 2.0212\n",
      "    -         history_span loss: 9.0758\n",
      "    -      history_passage loss: 2.0128\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1252\n",
      "    -             emb_val other: 0.27534035\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7768.3884\n",
      "Epoch: 0: Step: 3900/9807; Global_step=3900; lr=2.955e-05; train time per batch = 1.49\n",
      "Train: global step = 3900; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9317\n",
      "    -              passage loss: 1.9946\n",
      "    -         history_span loss: 9.1520\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1251\n",
      "    -             emb_val other: 0.27604371\n",
      "    -         eff_perturb other: 0.00000214\n",
      "\n",
      "Epoch: 0: Step: 4000/9807; Global_step=4000; lr=2.954e-05; train time per batch = 1.49\n",
      "Train: global step = 4000; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9801\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.9339\n",
      "    -      history_passage loss: 2.0019\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9427\n",
      "    -             emb_val other: 0.27633986\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Validation: Epoch: 0 Step: 4000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 4100/9807; Global_step=4100; lr=2.952e-05; train time per batch = 1.49\n",
      "Train: global step = 4100; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0003\n",
      "    -                  end loss: 3.9589\n",
      "    -                 span loss: 7.9592\n",
      "    -              passage loss: 2.0324\n",
      "    -         history_span loss: 8.7146\n",
      "    -      history_passage loss: 2.0309\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7907\n",
      "    -             emb_val other: 0.27648199\n",
      "    -         eff_perturb other: 0.00000116\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8202.4101\n",
      "Epoch: 0: Step: 4200/9807; Global_step=4200; lr=2.951e-05; train time per batch = 1.49\n",
      "Train: global step = 4200; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9418\n",
      "    -              passage loss: 1.9919\n",
      "    -         history_span loss: 9.0778\n",
      "    -      history_passage loss: 2.0034\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0680\n",
      "    -             emb_val other: 0.27577877\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 4300/9807; Global_step=4300; lr=2.949e-05; train time per batch = 1.49\n",
      "Train: global step = 4300; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9517\n",
      "    -              passage loss: 2.0130\n",
      "    -         history_span loss: 8.9824\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0011\n",
      "    -             emb_val other: 0.27624288\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 4400/9807; Global_step=4400; lr=2.948e-05; train time per batch = 1.49\n",
      "Train: global step = 4400; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0000\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0291\n",
      "    -      history_passage loss: 2.0129\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0644\n",
      "    -             emb_val other: 0.27622613\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8802.4401\n",
      "Epoch: 0: Step: 4500/9807; Global_step=4500; lr=2.946e-05; train time per batch = 1.49\n",
      "Train: global step = 4500; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9997\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9507\n",
      "    -              passage loss: 1.9953\n",
      "    -         history_span loss: 8.9936\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9907\n",
      "    -             emb_val other: 0.27563578\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 4600/9807; Global_step=4600; lr=2.945e-05; train time per batch = 1.49\n",
      "Train: global step = 4600; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9583\n",
      "    -                 span loss: 7.9457\n",
      "    -              passage loss: 2.0229\n",
      "    -         history_span loss: 9.1235\n",
      "    -      history_passage loss: 2.0170\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1671\n",
      "    -             emb_val other: 0.27427548\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.9400.4700\n",
      "Epoch: 0: Step: 4700/9807; Global_step=4700; lr=2.943e-05; train time per batch = 1.49\n",
      "Train: global step = 4700; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0021\n",
      "    -                  end loss: 3.9570\n",
      "    -                 span loss: 7.9591\n",
      "    -              passage loss: 2.0036\n",
      "    -         history_span loss: 9.1726\n",
      "    -      history_passage loss: 2.0127\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.2016\n",
      "    -             emb_val other: 0.27657488\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 0: Step: 4800/9807; Global_step=4800; lr=2.942e-05; train time per batch = 1.49\n",
      "Train: global step = 4800; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9590\n",
      "    -                 span loss: 7.9510\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 8.9011\n",
      "    -      history_passage loss: 2.0195\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9577\n",
      "    -             emb_val other: 0.27667508\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 4900/9807; Global_step=4900; lr=2.940e-05; train time per batch = 1.49\n",
      "Train: global step = 4900; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9678\n",
      "    -                 span loss: 7.9654\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 9.0152\n",
      "    -      history_passage loss: 2.0047\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0489\n",
      "    -             emb_val other: 0.27501133\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 0: Step: 5000/9807; Global_step=5000; lr=2.939e-05; train time per batch = 1.49\n",
      "Train: global step = 5000; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0138\n",
      "    -         history_span loss: 8.7519\n",
      "    -      history_passage loss: 2.0133\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0032\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7887\n",
      "    -             emb_val other: 0.27501491\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Validation: Epoch: 0 Step: 5000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.10002.5001\n",
      "Epoch: 0: Step: 5100/9807; Global_step=5100; lr=2.937e-05; train time per batch = 1.49\n",
      "Train: global step = 5100; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9483\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 2.0113\n",
      "    -         history_span loss: 9.1551\n",
      "    -      history_passage loss: 2.0072\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.1705\n",
      "    -             emb_val other: 0.27676600\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 5200/9807; Global_step=5200; lr=2.935e-05; train time per batch = 1.49\n",
      "Train: global step = 5200; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9905\n",
      "    -                  end loss: 3.9620\n",
      "    -                 span loss: 7.9525\n",
      "    -              passage loss: 1.9980\n",
      "    -         history_span loss: 8.9436\n",
      "    -      history_passage loss: 2.0012\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9478\n",
      "    -             emb_val other: 0.27658525\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 5300/9807; Global_step=5300; lr=2.934e-05; train time per batch = 1.49\n",
      "Train: global step = 5300; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9907\n",
      "    -                  end loss: 3.9456\n",
      "    -                 span loss: 7.9363\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0135\n",
      "    -      history_passage loss: 2.0125\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0303\n",
      "    -             emb_val other: 0.27570173\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.10608.5304\n",
      "Epoch: 0: Step: 5400/9807; Global_step=5400; lr=2.932e-05; train time per batch = 1.49\n",
      "Train: global step = 5400; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9505\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 8.9325\n",
      "    -      history_passage loss: 2.0088\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9552\n",
      "    -             emb_val other: 0.27502593\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 5500/9807; Global_step=5500; lr=2.931e-05; train time per batch = 1.49\n",
      "Train: global step = 5500; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9821\n",
      "    -                  end loss: 3.9645\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 8.7465\n",
      "    -      history_passage loss: 2.0040\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7553\n",
      "    -             emb_val other: 0.27686626\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 0: Step: 5600/9807; Global_step=5600; lr=2.929e-05; train time per batch = 1.49\n",
      "Train: global step = 5600; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9959\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9552\n",
      "    -              passage loss: 1.9798\n",
      "    -         history_span loss: 8.9386\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9246\n",
      "    -             emb_val other: 0.27575988\n",
      "    -         eff_perturb other: 0.00000189\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11222.5611\n",
      "Epoch: 0: Step: 5700/9807; Global_step=5700; lr=2.928e-05; train time per batch = 1.49\n",
      "Train: global step = 5700; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9995\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9604\n",
      "    -              passage loss: 1.9714\n",
      "    -         history_span loss: 9.1502\n",
      "    -      history_passage loss: 1.9738\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1123\n",
      "    -             emb_val other: 0.27628312\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 5800/9807; Global_step=5800; lr=2.926e-05; train time per batch = 1.49\n",
      "Train: global step = 5800; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8865\n",
      "    -      history_passage loss: 1.9816\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8554\n",
      "    -             emb_val other: 0.27609265\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 0: Step: 5900/9807; Global_step=5900; lr=2.925e-05; train time per batch = 1.49\n",
      "Train: global step = 5900; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9952\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 8.9279\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9442\n",
      "    -             emb_val other: 0.27519867\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11832.5916\n",
      "Epoch: 0: Step: 6000/9807; Global_step=6000; lr=2.923e-05; train time per batch = 1.49\n",
      "Train: global step = 6000; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9909\n",
      "    -                  end loss: 3.9507\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0018\n",
      "    -         history_span loss: 9.1625\n",
      "    -      history_passage loss: 1.9913\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1495\n",
      "    -             emb_val other: 0.27741668\n",
      "    -         eff_perturb other: 0.00000110\n",
      "\n",
      "Validation: Epoch: 0 Step: 6000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 6100/9807; Global_step=6100; lr=2.922e-05; train time per batch = 1.49\n",
      "Train: global step = 6100; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9927\n",
      "    -         history_span loss: 9.0373\n",
      "    -      history_passage loss: 1.9856\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0178\n",
      "    -             emb_val other: 0.27629897\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.12280.6140\n",
      "Epoch: 0: Step: 6200/9807; Global_step=6200; lr=2.920e-05; train time per batch = 1.49\n",
      "Train: global step = 6200; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9602\n",
      "    -         history_span loss: 9.1018\n",
      "    -      history_passage loss: 1.9549\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0233\n",
      "    -             emb_val other: 0.27452242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 0: Step: 6300/9807; Global_step=6300; lr=2.919e-05; train time per batch = 1.49\n",
      "Train: global step = 6300; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9659\n",
      "    -         history_span loss: 9.1764\n",
      "    -      history_passage loss: 1.9571\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1010\n",
      "    -             emb_val other: 0.27559462\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 6400/9807; Global_step=6400; lr=2.917e-05; train time per batch = 1.49\n",
      "Train: global step = 6400; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9872\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0060\n",
      "    -         history_span loss: 9.0891\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0903\n",
      "    -             emb_val other: 0.27663863\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.12894.6447\n",
      "Epoch: 0: Step: 6600/9807; Global_step=6600; lr=2.914e-05; train time per batch = 1.49\n",
      "Train: global step = 6600; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9619\n",
      "    -                 span loss: 7.9522\n",
      "    -              passage loss: 1.9880\n",
      "    -         history_span loss: 8.9048\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8847\n",
      "    -             emb_val other: 0.27534875\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 6700/9807; Global_step=6700; lr=2.912e-05; train time per batch = 1.49\n",
      "Train: global step = 6700; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0030\n",
      "    -                  end loss: 3.9497\n",
      "    -                 span loss: 7.9527\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 9.2673\n",
      "    -      history_passage loss: 1.9911\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2750\n",
      "    -             emb_val other: 0.27513123\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.13506.6753\n",
      "Epoch: 0: Step: 6800/9807; Global_step=6800; lr=2.911e-05; train time per batch = 1.49\n",
      "Train: global step = 6800; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9710\n",
      "    -                 span loss: 7.9558\n",
      "    -              passage loss: 1.9905\n",
      "    -         history_span loss: 8.9291\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9376\n",
      "    -             emb_val other: 0.27625322\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 6900/9807; Global_step=6900; lr=2.909e-05; train time per batch = 1.49\n",
      "Train: global step = 6900; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9578\n",
      "    -              passage loss: 1.9862\n",
      "    -         history_span loss: 8.9226\n",
      "    -      history_passage loss: 1.9872\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9079\n",
      "    -             emb_val other: 0.27606720\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 7000/9807; Global_step=7000; lr=2.908e-05; train time per batch = 1.49\n",
      "Train: global step = 7000; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9845\n",
      "    -                  end loss: 3.9657\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 2.0127\n",
      "    -         history_span loss: 8.9778\n",
      "    -      history_passage loss: 2.0107\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0100\n",
      "    -             emb_val other: 0.27585945\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Validation: Epoch: 0 Step: 7000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.14002.7001\n",
      "Epoch: 0: Step: 7100/9807; Global_step=7100; lr=2.906e-05; train time per batch = 1.49\n",
      "Train: global step = 7100; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9880\n",
      "    -                  end loss: 3.9588\n",
      "    -                 span loss: 7.9468\n",
      "    -              passage loss: 1.9866\n",
      "    -         history_span loss: 9.0677\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0380\n",
      "    -             emb_val other: 0.27670929\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 0: Step: 7200/9807; Global_step=7200; lr=2.905e-05; train time per batch = 1.49\n",
      "Train: global step = 7200; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9823\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9358\n",
      "    -              passage loss: 2.0028\n",
      "    -         history_span loss: 9.0188\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0087\n",
      "    -             emb_val other: 0.27722108\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 7300/9807; Global_step=7300; lr=2.903e-05; train time per batch = 1.48\n",
      "Train: global step = 7300; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0015\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9340\n",
      "    -         history_span loss: 8.9996\n",
      "    -      history_passage loss: 1.9280\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8690\n",
      "    -             emb_val other: 0.27567086\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.14612.7306\n",
      "Epoch: 0: Step: 7400/9807; Global_step=7400; lr=2.902e-05; train time per batch = 1.48\n",
      "Train: global step = 7400; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0044\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9550\n",
      "    -              passage loss: 1.9725\n",
      "    -         history_span loss: 9.0979\n",
      "    -      history_passage loss: 1.9755\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0043\n",
      "    -                total loss: 21.0509\n",
      "    -             emb_val other: 0.27665615\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 7500/9807; Global_step=7500; lr=2.900e-05; train time per batch = 1.48\n",
      "Train: global step = 7500; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9502\n",
      "    -              passage loss: 1.9900\n",
      "    -         history_span loss: 8.9454\n",
      "    -      history_passage loss: 1.9809\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9201\n",
      "    -             emb_val other: 0.27629513\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 7600/9807; Global_step=7600; lr=2.899e-05; train time per batch = 1.48\n",
      "Train: global step = 7600; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9572\n",
      "    -                 span loss: 7.9489\n",
      "    -              passage loss: 1.9849\n",
      "    -         history_span loss: 8.8690\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8417\n",
      "    -             emb_val other: 0.27590010\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15226.7613\n",
      "Epoch: 0: Step: 7700/9807; Global_step=7700; lr=2.897e-05; train time per batch = 1.48\n",
      "Train: global step = 7700; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9545\n",
      "    -         history_span loss: 8.7893\n",
      "    -      history_passage loss: 1.9477\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.6940\n",
      "    -             emb_val other: 0.27498001\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 0: Step: 7800/9807; Global_step=7800; lr=2.895e-05; train time per batch = 1.48\n",
      "Train: global step = 7800; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9480\n",
      "    -                 span loss: 7.9394\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 9.0379\n",
      "    -      history_passage loss: 1.9992\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0284\n",
      "    -             emb_val other: 0.27694300\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 7900/9807; Global_step=7900; lr=2.894e-05; train time per batch = 1.48\n",
      "Train: global step = 7900; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9820\n",
      "    -                  end loss: 3.9698\n",
      "    -                 span loss: 7.9519\n",
      "    -              passage loss: 1.9882\n",
      "    -         history_span loss: 9.0342\n",
      "    -      history_passage loss: 2.0003\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 21.0271\n",
      "    -             emb_val other: 0.27663869\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15834.7917\n",
      "Epoch: 0: Step: 8000/9807; Global_step=8000; lr=2.892e-05; train time per batch = 1.48\n",
      "Train: global step = 8000; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9866\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9381\n",
      "    -              passage loss: 2.0139\n",
      "    -         history_span loss: 9.1433\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1490\n",
      "    -             emb_val other: 0.27531275\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Validation: Epoch: 0 Step: 8000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 8100/9807; Global_step=8100; lr=2.891e-05; train time per batch = 1.48\n",
      "Train: global step = 8100; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9886\n",
      "    -                  end loss: 3.9587\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 2.0223\n",
      "    -         history_span loss: 9.3031\n",
      "    -      history_passage loss: 2.0246\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.3551\n",
      "    -             emb_val other: 0.27587658\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.16270.8135\n",
      "Epoch: 0: Step: 8200/9807; Global_step=8200; lr=2.889e-05; train time per batch = 1.48\n",
      "Train: global step = 8200; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0027\n",
      "    -         history_span loss: 8.8936\n",
      "    -      history_passage loss: 2.0010\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9048\n",
      "    -             emb_val other: 0.27636260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 0: Step: 8300/9807; Global_step=8300; lr=2.888e-05; train time per batch = 1.49\n",
      "Train: global step = 8300; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9386\n",
      "    -              passage loss: 2.0099\n",
      "    -         history_span loss: 9.0721\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0882\n",
      "    -             emb_val other: 0.27487475\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Epoch: 0: Step: 8400/9807; Global_step=8400; lr=2.886e-05; train time per batch = 1.48\n",
      "Train: global step = 8400; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9980\n",
      "    -                  end loss: 3.9577\n",
      "    -                 span loss: 7.9557\n",
      "    -              passage loss: 1.9487\n",
      "    -         history_span loss: 9.0075\n",
      "    -      history_passage loss: 1.9532\n",
      "    -            adv_start loss: 0.0028\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9151\n",
      "    -             emb_val other: 0.27455506\n",
      "    -         eff_perturb other: 0.00000171\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.16886.8443\n",
      "Epoch: 0: Step: 8500/9807; Global_step=8500; lr=2.885e-05; train time per batch = 1.48\n",
      "Train: global step = 8500; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9457\n",
      "    -                 span loss: 7.9446\n",
      "    -              passage loss: 1.9601\n",
      "    -         history_span loss: 8.9329\n",
      "    -      history_passage loss: 1.9572\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8481\n",
      "    -             emb_val other: 0.27500150\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 8600/9807; Global_step=8600; lr=2.883e-05; train time per batch = 1.48\n",
      "Train: global step = 8600; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9842\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9406\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0033\n",
      "    -      history_passage loss: 1.9682\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9337\n",
      "    -             emb_val other: 0.27566877\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 8700/9807; Global_step=8700; lr=2.882e-05; train time per batch = 1.48\n",
      "Train: global step = 8700; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9465\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 1.9752\n",
      "    -         history_span loss: 8.9455\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8744\n",
      "    -             emb_val other: 0.27678972\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.17502.8751\n",
      "Epoch: 0: Step: 8900/9807; Global_step=8900; lr=2.879e-05; train time per batch = 1.48\n",
      "Train: global step = 8900; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9922\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9428\n",
      "    -              passage loss: 2.0165\n",
      "    -         history_span loss: 9.1788\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2018\n",
      "    -             emb_val other: 0.27680466\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 9000/9807; Global_step=9000; lr=2.877e-05; train time per batch = 1.48\n",
      "Train: global step = 9000; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9530\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 8.9586\n",
      "    -      history_passage loss: 1.9868\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9368\n",
      "    -             emb_val other: 0.27589667\n",
      "    -         eff_perturb other: 0.00000156\n",
      "\n",
      "Validation: Epoch: 0 Step: 9000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18002.9001\n",
      "Epoch: 0: Step: 9100/9807; Global_step=9100; lr=2.875e-05; train time per batch = 1.48\n",
      "Train: global step = 9100; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 1.9518\n",
      "    -         history_span loss: 8.8601\n",
      "    -      history_passage loss: 1.9453\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7592\n",
      "    -             emb_val other: 0.27497700\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Epoch: 0: Step: 9200/9807; Global_step=9200; lr=2.874e-05; train time per batch = 1.48\n",
      "Train: global step = 9200; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9967\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 1.9984\n",
      "    -         history_span loss: 8.8960\n",
      "    -      history_passage loss: 1.9915\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8974\n",
      "    -             emb_val other: 0.27608368\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 9300/9807; Global_step=9300; lr=2.872e-05; train time per batch = 1.48\n",
      "Train: global step = 9300; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9539\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0071\n",
      "    -         history_span loss: 8.7872\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8144\n",
      "    -             emb_val other: 0.27703959\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18618.9309\n",
      "Epoch: 0: Step: 9400/9807; Global_step=9400; lr=2.871e-05; train time per batch = 1.48\n",
      "Train: global step = 9400; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9802\n",
      "    -                  end loss: 3.9523\n",
      "    -                 span loss: 7.9325\n",
      "    -              passage loss: 1.9874\n",
      "    -         history_span loss: 8.9604\n",
      "    -      history_passage loss: 1.9973\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9316\n",
      "    -             emb_val other: 0.27661490\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Epoch: 0: Step: 9500/9807; Global_step=9500; lr=2.869e-05; train time per batch = 1.48\n",
      "Train: global step = 9500; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9854\n",
      "    -                  end loss: 3.9623\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.9132\n",
      "    -      history_passage loss: 1.9998\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9060\n",
      "    -             emb_val other: 0.27795157\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 9600/9807; Global_step=9600; lr=2.868e-05; train time per batch = 1.48\n",
      "Train: global step = 9600; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0013\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 2.0271\n",
      "    -         history_span loss: 9.1246\n",
      "    -      history_passage loss: 2.0232\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1903\n",
      "    -             emb_val other: 0.27589342\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.19218.9609\n",
      "Epoch: 0: Step: 9700/9807; Global_step=9700; lr=2.866e-05; train time per batch = 1.48\n",
      "Train: global step = 9700; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 2.0051\n",
      "    -         history_span loss: 8.8303\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.8410\n",
      "    -             emb_val other: 0.27555186\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 9800/9807; Global_step=9800; lr=2.865e-05; train time per batch = 1.48\n",
      "Train: global step = 9800; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9462\n",
      "    -                 span loss: 7.9521\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.8695\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.8560\n",
      "    -             emb_val other: 0.27552018\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Avg. total Loss of epoch 0 =21.009\n",
      "================================================================================\n",
      "                                    Epoch 1\n",
      "================================================================================\n",
      "Epoch: 1: Step: 93/9807; Global_step=9900; lr=2.863e-05; train time per batch = 1.49\n",
      "Train: global step = 9907; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0029\n",
      "    -                  end loss: 3.9627\n",
      "    -                 span loss: 7.9656\n",
      "    -              passage loss: 1.9664\n",
      "    -         history_span loss: 9.1381\n",
      "    -      history_passage loss: 1.9804\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1069\n",
      "    -             emb_val other: 0.27560779\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 1: Step: 193/9807; Global_step=10000; lr=2.862e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 10007; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9898\n",
      "    -                  end loss: 3.9626\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8406\n",
      "    -      history_passage loss: 2.0330\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9080\n",
      "    -             emb_val other: 0.27706259\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.438.10026\n",
      "Epoch: 1: Step: 293/9807; Global_step=10100; lr=2.860e-05; train time per batch = 1.50\n",
      "Train: global step = 10107; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9914\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9455\n",
      "    -              passage loss: 1.9941\n",
      "    -         history_span loss: 8.9621\n",
      "    -      history_passage loss: 1.9966\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9546\n",
      "    -             emb_val other: 0.27553037\n",
      "    -         eff_perturb other: 0.00000218\n",
      "\n",
      "Epoch: 1: Step: 393/9807; Global_step=10200; lr=2.859e-05; train time per batch = 1.49\n",
      "Train: global step = 10207; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9383\n",
      "    -              passage loss: 1.9966\n",
      "    -         history_span loss: 9.0171\n",
      "    -      history_passage loss: 1.9910\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9965\n",
      "    -             emb_val other: 0.27761611\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 1: Step: 493/9807; Global_step=10300; lr=2.857e-05; train time per batch = 1.49\n",
      "Train: global step = 10307; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9439\n",
      "    -              passage loss: 2.0243\n",
      "    -         history_span loss: 9.0539\n",
      "    -      history_passage loss: 2.0236\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0998\n",
      "    -             emb_val other: 0.27513096\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1042.10328\n",
      "Epoch: 1: Step: 593/9807; Global_step=10400; lr=2.855e-05; train time per batch = 1.50\n",
      "Train: global step = 10407; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9925\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9771\n",
      "    -         history_span loss: 9.0702\n",
      "    -      history_passage loss: 1.9713\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0310\n",
      "    -             emb_val other: 0.27559817\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 1: Step: 693/9807; Global_step=10500; lr=2.854e-05; train time per batch = 1.49\n",
      "Train: global step = 10507; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9862\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9616\n",
      "    -         history_span loss: 9.1537\n",
      "    -      history_passage loss: 1.9504\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0657\n",
      "    -             emb_val other: 0.27465016\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Epoch: 1: Step: 793/9807; Global_step=10600; lr=2.852e-05; train time per batch = 1.49\n",
      "Train: global step = 10607; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9474\n",
      "    -                 span loss: 7.9425\n",
      "    -              passage loss: 2.0218\n",
      "    -         history_span loss: 9.1308\n",
      "    -      history_passage loss: 2.0081\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1599\n",
      "    -             emb_val other: 0.27554685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1654.10634\n",
      "Epoch: 1: Step: 893/9807; Global_step=10700; lr=2.851e-05; train time per batch = 1.49\n",
      "Train: global step = 10707; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9427\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9863\n",
      "    -         history_span loss: 9.0427\n",
      "    -      history_passage loss: 1.9700\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0058\n",
      "    -                total loss: 20.9979\n",
      "    -             emb_val other: 0.27506685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 1: Step: 993/9807; Global_step=10800; lr=2.849e-05; train time per batch = 1.49\n",
      "Train: global step = 10807; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9928\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 2.0037\n",
      "    -         history_span loss: 9.1359\n",
      "    -      history_passage loss: 2.0053\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1566\n",
      "    -             emb_val other: 0.27612543\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 1093/9807; Global_step=10900; lr=2.848e-05; train time per batch = 1.48\n",
      "Train: global step = 10907; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9413\n",
      "    -              passage loss: 1.9920\n",
      "    -         history_span loss: 8.9912\n",
      "    -      history_passage loss: 1.9923\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9697\n",
      "    -             emb_val other: 0.27564260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2268.10941\n",
      "Epoch: 1: Step: 1193/9807; Global_step=11000; lr=2.846e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 1193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 11007; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9524\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0002\n",
      "    -         history_span loss: 8.9556\n",
      "    -      history_passage loss: 2.0030\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9563\n",
      "    -             emb_val other: 0.27449274\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 1293/9807; Global_step=11100; lr=2.845e-05; train time per batch = 1.49\n",
      "Train: global step = 11107; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9924\n",
      "    -                  end loss: 3.9605\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0373\n",
      "    -         history_span loss: 8.9785\n",
      "    -      history_passage loss: 2.0198\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0424\n",
      "    -             emb_val other: 0.27660847\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2708.11161\n",
      "Epoch: 1: Step: 1393/9807; Global_step=11200; lr=2.843e-05; train time per batch = 1.49\n",
      "Train: global step = 11207; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9964\n",
      "    -         history_span loss: 9.0059\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9984\n",
      "    -             emb_val other: 0.27549130\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 1: Step: 1493/9807; Global_step=11300; lr=2.842e-05; train time per batch = 1.49\n",
      "Train: global step = 11307; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9459\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.0162\n",
      "    -      history_passage loss: 2.0050\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0327\n",
      "    -             emb_val other: 0.27677551\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Epoch: 1: Step: 1593/9807; Global_step=11400; lr=2.840e-05; train time per batch = 1.49\n",
      "Train: global step = 11407; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9735\n",
      "    -         history_span loss: 9.0643\n",
      "    -      history_passage loss: 1.9732\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0106\n",
      "    -             emb_val other: 0.27586836\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.3324.11469\n",
      "Epoch: 1: Step: 1693/9807; Global_step=11500; lr=2.839e-05; train time per batch = 1.49\n",
      "Train: global step = 11507; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9879\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9864\n",
      "    -         history_span loss: 9.3993\n",
      "    -      history_passage loss: 1.9836\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.3589\n",
      "    -             emb_val other: 0.27617666\n",
      "    -         eff_perturb other: 0.00000160\n",
      "\n",
      "Epoch: 1: Step: 1793/9807; Global_step=11600; lr=2.837e-05; train time per batch = 1.49\n",
      "Train: global step = 11607; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9973\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.1000\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1207\n",
      "    -             emb_val other: 0.27521113\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 1: Step: 1893/9807; Global_step=11700; lr=2.836e-05; train time per batch = 1.49\n",
      "Train: global step = 11707; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9787\n",
      "    -                  end loss: 3.9464\n",
      "    -                 span loss: 7.9251\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 9.3338\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2336\n",
      "    -             emb_val other: 0.27513120\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.3936.11775\n",
      "Epoch: 1: Step: 1993/9807; Global_step=11800; lr=2.834e-05; train time per batch = 1.49\n",
      "Train: global step = 11807; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0008\n",
      "    -                  end loss: 3.9575\n",
      "    -                 span loss: 7.9583\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 8.8437\n",
      "    -      history_passage loss: 1.9642\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7785\n",
      "    -             emb_val other: 0.27490121\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 1: Step: 2093/9807; Global_step=11900; lr=2.832e-05; train time per batch = 1.49\n",
      "Train: global step = 11907; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9949\n",
      "    -                  end loss: 3.9365\n",
      "    -                 span loss: 7.9313\n",
      "    -              passage loss: 1.9860\n",
      "    -         history_span loss: 8.7881\n",
      "    -      history_passage loss: 1.9851\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7457\n",
      "    -             emb_val other: 0.27495745\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 2193/9807; Global_step=12000; lr=2.831e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 2193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4388.12001\n",
      "Train: global step = 12007; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 1.9609\n",
      "    -         history_span loss: 8.9000\n",
      "    -      history_passage loss: 1.9619\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8250\n",
      "    -             emb_val other: 0.27509722\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 1: Step: 2293/9807; Global_step=12100; lr=2.829e-05; train time per batch = 1.49\n",
      "Train: global step = 12107; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9636\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 2.0200\n",
      "    -         history_span loss: 8.9210\n",
      "    -      history_passage loss: 2.0130\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9650\n",
      "    -             emb_val other: 0.27607048\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 2393/9807; Global_step=12200; lr=2.828e-05; train time per batch = 1.49\n",
      "Train: global step = 12207; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0035\n",
      "    -                  end loss: 3.9610\n",
      "    -                 span loss: 7.9645\n",
      "    -              passage loss: 2.0016\n",
      "    -         history_span loss: 8.8582\n",
      "    -      history_passage loss: 2.0002\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8790\n",
      "    -             emb_val other: 0.27457252\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 1: Step: 2493/9807; Global_step=12300; lr=2.826e-05; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4996.12305\n",
      "Train: global step = 12307; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9401\n",
      "    -              passage loss: 1.9669\n",
      "    -         history_span loss: 8.8598\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7912\n",
      "    -             emb_val other: 0.27571741\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 1: Step: 2593/9807; Global_step=12400; lr=2.825e-05; train time per batch = 1.49\n",
      "Train: global step = 12407; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.0364\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0523\n",
      "    -             emb_val other: 0.27602518\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Epoch: 1: Step: 2693/9807; Global_step=12500; lr=2.823e-05; train time per batch = 1.49\n",
      "Train: global step = 12507; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0024\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9590\n",
      "    -              passage loss: 2.0391\n",
      "    -         history_span loss: 9.1507\n",
      "    -      history_passage loss: 2.0310\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2343\n",
      "    -             emb_val other: 0.27676222\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 2793/9807; Global_step=12600; lr=2.822e-05; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5596.12605\n",
      "Train: global step = 12607; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9493\n",
      "    -              passage loss: 1.9819\n",
      "    -         history_span loss: 9.1731\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1477\n",
      "    -             emb_val other: 0.27653170\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 2893/9807; Global_step=12700; lr=2.820e-05; train time per batch = 1.49\n",
      "Train: global step = 12707; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9931\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0141\n",
      "    -         history_span loss: 8.9224\n",
      "    -      history_passage loss: 2.0176\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9636\n",
      "    -             emb_val other: 0.27731833\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 1: Step: 2993/9807; Global_step=12800; lr=2.819e-05; train time per batch = 1.49\n",
      "Train: global step = 12807; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9498\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0105\n",
      "    -         history_span loss: 9.0754\n",
      "    -      history_passage loss: 2.0168\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1033\n",
      "    -             emb_val other: 0.27521381\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 3093/9807; Global_step=12900; lr=2.817e-05; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6200.12907\n",
      "Train: global step = 12907; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9875\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9397\n",
      "    -              passage loss: 1.9785\n",
      "    -         history_span loss: 9.2084\n",
      "    -      history_passage loss: 1.9822\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1605\n",
      "    -             emb_val other: 0.27617440\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 1: Step: 3193/9807; Global_step=13000; lr=2.816e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 3193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 13007; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9939\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9459\n",
      "    -              passage loss: 1.9879\n",
      "    -         history_span loss: 8.8245\n",
      "    -      history_passage loss: 1.9782\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7940\n",
      "    -             emb_val other: 0.27349240\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 1: Step: 3293/9807; Global_step=13100; lr=2.814e-05; train time per batch = 1.49\n",
      "Train: global step = 13107; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9868\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9606\n",
      "    -         history_span loss: 9.0673\n",
      "    -      history_passage loss: 1.9737\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0120\n",
      "    -             emb_val other: 0.27484637\n",
      "    -         eff_perturb other: 0.00000183\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6652.13133\n",
      "Epoch: 1: Step: 3393/9807; Global_step=13200; lr=2.812e-05; train time per batch = 1.49\n",
      "Train: global step = 13207; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0121\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9731\n",
      "    -              passage loss: 1.9739\n",
      "    -         history_span loss: 8.9081\n",
      "    -      history_passage loss: 1.9829\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8917\n",
      "    -             emb_val other: 0.27607408\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 1: Step: 3493/9807; Global_step=13300; lr=2.811e-05; train time per batch = 1.49\n",
      "Train: global step = 13307; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9860\n",
      "    -                  end loss: 3.9722\n",
      "    -                 span loss: 7.9582\n",
      "    -              passage loss: 2.0262\n",
      "    -         history_span loss: 8.9862\n",
      "    -      history_passage loss: 2.0211\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0458\n",
      "    -             emb_val other: 0.27722073\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 3593/9807; Global_step=13400; lr=2.809e-05; train time per batch = 1.49\n",
      "Train: global step = 13407; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0042\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9605\n",
      "    -              passage loss: 2.0115\n",
      "    -         history_span loss: 8.6957\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7369\n",
      "    -             emb_val other: 0.27645412\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7262.13438\n",
      "Epoch: 1: Step: 3693/9807; Global_step=13500; lr=2.808e-05; train time per batch = 1.49\n",
      "Train: global step = 13507; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0182\n",
      "    -         history_span loss: 8.9357\n",
      "    -      history_passage loss: 2.0033\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9625\n",
      "    -             emb_val other: 0.27678561\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 3793/9807; Global_step=13600; lr=2.806e-05; train time per batch = 1.49\n",
      "Train: global step = 13607; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9165\n",
      "    -      history_passage loss: 1.9802\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8742\n",
      "    -             emb_val other: 0.27615097\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 1: Step: 3893/9807; Global_step=13700; lr=2.805e-05; train time per batch = 1.49\n",
      "Train: global step = 13707; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9906\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0195\n",
      "    -         history_span loss: 8.8802\n",
      "    -      history_passage loss: 2.0086\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9146\n",
      "    -             emb_val other: 0.27567688\n",
      "    -         eff_perturb other: 0.00000186\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7870.13742\n",
      "Epoch: 1: Step: 3993/9807; Global_step=13800; lr=2.803e-05; train time per batch = 1.49\n",
      "Train: global step = 13807; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9384\n",
      "    -              passage loss: 1.9747\n",
      "    -         history_span loss: 9.1005\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0428\n",
      "    -             emb_val other: 0.27584198\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 1: Step: 4093/9807; Global_step=13900; lr=2.802e-05; train time per batch = 1.49\n",
      "Train: global step = 13907; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0001\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 2.0142\n",
      "    -         history_span loss: 9.0730\n",
      "    -      history_passage loss: 1.9901\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0873\n",
      "    -             emb_val other: 0.27592555\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 1: Step: 4193/9807; Global_step=14000; lr=2.800e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 4193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8388.14001\n",
      "Train: global step = 14007; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9423\n",
      "    -                 span loss: 7.9391\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 8.8066\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.8130\n",
      "    -             emb_val other: 0.27769196\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 1: Step: 4293/9807; Global_step=14100; lr=2.799e-05; train time per batch = 1.49\n",
      "Train: global step = 14107; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9800\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9346\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 8.9613\n",
      "    -      history_passage loss: 1.9920\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9414\n",
      "    -             emb_val other: 0.27621943\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 1: Step: 4393/9807; Global_step=14200; lr=2.797e-05; train time per batch = 1.49\n",
      "Train: global step = 14207; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0068\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.9842\n",
      "    -      history_passage loss: 1.9703\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9436\n",
      "    -             emb_val other: 0.27614722\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 1: Step: 4493/9807; Global_step=14300; lr=2.796e-05; train time per batch = 1.49\n",
      "Train: global step = 14307; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9616\n",
      "    -                 span loss: 7.9536\n",
      "    -              passage loss: 1.9903\n",
      "    -         history_span loss: 8.8295\n",
      "    -      history_passage loss: 1.9891\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8198\n",
      "    -             emb_val other: 0.27651179\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9002.14308\n",
      "Epoch: 1: Step: 4593/9807; Global_step=14400; lr=2.794e-05; train time per batch = 1.49\n",
      "Train: global step = 14407; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0128\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0048\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0571\n",
      "    -             emb_val other: 0.27614293\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 4693/9807; Global_step=14500; lr=2.792e-05; train time per batch = 1.49\n",
      "Train: global step = 14507; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9817\n",
      "    -         history_span loss: 9.0039\n",
      "    -      history_passage loss: 1.9922\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9795\n",
      "    -             emb_val other: 0.27605405\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 4793/9807; Global_step=14600; lr=2.791e-05; train time per batch = 1.49\n",
      "Train: global step = 14607; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0075\n",
      "    -                  end loss: 3.9538\n",
      "    -                 span loss: 7.9612\n",
      "    -              passage loss: 2.0136\n",
      "    -         history_span loss: 9.2063\n",
      "    -      history_passage loss: 1.9997\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2358\n",
      "    -             emb_val other: 0.27626783\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9616.14615\n",
      "Epoch: 1: Step: 4893/9807; Global_step=14700; lr=2.789e-05; train time per batch = 1.49\n",
      "Train: global step = 14707; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9578\n",
      "    -                 span loss: 7.9524\n",
      "    -              passage loss: 1.9926\n",
      "    -         history_span loss: 9.1422\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1243\n",
      "    -             emb_val other: 0.27685645\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 1: Step: 4993/9807; Global_step=14800; lr=2.788e-05; train time per batch = 1.49\n",
      "Train: global step = 14807; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9816\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9350\n",
      "    -              passage loss: 1.9892\n",
      "    -         history_span loss: 9.0125\n",
      "    -      history_passage loss: 1.9762\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9652\n",
      "    -             emb_val other: 0.27527630\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 1: Step: 5093/9807; Global_step=14900; lr=2.786e-05; train time per batch = 1.49\n",
      "Train: global step = 14907; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0028\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9576\n",
      "    -              passage loss: 1.9846\n",
      "    -         history_span loss: 9.0158\n",
      "    -      history_passage loss: 1.9847\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9973\n",
      "    -             emb_val other: 0.27496317\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10228.14921\n",
      "Epoch: 1: Step: 5193/9807; Global_step=15000; lr=2.785e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 5193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 15007; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9534\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0368\n",
      "    -      history_passage loss: 1.9753\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9873\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 5293/9807; Global_step=15100; lr=2.783e-05; train time per batch = 1.49\n",
      "Train: global step = 15107; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9934\n",
      "    -                  end loss: 3.9669\n",
      "    -                 span loss: 7.9603\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8100\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7952\n",
      "    -             emb_val other: 0.27592626\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10680.15147\n",
      "Epoch: 1: Step: 5393/9807; Global_step=15200; lr=2.782e-05; train time per batch = 1.49\n",
      "Train: global step = 15207; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9855\n",
      "    -                  end loss: 3.9606\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0035\n",
      "    -         history_span loss: 8.9616\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9751\n",
      "    -             emb_val other: 0.27645674\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 1: Step: 5493/9807; Global_step=15300; lr=2.780e-05; train time per batch = 1.49\n",
      "Train: global step = 15307; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9736\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9248\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.8868\n",
      "    -      history_passage loss: 2.0403\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9527\n",
      "    -             emb_val other: 0.27541244\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 5593/9807; Global_step=15400; lr=2.779e-05; train time per batch = 1.49\n",
      "Train: global step = 15407; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9551\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9593\n",
      "    -         history_span loss: 9.0491\n",
      "    -      history_passage loss: 1.9657\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9861\n",
      "    -             emb_val other: 0.27585569\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.11288.15451\n",
      "Epoch: 1: Step: 5693/9807; Global_step=15500; lr=2.777e-05; train time per batch = 1.49\n",
      "Train: global step = 15507; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9574\n",
      "    -                 span loss: 7.9500\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 9.0387\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0563\n",
      "    -             emb_val other: 0.27559242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 1: Step: 5793/9807; Global_step=15600; lr=2.776e-05; train time per batch = 1.49\n",
      "Train: global step = 15607; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 2.0076\n",
      "    -         history_span loss: 9.2745\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2814\n",
      "    -             emb_val other: 0.27620414\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 1: Step: 5893/9807; Global_step=15700; lr=2.774e-05; train time per batch = 1.49\n",
      "Train: global step = 15707; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9944\n",
      "    -                  end loss: 3.9635\n",
      "    -                 span loss: 7.9580\n",
      "    -              passage loss: 2.0303\n",
      "    -         history_span loss: 9.1783\n",
      "    -      history_passage loss: 2.0191\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2424\n",
      "    -             emb_val other: 0.27538690\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.11896.15755\n",
      "Epoch: 1: Step: 5993/9807; Global_step=15800; lr=2.772e-05; train time per batch = 1.49\n",
      "Train: global step = 15807; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9887\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9483\n",
      "    -              passage loss: 2.0006\n",
      "    -         history_span loss: 8.9798\n",
      "    -      history_passage loss: 1.9983\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9839\n",
      "    -             emb_val other: 0.27662101\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Epoch: 1: Step: 6093/9807; Global_step=15900; lr=2.771e-05; train time per batch = 1.49\n",
      "Train: global step = 15907; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0088\n",
      "    -         history_span loss: 8.9674\n",
      "    -      history_passage loss: 2.0163\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9944\n",
      "    -             emb_val other: 0.27684483\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6193/9807; Global_step=16000; lr=2.769e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 6193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12388.16001\n",
      "Train: global step = 16007; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9682\n",
      "    -                 span loss: 7.9638\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 8.8223\n",
      "    -      history_passage loss: 1.9758\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7868\n",
      "    -             emb_val other: 0.27515936\n",
      "    -         eff_perturb other: 0.00000178\n",
      "\n",
      "Epoch: 1: Step: 6293/9807; Global_step=16100; lr=2.768e-05; train time per batch = 1.49\n",
      "Train: global step = 16107; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9929\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9404\n",
      "    -              passage loss: 2.0220\n",
      "    -         history_span loss: 8.8795\n",
      "    -      history_passage loss: 2.0121\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9077\n",
      "    -             emb_val other: 0.27588502\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 6393/9807; Global_step=16200; lr=2.766e-05; train time per batch = 1.49\n",
      "Train: global step = 16207; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9785\n",
      "    -                  end loss: 3.9608\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 9.2224\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2166\n",
      "    -             emb_val other: 0.27573889\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 1: Step: 6493/9807; Global_step=16300; lr=2.765e-05; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13000.16307\n",
      "Train: global step = 16307; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9482\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8765\n",
      "    -      history_passage loss: 2.0119\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27598554\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 6593/9807; Global_step=16400; lr=2.763e-05; train time per batch = 1.49\n",
      "Train: global step = 16407; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9535\n",
      "    -              passage loss: 2.0410\n",
      "    -         history_span loss: 9.0682\n",
      "    -      history_passage loss: 2.0264\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1463\n",
      "    -             emb_val other: 0.27549431\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 6693/9807; Global_step=16500; lr=2.762e-05; train time per batch = 1.49\n",
      "Train: global step = 16507; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0065\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9588\n",
      "    -              passage loss: 1.9778\n",
      "    -         history_span loss: 8.9854\n",
      "    -      history_passage loss: 1.9844\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9615\n",
      "    -             emb_val other: 0.27585372\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6793/9807; Global_step=16600; lr=2.760e-05; train time per batch = 1.49\n",
      "Train: global step = 16607; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9809\n",
      "    -                  end loss: 3.9671\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 1.9419\n",
      "    -         history_span loss: 9.1481\n",
      "    -      history_passage loss: 1.9449\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0363\n",
      "    -             emb_val other: 0.27662677\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13612.16613\n",
      "Epoch: 1: Step: 6893/9807; Global_step=16700; lr=2.759e-05; train time per batch = 1.49\n",
      "Train: global step = 16707; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0060\n",
      "    -                  end loss: 3.9519\n",
      "    -                 span loss: 7.9579\n",
      "    -              passage loss: 1.9736\n",
      "    -         history_span loss: 9.1705\n",
      "    -      history_passage loss: 1.9587\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1156\n",
      "    -             emb_val other: 0.27487966\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6993/9807; Global_step=16800; lr=2.757e-05; train time per batch = 1.49\n",
      "Train: global step = 16807; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9417\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9723\n",
      "    -         history_span loss: 9.0560\n",
      "    -      history_passage loss: 1.9721\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9909\n",
      "    -             emb_val other: 0.27508208\n",
      "    -         eff_perturb other: 0.00000174\n",
      "\n",
      "Epoch: 1: Step: 7093/9807; Global_step=16900; lr=2.756e-05; train time per batch = 1.49\n",
      "Train: global step = 16907; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0100\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9635\n",
      "    -              passage loss: 2.0089\n",
      "    -         history_span loss: 9.0971\n",
      "    -      history_passage loss: 1.9994\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1221\n",
      "    -             emb_val other: 0.27543363\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14234.16924\n",
      "Epoch: 1: Step: 7193/9807; Global_step=17000; lr=2.754e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 7193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percobaan training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fa4a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   dialdoc/exp_11/dialki.1.10032.23017\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   dialdoc/inference\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   None\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files dialdoc/exp_11/dialki.1.10032.23017\n",
      "Reading saved model from dialdoc/exp_11/dialki.1.10032.23017\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Loading checkpoint @epoch = 1, offset = 10032, global_step = 23017, \n",
      "Loading model weights from saved state ...\n",
      "No train files are specified. Run validation.\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Saving prediction results to  dialdoc/inference\n"
     ]
    }
   ],
   "source": [
    "!bash run_eval_longformer.sh 'dialdoc dialdoc/exp_11/dialki.1.10032.23017' 'dialdoc/inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b58e5",
   "metadata": {},
   "source": [
    "Percobaan training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af0974",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   ./dialdoc/exp/dialki.1.16388.18001\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files ./dialdoc/exp/dialki.1.16388.18001\n",
      "Reading saved model from ./dialdoc/exp/dialki.1.16388.18001\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Loading checkpoint @epoch = 1, offset = 16388, global_step = 18001, \n",
      "Loading model weights from saved state ...\n",
      "Loading saved optimizer state ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "Loading scheduler state ...\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196140.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 1 (dataset) = step 16388\n",
      "Updated step of the epoch 1 (dataloader) = step 18001\n",
      "Total remaining updates = 178139.0\n",
      "================================================================================\n",
      "                                    Epoch 1\n",
      "================================================================================\n",
      "Epoch: 1: Step: 99/9807; Global_step=18100; lr=2.737e-05; train time per batch = 1.54\n",
      "Train: global step = 18101; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 1: Step: 199/9807; Global_step=18200; lr=2.736e-05; train time per batch = 1.56\n",
      "Train: global step = 18201; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 1: Step: 299/9807; Global_step=18300; lr=2.734e-05; train time per batch = 1.55\n",
      "Train: global step = 18301; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.608.18305\n",
      "Epoch: 1: Step: 399/9807; Global_step=18400; lr=2.733e-05; train time per batch = 1.55\n",
      "Train: global step = 18401; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 1: Step: 499/9807; Global_step=18500; lr=2.731e-05; train time per batch = 1.55\n",
      "Train: global step = 18501; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 1: Step: 699/9807; Global_step=18700; lr=2.728e-05; train time per batch = 1.54\n",
      "Train: global step = 18701; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9981\n",
      "    -                  end loss: 3.9470\n",
      "    -                 span loss: 7.9450\n",
      "    -              passage loss: 1.9715\n",
      "    -         history_span loss: 9.0247\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9632\n",
      "    -             emb_val other: 0.27524096\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 1: Step: 799/9807; Global_step=18800; lr=2.726e-05; train time per batch = 1.53\n",
      "Train: global step = 18801; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 1: Step: 899/9807; Global_step=18900; lr=2.725e-05; train time per batch = 1.53\n",
      "Train: global step = 18901; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1838.18920\n",
      "Epoch: 1: Step: 999/9807; Global_step=19000; lr=2.723e-05; train time per batch = 1.53\n",
      "Validation: Epoch: 1 Step: 999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 19001; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 1099/9807; Global_step=19100; lr=2.722e-05; train time per batch = 1.53\n",
      "Train: global step = 19101; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9966\n",
      "    -                  end loss: 3.9467\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9663\n",
      "    -         history_span loss: 8.8642\n",
      "    -      history_passage loss: 1.9765\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8058\n",
      "    -             emb_val other: 0.27565560\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2288.19145\n",
      "Epoch: 1: Step: 1199/9807; Global_step=19200; lr=2.720e-05; train time per batch = 1.53\n",
      "Train: global step = 19201; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9398\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 9.0099\n",
      "    -      history_passage loss: 1.9759\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9501\n",
      "    -             emb_val other: 0.27486575\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 1: Step: 1299/9807; Global_step=19300; lr=2.719e-05; train time per batch = 1.53\n",
      "Train: global step = 19301; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9893\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 9.1465\n",
      "    -      history_passage loss: 1.9884\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1118\n",
      "    -             emb_val other: 0.27678522\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 1: Step: 1399/9807; Global_step=19400; lr=2.717e-05; train time per batch = 1.53\n",
      "Train: global step = 19401; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0027\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9559\n",
      "    -              passage loss: 2.0031\n",
      "    -         history_span loss: 8.8815\n",
      "    -      history_passage loss: 1.9935\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8926\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2902.19452\n",
      "Epoch: 1: Step: 1499/9807; Global_step=19500; lr=2.716e-05; train time per batch = 1.53\n",
      "Train: global step = 19501; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9631\n",
      "    -                 span loss: 7.9515\n",
      "    -              passage loss: 1.9745\n",
      "    -         history_span loss: 8.9667\n",
      "    -      history_passage loss: 1.9744\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27560320\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 1: Step: 1599/9807; Global_step=19600; lr=2.714e-05; train time per batch = 1.52\n",
      "Train: global step = 19601; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9380\n",
      "    -             emb_val other: 0.27449915\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 1699/9807; Global_step=19700; lr=2.713e-05; train time per batch = 1.52\n",
      "Train: global step = 19701; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9833\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 2.0281\n",
      "    -         history_span loss: 8.8943\n",
      "    -      history_passage loss: 2.0275\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9579\n",
      "    -             emb_val other: 0.27573657\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.3514.19758\n",
      "Epoch: 1: Step: 1799/9807; Global_step=19800; lr=2.711e-05; train time per batch = 1.53\n",
      "Train: global step = 19801; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0051\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9573\n",
      "    -              passage loss: 2.0185\n",
      "    -         history_span loss: 9.1309\n",
      "    -      history_passage loss: 1.9999\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1602\n",
      "    -             emb_val other: 0.27481243\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 1: Step: 1899/9807; Global_step=19900; lr=2.709e-05; train time per batch = 1.52\n",
      "Train: global step = 19901; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9947\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9821\n",
      "    -         history_span loss: 8.9765\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9583\n",
      "    -             emb_val other: 0.27541786\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 1: Step: 1999/9807; Global_step=20000; lr=2.708e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 1999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4000.20001\n",
      "Train: global step = 20001; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9504\n",
      "    -              passage loss: 2.0042\n",
      "    -         history_span loss: 9.1781\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1936\n",
      "    -             emb_val other: 0.27660093\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 2099/9807; Global_step=20100; lr=2.706e-05; train time per batch = 1.52\n",
      "Train: global step = 20101; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.8982\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9148\n",
      "    -             emb_val other: 0.27517632\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 1: Step: 2199/9807; Global_step=20200; lr=2.705e-05; train time per batch = 1.52\n",
      "Train: global step = 20201; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 1.9627\n",
      "    -         history_span loss: 9.1273\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0661\n",
      "    -             emb_val other: 0.27609926\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Epoch: 1: Step: 2299/9807; Global_step=20300; lr=2.703e-05; train time per batch = 1.52\n",
      "Train: global step = 20301; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9649\n",
      "    -                 span loss: 7.9566\n",
      "    -              passage loss: 1.9820\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9759\n",
      "    -             emb_val other: 0.27716950\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4618.20310\n",
      "Epoch: 1: Step: 2399/9807; Global_step=20400; lr=2.702e-05; train time per batch = 1.52\n",
      "Train: global step = 20401; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 8.8510\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7985\n",
      "    -             emb_val other: 0.27587956\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 1: Step: 2499/9807; Global_step=20500; lr=2.700e-05; train time per batch = 1.52\n",
      "Train: global step = 20501; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0134\n",
      "    -         history_span loss: 9.0348\n",
      "    -      history_passage loss: 2.0062\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0602\n",
      "    -             emb_val other: 0.27547652\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Epoch: 1: Step: 2599/9807; Global_step=20600; lr=2.699e-05; train time per batch = 1.52\n",
      "Train: global step = 20601; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9932\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9891\n",
      "    -         history_span loss: 9.4932\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4753\n",
      "    -             emb_val other: 0.27565563\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5238.20620\n",
      "Epoch: 1: Step: 2699/9807; Global_step=20700; lr=2.697e-05; train time per batch = 1.52\n",
      "Train: global step = 20701; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9389\n",
      "    -              passage loss: 2.0001\n",
      "    -         history_span loss: 9.0556\n",
      "    -      history_passage loss: 2.0041\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0514\n",
      "    -             emb_val other: 0.27616084\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 1: Step: 2799/9807; Global_step=20800; lr=2.696e-05; train time per batch = 1.52\n",
      "Train: global step = 20801; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0017\n",
      "    -                  end loss: 3.9473\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 9.0647\n",
      "    -      history_passage loss: 2.0273\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1264\n",
      "    -             emb_val other: 0.27552190\n",
      "    -         eff_perturb other: 0.00000165\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5840.20921\n",
      "Epoch: 1: Step: 2999/9807; Global_step=21000; lr=2.693e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 2999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 21001; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9958\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 2.0304\n",
      "    -         history_span loss: 9.3055\n",
      "    -      history_passage loss: 2.0239\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.3652\n",
      "    -             emb_val other: 0.27447194\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 3099/9807; Global_step=21100; lr=2.691e-05; train time per batch = 1.52\n",
      "Train: global step = 21101; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 1.9869\n",
      "    -         history_span loss: 8.9978\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9847\n",
      "    -             emb_val other: 0.27495521\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6284.21143\n",
      "Epoch: 1: Step: 3199/9807; Global_step=21200; lr=2.689e-05; train time per batch = 1.52\n",
      "Train: global step = 21201; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9674\n",
      "    -                 span loss: 7.9642\n",
      "    -              passage loss: 1.9887\n",
      "    -         history_span loss: 9.2446\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2444\n",
      "    -             emb_val other: 0.27625531\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Epoch: 1: Step: 3299/9807; Global_step=21300; lr=2.688e-05; train time per batch = 1.52\n",
      "Train: global step = 21301; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9840\n",
      "    -                  end loss: 3.9533\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9677\n",
      "    -         history_span loss: 8.9238\n",
      "    -      history_passage loss: 1.9604\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8442\n",
      "    -             emb_val other: 0.27471855\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 3399/9807; Global_step=21400; lr=2.686e-05; train time per batch = 1.52\n",
      "Train: global step = 21401; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9465\n",
      "    -              passage loss: 2.0172\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0076\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0573\n",
      "    -             emb_val other: 0.27665561\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6902.21452\n",
      "Epoch: 1: Step: 3499/9807; Global_step=21500; lr=2.685e-05; train time per batch = 1.52\n",
      "Train: global step = 21501; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9990\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.8350\n",
      "    -      history_passage loss: 1.9761\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7858\n",
      "    -             emb_val other: 0.27657977\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 1: Step: 3599/9807; Global_step=21600; lr=2.683e-05; train time per batch = 1.52\n",
      "Train: global step = 21601; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9547\n",
      "    -              passage loss: 1.9921\n",
      "    -         history_span loss: 9.0610\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0550\n",
      "    -             emb_val other: 0.27563903\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Epoch: 1: Step: 3699/9807; Global_step=21700; lr=2.682e-05; train time per batch = 1.52\n",
      "Train: global step = 21701; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9919\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9424\n",
      "    -              passage loss: 1.9793\n",
      "    -         history_span loss: 9.1845\n",
      "    -      history_passage loss: 1.9659\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1248\n",
      "    -             emb_val other: 0.27591288\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7516.21759\n",
      "Epoch: 1: Step: 3799/9807; Global_step=21800; lr=2.680e-05; train time per batch = 1.52\n",
      "Train: global step = 21801; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9619\n",
      "    -              passage loss: 2.0212\n",
      "    -         history_span loss: 9.0758\n",
      "    -      history_passage loss: 2.0128\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1252\n",
      "    -             emb_val other: 0.27534035\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 1: Step: 3899/9807; Global_step=21900; lr=2.679e-05; train time per batch = 1.52\n",
      "Train: global step = 21901; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9317\n",
      "    -              passage loss: 1.9946\n",
      "    -         history_span loss: 9.1520\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1251\n",
      "    -             emb_val other: 0.27604371\n",
      "    -         eff_perturb other: 0.00000214\n",
      "\n",
      "Epoch: 1: Step: 3999/9807; Global_step=22000; lr=2.677e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 3999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8000.22001\n",
      "Train: global step = 22001; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9801\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.9339\n",
      "    -      history_passage loss: 2.0019\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9427\n",
      "    -             emb_val other: 0.27633986\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Epoch: 1: Step: 4099/9807; Global_step=22100; lr=2.676e-05; train time per batch = 1.52\n",
      "Train: global step = 22101; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0003\n",
      "    -                  end loss: 3.9589\n",
      "    -                 span loss: 7.9592\n",
      "    -              passage loss: 2.0324\n",
      "    -         history_span loss: 8.7146\n",
      "    -      history_passage loss: 2.0309\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7907\n",
      "    -             emb_val other: 0.27648199\n",
      "    -         eff_perturb other: 0.00000116\n",
      "\n",
      "Epoch: 1: Step: 4199/9807; Global_step=22200; lr=2.674e-05; train time per batch = 1.52\n",
      "Train: global step = 22201; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9418\n",
      "    -              passage loss: 1.9919\n",
      "    -         history_span loss: 9.0778\n",
      "    -      history_passage loss: 2.0034\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0680\n",
      "    -             emb_val other: 0.27577877\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8562.22282\n",
      "Epoch: 1: Step: 4299/9807; Global_step=22300; lr=2.673e-05; train time per batch = 1.52\n",
      "Train: global step = 22301; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9517\n",
      "    -              passage loss: 2.0130\n",
      "    -         history_span loss: 8.9824\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0011\n",
      "    -             emb_val other: 0.27624288\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 4399/9807; Global_step=22400; lr=2.671e-05; train time per batch = 1.52\n",
      "Train: global step = 22401; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0000\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0291\n",
      "    -      history_passage loss: 2.0129\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0644\n",
      "    -             emb_val other: 0.27622613\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 4499/9807; Global_step=22500; lr=2.669e-05; train time per batch = 1.52\n",
      "Train: global step = 22501; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9997\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9507\n",
      "    -              passage loss: 1.9953\n",
      "    -         history_span loss: 8.9936\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9907\n",
      "    -             emb_val other: 0.27563578\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9142.22572\n",
      "Epoch: 1: Step: 4599/9807; Global_step=22600; lr=2.668e-05; train time per batch = 1.53\n",
      "Train: global step = 22601; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9583\n",
      "    -                 span loss: 7.9457\n",
      "    -              passage loss: 2.0229\n",
      "    -         history_span loss: 9.1235\n",
      "    -      history_passage loss: 2.0170\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1671\n",
      "    -             emb_val other: 0.27427548\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Epoch: 1: Step: 4699/9807; Global_step=22700; lr=2.666e-05; train time per batch = 1.53\n",
      "Train: global step = 22701; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0021\n",
      "    -                  end loss: 3.9570\n",
      "    -                 span loss: 7.9591\n",
      "    -              passage loss: 2.0036\n",
      "    -         history_span loss: 9.1726\n",
      "    -      history_passage loss: 2.0127\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.2016\n",
      "    -             emb_val other: 0.27657488\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 1: Step: 4799/9807; Global_step=22800; lr=2.665e-05; train time per batch = 1.53\n",
      "Train: global step = 22801; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9590\n",
      "    -                 span loss: 7.9510\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 8.9011\n",
      "    -      history_passage loss: 2.0195\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9577\n",
      "    -             emb_val other: 0.27667508\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9748.22875\n",
      "Epoch: 1: Step: 4899/9807; Global_step=22900; lr=2.663e-05; train time per batch = 1.53\n",
      "Train: global step = 22901; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9678\n",
      "    -                 span loss: 7.9654\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 9.0152\n",
      "    -      history_passage loss: 2.0047\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0489\n",
      "    -             emb_val other: 0.27501133\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 1: Step: 4999/9807; Global_step=23000; lr=2.662e-05; train time per batch = 1.53\n",
      "Validation: Epoch: 1 Step: 4999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.28\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 23001; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0138\n",
      "    -         history_span loss: 8.7519\n",
      "    -      history_passage loss: 2.0133\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0032\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7887\n",
      "    -             emb_val other: 0.27501491\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10188.23095\n",
      "Epoch: 1: Step: 5099/9807; Global_step=23100; lr=2.660e-05; train time per batch = 1.53\n",
      "Train: global step = 23101; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9483\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 2.0113\n",
      "    -         history_span loss: 9.1551\n",
      "    -      history_passage loss: 2.0072\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.1705\n",
      "    -             emb_val other: 0.27676600\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 5199/9807; Global_step=23200; lr=2.659e-05; train time per batch = 1.53\n",
      "Train: global step = 23201; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9905\n",
      "    -                  end loss: 3.9620\n",
      "    -                 span loss: 7.9525\n",
      "    -              passage loss: 1.9980\n",
      "    -         history_span loss: 8.9436\n",
      "    -      history_passage loss: 2.0012\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9478\n",
      "    -             emb_val other: 0.27658525\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 5299/9807; Global_step=23300; lr=2.657e-05; train time per batch = 1.53\n",
      "Train: global step = 23301; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9907\n",
      "    -                  end loss: 3.9456\n",
      "    -                 span loss: 7.9363\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0135\n",
      "    -      history_passage loss: 2.0125\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0303\n",
      "    -             emb_val other: 0.27570173\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10798.23400\n",
      "Epoch: 1: Step: 5399/9807; Global_step=23400; lr=2.656e-05; train time per batch = 1.53\n",
      "Train: global step = 23401; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9505\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 8.9325\n",
      "    -      history_passage loss: 2.0088\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9552\n",
      "    -             emb_val other: 0.27502593\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 1: Step: 5499/9807; Global_step=23500; lr=2.654e-05; train time per batch = 1.53\n",
      "Train: global step = 23501; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9821\n",
      "    -                  end loss: 3.9645\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 8.7465\n",
      "    -      history_passage loss: 2.0040\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7553\n",
      "    -             emb_val other: 0.27686626\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 5599/9807; Global_step=23600; lr=2.653e-05; train time per batch = 1.53\n",
      "Train: global step = 23601; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9959\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9552\n",
      "    -              passage loss: 1.9798\n",
      "    -         history_span loss: 8.9386\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9246\n",
      "    -             emb_val other: 0.27575988\n",
      "    -         eff_perturb other: 0.00000189\n",
      "\n",
      "Epoch: 1: Step: 5699/9807; Global_step=23700; lr=2.651e-05; train time per batch = 1.53\n",
      "Train: global step = 23701; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9995\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9604\n",
      "    -              passage loss: 1.9714\n",
      "    -         history_span loss: 9.1502\n",
      "    -      history_passage loss: 1.9738\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1123\n",
      "    -             emb_val other: 0.27628312\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.11418.23710\n",
      "Epoch: 1: Step: 5799/9807; Global_step=23800; lr=2.649e-05; train time per batch = 1.52\n",
      "Train: global step = 23801; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8865\n",
      "    -      history_passage loss: 1.9816\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8554\n",
      "    -             emb_val other: 0.27609265\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 1: Step: 5899/9807; Global_step=23900; lr=2.648e-05; train time per batch = 1.52\n",
      "Train: global step = 23901; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9952\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 8.9279\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9442\n",
      "    -             emb_val other: 0.27519867\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Epoch: 1: Step: 5999/9807; Global_step=24000; lr=2.646e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 5999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12000.24001\n",
      "Train: global step = 24001; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9909\n",
      "    -                  end loss: 3.9507\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0018\n",
      "    -         history_span loss: 9.1625\n",
      "    -      history_passage loss: 1.9913\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1495\n",
      "    -             emb_val other: 0.27741668\n",
      "    -         eff_perturb other: 0.00000110\n",
      "\n",
      "Epoch: 1: Step: 6099/9807; Global_step=24100; lr=2.645e-05; train time per batch = 1.52\n",
      "Train: global step = 24101; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9927\n",
      "    -         history_span loss: 9.0373\n",
      "    -      history_passage loss: 1.9856\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0178\n",
      "    -             emb_val other: 0.27629897\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Epoch: 1: Step: 6199/9807; Global_step=24200; lr=2.643e-05; train time per batch = 1.52\n",
      "Train: global step = 24201; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9602\n",
      "    -         history_span loss: 9.1018\n",
      "    -      history_passage loss: 1.9549\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0233\n",
      "    -             emb_val other: 0.27452242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 1: Step: 6299/9807; Global_step=24300; lr=2.642e-05; train time per batch = 1.52\n",
      "Train: global step = 24301; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9659\n",
      "    -         history_span loss: 9.1764\n",
      "    -      history_passage loss: 1.9571\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1010\n",
      "    -             emb_val other: 0.27559462\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12624.24313\n",
      "Epoch: 1: Step: 6399/9807; Global_step=24400; lr=2.640e-05; train time per batch = 1.52\n",
      "Train: global step = 24401; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9872\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0060\n",
      "    -         history_span loss: 9.0891\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0903\n",
      "    -             emb_val other: 0.27663863\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 1: Step: 6499/9807; Global_step=24500; lr=2.639e-05; train time per batch = 1.52\n",
      "Train: global step = 24501; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0102\n",
      "    -                  end loss: 3.9483\n",
      "    -                 span loss: 7.9585\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 9.1157\n",
      "    -      history_passage loss: 1.9965\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1306\n",
      "    -             emb_val other: 0.27579606\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 6599/9807; Global_step=24600; lr=2.637e-05; train time per batch = 1.52\n",
      "Train: global step = 24601; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9619\n",
      "    -                 span loss: 7.9522\n",
      "    -              passage loss: 1.9880\n",
      "    -         history_span loss: 8.9048\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8847\n",
      "    -             emb_val other: 0.27534875\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13238.24620\n",
      "Epoch: 1: Step: 6699/9807; Global_step=24700; lr=2.636e-05; train time per batch = 1.52\n",
      "Train: global step = 24701; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0030\n",
      "    -                  end loss: 3.9497\n",
      "    -                 span loss: 7.9527\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 9.2673\n",
      "    -      history_passage loss: 1.9911\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2750\n",
      "    -             emb_val other: 0.27513123\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 6799/9807; Global_step=24800; lr=2.634e-05; train time per batch = 1.52\n",
      "Train: global step = 24801; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9710\n",
      "    -                 span loss: 7.9558\n",
      "    -              passage loss: 1.9905\n",
      "    -         history_span loss: 8.9291\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9376\n",
      "    -             emb_val other: 0.27625322\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 1: Step: 6899/9807; Global_step=24900; lr=2.633e-05; train time per batch = 1.52\n",
      "Train: global step = 24901; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9578\n",
      "    -              passage loss: 1.9862\n",
      "    -         history_span loss: 8.9226\n",
      "    -      history_passage loss: 1.9872\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9079\n",
      "    -             emb_val other: 0.27606720\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13856.24929\n",
      "Epoch: 1: Step: 6999/9807; Global_step=25000; lr=2.631e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 6999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 25001; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9845\n",
      "    -                  end loss: 3.9657\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 2.0127\n",
      "    -         history_span loss: 8.9778\n",
      "    -      history_passage loss: 2.0107\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0100\n",
      "    -             emb_val other: 0.27585945\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 1: Step: 7099/9807; Global_step=25100; lr=2.630e-05; train time per batch = 1.52\n",
      "Train: global step = 25101; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9880\n",
      "    -                  end loss: 3.9588\n",
      "    -                 span loss: 7.9468\n",
      "    -              passage loss: 1.9866\n",
      "    -         history_span loss: 9.0677\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0380\n",
      "    -             emb_val other: 0.27670929\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14302.25152\n",
      "Epoch: 1: Step: 7199/9807; Global_step=25200; lr=2.628e-05; train time per batch = 1.52\n",
      "Train: global step = 25201; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9823\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9358\n",
      "    -              passage loss: 2.0028\n",
      "    -         history_span loss: 9.0188\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0087\n",
      "    -             emb_val other: 0.27722108\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 1: Step: 7299/9807; Global_step=25300; lr=2.626e-05; train time per batch = 1.52\n",
      "Train: global step = 25301; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0015\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9340\n",
      "    -         history_span loss: 8.9996\n",
      "    -      history_passage loss: 1.9280\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8690\n",
      "    -             emb_val other: 0.27567086\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 1: Step: 7399/9807; Global_step=25400; lr=2.625e-05; train time per batch = 1.52\n",
      "Train: global step = 25401; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0044\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9550\n",
      "    -              passage loss: 1.9725\n",
      "    -         history_span loss: 9.0979\n",
      "    -      history_passage loss: 1.9755\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0043\n",
      "    -                total loss: 21.0509\n",
      "    -             emb_val other: 0.27665615\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14928.25465\n",
      "Epoch: 1: Step: 7499/9807; Global_step=25500; lr=2.623e-05; train time per batch = 1.52\n",
      "Train: global step = 25501; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9502\n",
      "    -              passage loss: 1.9900\n",
      "    -         history_span loss: 8.9454\n",
      "    -      history_passage loss: 1.9809\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9201\n",
      "    -             emb_val other: 0.27629513\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 1: Step: 7599/9807; Global_step=25600; lr=2.622e-05; train time per batch = 1.52\n",
      "Train: global step = 25601; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9572\n",
      "    -                 span loss: 7.9489\n",
      "    -              passage loss: 1.9849\n",
      "    -         history_span loss: 8.8690\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8417\n",
      "    -             emb_val other: 0.27590010\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 7699/9807; Global_step=25700; lr=2.620e-05; train time per batch = 1.52\n",
      "Train: global step = 25701; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9545\n",
      "    -         history_span loss: 8.7893\n",
      "    -      history_passage loss: 1.9477\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.6940\n",
      "    -             emb_val other: 0.27498001\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.15546.25774\n",
      "Epoch: 1: Step: 7799/9807; Global_step=25800; lr=2.619e-05; train time per batch = 1.52\n",
      "Train: global step = 25801; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9480\n",
      "    -                 span loss: 7.9394\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 9.0379\n",
      "    -      history_passage loss: 1.9992\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0284\n",
      "    -             emb_val other: 0.27694300\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 1: Step: 7899/9807; Global_step=25900; lr=2.617e-05; train time per batch = 1.52\n",
      "Train: global step = 25901; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9820\n",
      "    -                  end loss: 3.9698\n",
      "    -                 span loss: 7.9519\n",
      "    -              passage loss: 1.9882\n",
      "    -         history_span loss: 9.0342\n",
      "    -      history_passage loss: 2.0003\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 21.0271\n",
      "    -             emb_val other: 0.27663869\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 1: Step: 7999/9807; Global_step=26000; lr=2.616e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 7999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.16000.26001\n",
      "Train: global step = 26001; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9866\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9381\n",
      "    -              passage loss: 2.0139\n",
      "    -         history_span loss: 9.1433\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1490\n",
      "    -             emb_val other: 0.27531275\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 1: Step: 8099/9807; Global_step=26100; lr=2.614e-05; train time per batch = 1.52\n",
      "Train: global step = 26101; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9886\n",
      "    -                  end loss: 3.9587\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 2.0223\n",
      "    -         history_span loss: 9.3031\n",
      "    -      history_passage loss: 2.0246\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.3551\n",
      "    -             emb_val other: 0.27587658\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 8199/9807; Global_step=26200; lr=2.613e-05; train time per batch = 1.52\n",
      "Train: global step = 26201; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0027\n",
      "    -         history_span loss: 8.8936\n",
      "    -      history_passage loss: 2.0010\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9048\n",
      "    -             emb_val other: 0.27636260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 8299/9807; Global_step=26300; lr=2.611e-05; train time per batch = 1.52\n",
      "Train: global step = 26301; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9386\n",
      "    -              passage loss: 2.0099\n",
      "    -         history_span loss: 9.0721\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0882\n",
      "    -             emb_val other: 0.27487475\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.16614.26308\n",
      "Epoch: 1: Step: 8399/9807; Global_step=26400; lr=2.610e-05; train time per batch = 1.52\n",
      "Train: global step = 26401; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9980\n",
      "    -                  end loss: 3.9577\n",
      "    -                 span loss: 7.9557\n",
      "    -              passage loss: 1.9487\n",
      "    -         history_span loss: 9.0075\n",
      "    -      history_passage loss: 1.9532\n",
      "    -            adv_start loss: 0.0028\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9151\n",
      "    -             emb_val other: 0.27455506\n",
      "    -         eff_perturb other: 0.00000171\n",
      "\n",
      "Epoch: 1: Step: 8499/9807; Global_step=26500; lr=2.608e-05; train time per batch = 1.52\n",
      "Train: global step = 26501; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9457\n",
      "    -                 span loss: 7.9446\n",
      "    -              passage loss: 1.9601\n",
      "    -         history_span loss: 8.9329\n",
      "    -      history_passage loss: 1.9572\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8481\n",
      "    -             emb_val other: 0.27500150\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 1: Step: 8599/9807; Global_step=26600; lr=2.606e-05; train time per batch = 1.52\n",
      "Train: global step = 26601; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9842\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9406\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0033\n",
      "    -      history_passage loss: 1.9682\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9337\n",
      "    -             emb_val other: 0.27566877\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.17230.26616\n",
      "Epoch: 1: Step: 8699/9807; Global_step=26700; lr=2.605e-05; train time per batch = 1.52\n",
      "Train: global step = 26701; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9465\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 1.9752\n",
      "    -         history_span loss: 8.9455\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8744\n",
      "    -             emb_val other: 0.27678972\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Epoch: 1: Step: 8799/9807; Global_step=26800; lr=2.603e-05; train time per batch = 1.52\n",
      "Train: global step = 26801; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9866\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 1.9971\n",
      "    -         history_span loss: 9.1325\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1259\n",
      "    -             emb_val other: 0.27586383\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 8899/9807; Global_step=26900; lr=2.602e-05; train time per batch = 1.52\n",
      "Train: global step = 26901; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9922\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9428\n",
      "    -              passage loss: 2.0165\n",
      "    -         history_span loss: 9.1788\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2018\n",
      "    -             emb_val other: 0.27680466\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.17840.26921\n",
      "Epoch: 1: Step: 8999/9807; Global_step=27000; lr=2.600e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 1 Step: 8999/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 27001; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9530\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 8.9586\n",
      "    -      history_passage loss: 1.9868\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9368\n",
      "    -             emb_val other: 0.27589667\n",
      "    -         eff_perturb other: 0.00000156\n",
      "\n",
      "Epoch: 1: Step: 9099/9807; Global_step=27100; lr=2.599e-05; train time per batch = 1.52\n",
      "Train: global step = 27101; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 1.9518\n",
      "    -         history_span loss: 8.8601\n",
      "    -      history_passage loss: 1.9453\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7592\n",
      "    -             emb_val other: 0.27497700\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.18290.27146\n",
      "Epoch: 1: Step: 9199/9807; Global_step=27200; lr=2.597e-05; train time per batch = 1.52\n",
      "Train: global step = 27201; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9967\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 1.9984\n",
      "    -         history_span loss: 8.8960\n",
      "    -      history_passage loss: 1.9915\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8974\n",
      "    -             emb_val other: 0.27608368\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 1: Step: 9299/9807; Global_step=27300; lr=2.596e-05; train time per batch = 1.52\n",
      "Train: global step = 27301; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9539\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0071\n",
      "    -         history_span loss: 8.7872\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8144\n",
      "    -             emb_val other: 0.27703959\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Epoch: 1: Step: 9399/9807; Global_step=27400; lr=2.594e-05; train time per batch = 1.52\n",
      "Train: global step = 27401; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9802\n",
      "    -                  end loss: 3.9523\n",
      "    -                 span loss: 7.9325\n",
      "    -              passage loss: 1.9874\n",
      "    -         history_span loss: 8.9604\n",
      "    -      history_passage loss: 1.9973\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9316\n",
      "    -             emb_val other: 0.27661490\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.18886.27444\n",
      "Epoch: 1: Step: 9499/9807; Global_step=27500; lr=2.593e-05; train time per batch = 1.52\n",
      "Train: global step = 27501; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9854\n",
      "    -                  end loss: 3.9623\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.9132\n",
      "    -      history_passage loss: 1.9998\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9060\n",
      "    -             emb_val other: 0.27795157\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 9699/9807; Global_step=27700; lr=2.590e-05; train time per batch = 1.52\n",
      "Train: global step = 27701; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 2.0051\n",
      "    -         history_span loss: 8.8303\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.8410\n",
      "    -             emb_val other: 0.27555186\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.19468.27735\n",
      "Epoch: 1: Step: 9799/9807; Global_step=27800; lr=2.588e-05; train time per batch = 1.52\n",
      "Train: global step = 27801; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9462\n",
      "    -                 span loss: 7.9521\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.8695\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.8560\n",
      "    -             emb_val other: 0.27552018\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Avg. total Loss of epoch 1 =21.009\n",
      "================================================================================\n",
      "                                    Epoch 2\n",
      "================================================================================\n",
      "Epoch: 2: Step: 92/9807; Global_step=27900; lr=2.586e-05; train time per batch = 1.49\n",
      "Train: global step = 27908; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0029\n",
      "    -                  end loss: 3.9627\n",
      "    -                 span loss: 7.9656\n",
      "    -              passage loss: 1.9664\n",
      "    -         history_span loss: 9.1381\n",
      "    -      history_passage loss: 1.9804\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1069\n",
      "    -             emb_val other: 0.27560779\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 2: Step: 192/9807; Global_step=28000; lr=2.585e-05; train time per batch = 1.54\n",
      "Validation: Epoch: 2 Step: 192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 28008; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9898\n",
      "    -                  end loss: 3.9626\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8406\n",
      "    -      history_passage loss: 2.0330\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9080\n",
      "    -             emb_val other: 0.27706259\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.424.28020\n",
      "Epoch: 2: Step: 292/9807; Global_step=28100; lr=2.583e-05; train time per batch = 1.56\n",
      "Train: global step = 28108; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9914\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9455\n",
      "    -              passage loss: 1.9941\n",
      "    -         history_span loss: 8.9621\n",
      "    -      history_passage loss: 1.9966\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9546\n",
      "    -             emb_val other: 0.27553037\n",
      "    -         eff_perturb other: 0.00000218\n",
      "\n",
      "Epoch: 2: Step: 392/9807; Global_step=28200; lr=2.582e-05; train time per batch = 1.56\n",
      "Train: global step = 28208; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9383\n",
      "    -              passage loss: 1.9966\n",
      "    -         history_span loss: 9.0171\n",
      "    -      history_passage loss: 1.9910\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9965\n",
      "    -             emb_val other: 0.27761611\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 2: Step: 492/9807; Global_step=28300; lr=2.580e-05; train time per batch = 1.56\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.990.28303\n",
      "Train: global step = 28308; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9439\n",
      "    -              passage loss: 2.0243\n",
      "    -         history_span loss: 9.0539\n",
      "    -      history_passage loss: 2.0236\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0998\n",
      "    -             emb_val other: 0.27513096\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 2: Step: 592/9807; Global_step=28400; lr=2.579e-05; train time per batch = 1.56\n",
      "Train: global step = 28408; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9925\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9771\n",
      "    -         history_span loss: 9.0702\n",
      "    -      history_passage loss: 1.9713\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0310\n",
      "    -             emb_val other: 0.27559817\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 2: Step: 692/9807; Global_step=28500; lr=2.577e-05; train time per batch = 1.55\n",
      "Train: global step = 28508; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9862\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9616\n",
      "    -         history_span loss: 9.1537\n",
      "    -      history_passage loss: 1.9504\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0657\n",
      "    -             emb_val other: 0.27465016\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Epoch: 2: Step: 792/9807; Global_step=28600; lr=2.576e-05; train time per batch = 1.54\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.1586.28601\n",
      "Train: global step = 28608; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9474\n",
      "    -                 span loss: 7.9425\n",
      "    -              passage loss: 2.0218\n",
      "    -         history_span loss: 9.1308\n",
      "    -      history_passage loss: 2.0081\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1599\n",
      "    -             emb_val other: 0.27554685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 892/9807; Global_step=28700; lr=2.574e-05; train time per batch = 1.54\n",
      "Train: global step = 28708; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9427\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9863\n",
      "    -         history_span loss: 9.0427\n",
      "    -      history_passage loss: 1.9700\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0058\n",
      "    -                total loss: 20.9979\n",
      "    -             emb_val other: 0.27506685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 992/9807; Global_step=28800; lr=2.573e-05; train time per batch = 1.54\n",
      "Train: global step = 28808; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9928\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 2.0037\n",
      "    -         history_span loss: 9.1359\n",
      "    -      history_passage loss: 2.0053\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1566\n",
      "    -             emb_val other: 0.27612543\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 1092/9807; Global_step=28900; lr=2.571e-05; train time per batch = 1.54\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2194.28905\n",
      "Train: global step = 28908; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9413\n",
      "    -              passage loss: 1.9920\n",
      "    -         history_span loss: 8.9912\n",
      "    -      history_passage loss: 1.9923\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9697\n",
      "    -             emb_val other: 0.27564260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 2: Step: 1192/9807; Global_step=29000; lr=2.570e-05; train time per batch = 1.54\n",
      "Validation: Epoch: 2 Step: 1192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 29008; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9524\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0002\n",
      "    -         history_span loss: 8.9556\n",
      "    -      history_passage loss: 2.0030\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9563\n",
      "    -             emb_val other: 0.27449274\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 1292/9807; Global_step=29100; lr=2.568e-05; train time per batch = 1.54\n",
      "Train: global step = 29108; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9924\n",
      "    -                  end loss: 3.9605\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0373\n",
      "    -         history_span loss: 8.9785\n",
      "    -      history_passage loss: 2.0198\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0424\n",
      "    -             emb_val other: 0.27660847\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2630.29123\n",
      "Epoch: 2: Step: 1392/9807; Global_step=29200; lr=2.566e-05; train time per batch = 1.53\n",
      "Train: global step = 29208; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9964\n",
      "    -         history_span loss: 9.0059\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9984\n",
      "    -             emb_val other: 0.27549130\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 2: Step: 1492/9807; Global_step=29300; lr=2.565e-05; train time per batch = 1.53\n",
      "Train: global step = 29308; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9459\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.0162\n",
      "    -      history_passage loss: 2.0050\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0327\n",
      "    -             emb_val other: 0.27677551\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Epoch: 2: Step: 1592/9807; Global_step=29400; lr=2.563e-05; train time per batch = 1.53\n",
      "Train: global step = 29408; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9735\n",
      "    -         history_span loss: 9.0643\n",
      "    -      history_passage loss: 1.9732\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0106\n",
      "    -             emb_val other: 0.27586836\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.3242.29429\n",
      "Epoch: 2: Step: 1692/9807; Global_step=29500; lr=2.562e-05; train time per batch = 1.53\n",
      "Train: global step = 29508; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9879\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9864\n",
      "    -         history_span loss: 9.3993\n",
      "    -      history_passage loss: 1.9836\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.3589\n",
      "    -             emb_val other: 0.27617666\n",
      "    -         eff_perturb other: 0.00000160\n",
      "\n",
      "Epoch: 2: Step: 1792/9807; Global_step=29600; lr=2.560e-05; train time per batch = 1.53\n",
      "Train: global step = 29608; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9973\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.1000\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1207\n",
      "    -             emb_val other: 0.27521113\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 2: Step: 1892/9807; Global_step=29700; lr=2.559e-05; train time per batch = 1.53\n",
      "Train: global step = 29708; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9787\n",
      "    -                  end loss: 3.9464\n",
      "    -                 span loss: 7.9251\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 9.3338\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2336\n",
      "    -             emb_val other: 0.27513120\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.3852.29734\n",
      "Epoch: 2: Step: 1992/9807; Global_step=29800; lr=2.557e-05; train time per batch = 1.53\n",
      "Train: global step = 29808; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0008\n",
      "    -                  end loss: 3.9575\n",
      "    -                 span loss: 7.9583\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 8.8437\n",
      "    -      history_passage loss: 1.9642\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7785\n",
      "    -             emb_val other: 0.27490121\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 2: Step: 2092/9807; Global_step=29900; lr=2.556e-05; train time per batch = 1.53\n",
      "Train: global step = 29908; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9949\n",
      "    -                  end loss: 3.9365\n",
      "    -                 span loss: 7.9313\n",
      "    -              passage loss: 1.9860\n",
      "    -         history_span loss: 8.7881\n",
      "    -      history_passage loss: 1.9851\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7457\n",
      "    -             emb_val other: 0.27495745\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 2192/9807; Global_step=30000; lr=2.554e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 2192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.4386.30001\n",
      "Train: global step = 30008; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 1.9609\n",
      "    -         history_span loss: 8.9000\n",
      "    -      history_passage loss: 1.9619\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8250\n",
      "    -             emb_val other: 0.27509722\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 2: Step: 2292/9807; Global_step=30100; lr=2.553e-05; train time per batch = 1.52\n",
      "Train: global step = 30108; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9636\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 2.0200\n",
      "    -         history_span loss: 8.9210\n",
      "    -      history_passage loss: 2.0130\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9650\n",
      "    -             emb_val other: 0.27607048\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 2392/9807; Global_step=30200; lr=2.551e-05; train time per batch = 1.53\n",
      "Train: global step = 30208; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0035\n",
      "    -                  end loss: 3.9610\n",
      "    -                 span loss: 7.9645\n",
      "    -              passage loss: 2.0016\n",
      "    -         history_span loss: 8.8582\n",
      "    -      history_passage loss: 2.0002\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8790\n",
      "    -             emb_val other: 0.27457252\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 2: Step: 2492/9807; Global_step=30300; lr=2.550e-05; train time per batch = 1.52\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.4998.30307\n",
      "Train: global step = 30308; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9401\n",
      "    -              passage loss: 1.9669\n",
      "    -         history_span loss: 8.8598\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7912\n",
      "    -             emb_val other: 0.27571741\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 2592/9807; Global_step=30400; lr=2.548e-05; train time per batch = 1.52\n",
      "Train: global step = 30408; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.0364\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0523\n",
      "    -             emb_val other: 0.27602518\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Epoch: 2: Step: 2692/9807; Global_step=30500; lr=2.546e-05; train time per batch = 1.53\n",
      "Train: global step = 30508; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0024\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9590\n",
      "    -              passage loss: 2.0391\n",
      "    -         history_span loss: 9.1507\n",
      "    -      history_passage loss: 2.0310\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2343\n",
      "    -             emb_val other: 0.27676222\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 2: Step: 2792/9807; Global_step=30600; lr=2.545e-05; train time per batch = 1.53\n",
      "Train: global step = 30608; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9493\n",
      "    -              passage loss: 1.9819\n",
      "    -         history_span loss: 9.1731\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1477\n",
      "    -             emb_val other: 0.27653170\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.5604.30610\n",
      "Epoch: 2: Step: 2892/9807; Global_step=30700; lr=2.543e-05; train time per batch = 1.52\n",
      "Train: global step = 30708; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9931\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0141\n",
      "    -         history_span loss: 8.9224\n",
      "    -      history_passage loss: 2.0176\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9636\n",
      "    -             emb_val other: 0.27731833\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 2992/9807; Global_step=30800; lr=2.542e-05; train time per batch = 1.53\n",
      "Train: global step = 30808; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9498\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0105\n",
      "    -         history_span loss: 9.0754\n",
      "    -      history_passage loss: 2.0168\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1033\n",
      "    -             emb_val other: 0.27521381\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 2: Step: 3092/9807; Global_step=30900; lr=2.540e-05; train time per batch = 1.52\n",
      "Train: global step = 30908; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9875\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9397\n",
      "    -              passage loss: 1.9785\n",
      "    -         history_span loss: 9.2084\n",
      "    -      history_passage loss: 1.9822\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1605\n",
      "    -             emb_val other: 0.27617440\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.6214.30915\n",
      "Epoch: 2: Step: 3192/9807; Global_step=31000; lr=2.539e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 3192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 31008; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9939\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9459\n",
      "    -              passage loss: 1.9879\n",
      "    -         history_span loss: 8.8245\n",
      "    -      history_passage loss: 1.9782\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7940\n",
      "    -             emb_val other: 0.27349240\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 3292/9807; Global_step=31100; lr=2.537e-05; train time per batch = 1.52\n",
      "Train: global step = 31108; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9868\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9606\n",
      "    -         history_span loss: 9.0673\n",
      "    -      history_passage loss: 1.9737\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0120\n",
      "    -             emb_val other: 0.27484637\n",
      "    -         eff_perturb other: 0.00000183\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.6666.31141\n",
      "Epoch: 2: Step: 3392/9807; Global_step=31200; lr=2.536e-05; train time per batch = 1.52\n",
      "Train: global step = 31208; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0121\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9731\n",
      "    -              passage loss: 1.9739\n",
      "    -         history_span loss: 8.9081\n",
      "    -      history_passage loss: 1.9829\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8917\n",
      "    -             emb_val other: 0.27607408\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 2: Step: 3492/9807; Global_step=31300; lr=2.534e-05; train time per batch = 1.52\n",
      "Train: global step = 31308; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9860\n",
      "    -                  end loss: 3.9722\n",
      "    -                 span loss: 7.9582\n",
      "    -              passage loss: 2.0262\n",
      "    -         history_span loss: 8.9862\n",
      "    -      history_passage loss: 2.0211\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0458\n",
      "    -             emb_val other: 0.27722073\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 2: Step: 3592/9807; Global_step=31400; lr=2.533e-05; train time per batch = 1.52\n",
      "Train: global step = 31408; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0042\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9605\n",
      "    -              passage loss: 2.0115\n",
      "    -         history_span loss: 8.6957\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7369\n",
      "    -             emb_val other: 0.27645412\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7262.31439\n",
      "Epoch: 2: Step: 3692/9807; Global_step=31500; lr=2.531e-05; train time per batch = 1.52\n",
      "Train: global step = 31508; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0182\n",
      "    -         history_span loss: 8.9357\n",
      "    -      history_passage loss: 2.0033\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9625\n",
      "    -             emb_val other: 0.27678561\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 3792/9807; Global_step=31600; lr=2.530e-05; train time per batch = 1.52\n",
      "Train: global step = 31608; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9165\n",
      "    -      history_passage loss: 1.9802\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8742\n",
      "    -             emb_val other: 0.27615097\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 2: Step: 3892/9807; Global_step=31700; lr=2.528e-05; train time per batch = 1.52\n",
      "Train: global step = 31708; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9906\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0195\n",
      "    -         history_span loss: 8.8802\n",
      "    -      history_passage loss: 2.0086\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9146\n",
      "    -             emb_val other: 0.27567688\n",
      "    -         eff_perturb other: 0.00000186\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7866.31741\n",
      "Epoch: 2: Step: 3992/9807; Global_step=31800; lr=2.527e-05; train time per batch = 1.52\n",
      "Train: global step = 31808; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9384\n",
      "    -              passage loss: 1.9747\n",
      "    -         history_span loss: 9.1005\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0428\n",
      "    -             emb_val other: 0.27584198\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 2: Step: 4092/9807; Global_step=31900; lr=2.525e-05; train time per batch = 1.52\n",
      "Train: global step = 31908; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0001\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 2.0142\n",
      "    -         history_span loss: 9.0730\n",
      "    -      history_passage loss: 1.9901\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0873\n",
      "    -             emb_val other: 0.27592555\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 2: Step: 4192/9807; Global_step=32000; lr=2.523e-05; train time per batch = 1.53\n",
      "Validation: Epoch: 2 Step: 4192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.8386.32001\n",
      "Train: global step = 32008; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9423\n",
      "    -                 span loss: 7.9391\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 8.8066\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.8130\n",
      "    -             emb_val other: 0.27769196\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 4292/9807; Global_step=32100; lr=2.522e-05; train time per batch = 1.52\n",
      "Train: global step = 32108; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9800\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9346\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 8.9613\n",
      "    -      history_passage loss: 1.9920\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9414\n",
      "    -             emb_val other: 0.27621943\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 2: Step: 4392/9807; Global_step=32200; lr=2.520e-05; train time per batch = 1.52\n",
      "Train: global step = 32208; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0068\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.9842\n",
      "    -      history_passage loss: 1.9703\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9436\n",
      "    -             emb_val other: 0.27614722\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 2: Step: 4492/9807; Global_step=32300; lr=2.519e-05; train time per batch = 1.52\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.8992.32304\n",
      "Train: global step = 32308; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9616\n",
      "    -                 span loss: 7.9536\n",
      "    -              passage loss: 1.9903\n",
      "    -         history_span loss: 8.8295\n",
      "    -      history_passage loss: 1.9891\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8198\n",
      "    -             emb_val other: 0.27651179\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 4592/9807; Global_step=32400; lr=2.517e-05; train time per batch = 1.52\n",
      "Train: global step = 32408; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0128\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0048\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0571\n",
      "    -             emb_val other: 0.27614293\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 4692/9807; Global_step=32500; lr=2.516e-05; train time per batch = 1.52\n",
      "Train: global step = 32508; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9817\n",
      "    -         history_span loss: 9.0039\n",
      "    -      history_passage loss: 1.9922\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9795\n",
      "    -             emb_val other: 0.27605405\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 4792/9807; Global_step=32600; lr=2.514e-05; train time per batch = 1.53\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.9596.32606\n",
      "Train: global step = 32608; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0075\n",
      "    -                  end loss: 3.9538\n",
      "    -                 span loss: 7.9612\n",
      "    -              passage loss: 2.0136\n",
      "    -         history_span loss: 9.2063\n",
      "    -      history_passage loss: 1.9997\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2358\n",
      "    -             emb_val other: 0.27626783\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 2: Step: 4892/9807; Global_step=32700; lr=2.513e-05; train time per batch = 1.52\n",
      "Train: global step = 32708; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9578\n",
      "    -                 span loss: 7.9524\n",
      "    -              passage loss: 1.9926\n",
      "    -         history_span loss: 9.1422\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1243\n",
      "    -             emb_val other: 0.27685645\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 2: Step: 4992/9807; Global_step=32800; lr=2.511e-05; train time per batch = 1.52\n",
      "Train: global step = 32808; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9816\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9350\n",
      "    -              passage loss: 1.9892\n",
      "    -         history_span loss: 9.0125\n",
      "    -      history_passage loss: 1.9762\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9652\n",
      "    -             emb_val other: 0.27527630\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 5092/9807; Global_step=32900; lr=2.510e-05; train time per batch = 1.52\n",
      "Train: global step = 32908; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0028\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9576\n",
      "    -              passage loss: 1.9846\n",
      "    -         history_span loss: 9.0158\n",
      "    -      history_passage loss: 1.9847\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9973\n",
      "    -             emb_val other: 0.27496317\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.10216.32916\n",
      "Epoch: 2: Step: 5192/9807; Global_step=33000; lr=2.508e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 5192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 33008; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9534\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0368\n",
      "    -      history_passage loss: 1.9753\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9873\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 2: Step: 5292/9807; Global_step=33100; lr=2.507e-05; train time per batch = 1.52\n",
      "Train: global step = 33108; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9934\n",
      "    -                  end loss: 3.9669\n",
      "    -                 span loss: 7.9603\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8100\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7952\n",
      "    -             emb_val other: 0.27592626\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.10668.33142\n",
      "Epoch: 2: Step: 5392/9807; Global_step=33200; lr=2.505e-05; train time per batch = 1.52\n",
      "Train: global step = 33208; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9855\n",
      "    -                  end loss: 3.9606\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0035\n",
      "    -         history_span loss: 8.9616\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9751\n",
      "    -             emb_val other: 0.27645674\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 2: Step: 5492/9807; Global_step=33300; lr=2.503e-05; train time per batch = 1.52\n",
      "Train: global step = 33308; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9736\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9248\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.8868\n",
      "    -      history_passage loss: 2.0403\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9527\n",
      "    -             emb_val other: 0.27541244\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 2: Step: 5592/9807; Global_step=33400; lr=2.502e-05; train time per batch = 1.52\n",
      "Train: global step = 33408; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9551\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9593\n",
      "    -         history_span loss: 9.0491\n",
      "    -      history_passage loss: 1.9657\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9861\n",
      "    -             emb_val other: 0.27585569\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.11284.33450\n",
      "Epoch: 2: Step: 5692/9807; Global_step=33500; lr=2.500e-05; train time per batch = 1.52\n",
      "Train: global step = 33508; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9574\n",
      "    -                 span loss: 7.9500\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 9.0387\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0563\n",
      "    -             emb_val other: 0.27559242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 2: Step: 5792/9807; Global_step=33600; lr=2.499e-05; train time per batch = 1.52\n",
      "Train: global step = 33608; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 2.0076\n",
      "    -         history_span loss: 9.2745\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2814\n",
      "    -             emb_val other: 0.27620414\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 2: Step: 5892/9807; Global_step=33700; lr=2.497e-05; train time per batch = 1.52\n",
      "Train: global step = 33708; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9944\n",
      "    -                  end loss: 3.9635\n",
      "    -                 span loss: 7.9580\n",
      "    -              passage loss: 2.0303\n",
      "    -         history_span loss: 9.1783\n",
      "    -      history_passage loss: 2.0191\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2424\n",
      "    -             emb_val other: 0.27538690\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.11892.33754\n",
      "Epoch: 2: Step: 5992/9807; Global_step=33800; lr=2.496e-05; train time per batch = 1.52\n",
      "Train: global step = 33808; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9887\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9483\n",
      "    -              passage loss: 2.0006\n",
      "    -         history_span loss: 8.9798\n",
      "    -      history_passage loss: 1.9983\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9839\n",
      "    -             emb_val other: 0.27662101\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Epoch: 2: Step: 6092/9807; Global_step=33900; lr=2.494e-05; train time per batch = 1.52\n",
      "Train: global step = 33908; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0088\n",
      "    -         history_span loss: 8.9674\n",
      "    -      history_passage loss: 2.0163\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9944\n",
      "    -             emb_val other: 0.27684483\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 6192/9807; Global_step=34000; lr=2.493e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 6192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.12386.34001\n",
      "Train: global step = 34008; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9682\n",
      "    -                 span loss: 7.9638\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 8.8223\n",
      "    -      history_passage loss: 1.9758\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7868\n",
      "    -             emb_val other: 0.27515936\n",
      "    -         eff_perturb other: 0.00000178\n",
      "\n",
      "Epoch: 2: Step: 6292/9807; Global_step=34100; lr=2.491e-05; train time per batch = 1.52\n",
      "Train: global step = 34108; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9929\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9404\n",
      "    -              passage loss: 2.0220\n",
      "    -         history_span loss: 8.8795\n",
      "    -      history_passage loss: 2.0121\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9077\n",
      "    -             emb_val other: 0.27588502\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 2: Step: 6392/9807; Global_step=34200; lr=2.490e-05; train time per batch = 1.52\n",
      "Train: global step = 34208; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9785\n",
      "    -                  end loss: 3.9608\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 9.2224\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2166\n",
      "    -             emb_val other: 0.27573889\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 2: Step: 6492/9807; Global_step=34300; lr=2.488e-05; train time per batch = 1.52\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.13000.34308\n",
      "Train: global step = 34308; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9482\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8765\n",
      "    -      history_passage loss: 2.0119\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27598554\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 2: Step: 6592/9807; Global_step=34400; lr=2.487e-05; train time per batch = 1.52\n",
      "Train: global step = 34408; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9535\n",
      "    -              passage loss: 2.0410\n",
      "    -         history_span loss: 9.0682\n",
      "    -      history_passage loss: 2.0264\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1463\n",
      "    -             emb_val other: 0.27549431\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 2: Step: 6692/9807; Global_step=34500; lr=2.485e-05; train time per batch = 1.52\n",
      "Train: global step = 34508; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0065\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9588\n",
      "    -              passage loss: 1.9778\n",
      "    -         history_span loss: 8.9854\n",
      "    -      history_passage loss: 1.9844\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9615\n",
      "    -             emb_val other: 0.27585372\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 6792/9807; Global_step=34600; lr=2.483e-05; train time per batch = 1.52\n",
      "Train: global step = 34608; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9809\n",
      "    -                  end loss: 3.9671\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 1.9419\n",
      "    -         history_span loss: 9.1481\n",
      "    -      history_passage loss: 1.9449\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0363\n",
      "    -             emb_val other: 0.27662677\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.13612.34614\n",
      "Epoch: 2: Step: 6892/9807; Global_step=34700; lr=2.482e-05; train time per batch = 1.52\n",
      "Train: global step = 34708; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0060\n",
      "    -                  end loss: 3.9519\n",
      "    -                 span loss: 7.9579\n",
      "    -              passage loss: 1.9736\n",
      "    -         history_span loss: 9.1705\n",
      "    -      history_passage loss: 1.9587\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1156\n",
      "    -             emb_val other: 0.27487966\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 6992/9807; Global_step=34800; lr=2.480e-05; train time per batch = 1.52\n",
      "Train: global step = 34808; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9417\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9723\n",
      "    -         history_span loss: 9.0560\n",
      "    -      history_passage loss: 1.9721\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9909\n",
      "    -             emb_val other: 0.27508208\n",
      "    -         eff_perturb other: 0.00000174\n",
      "\n",
      "Epoch: 2: Step: 7092/9807; Global_step=34900; lr=2.479e-05; train time per batch = 1.52\n",
      "Train: global step = 34908; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0100\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9635\n",
      "    -              passage loss: 2.0089\n",
      "    -         history_span loss: 9.0971\n",
      "    -      history_passage loss: 1.9994\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1221\n",
      "    -             emb_val other: 0.27543363\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.14230.34923\n",
      "Epoch: 2: Step: 7192/9807; Global_step=35000; lr=2.477e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 7192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 35008; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9769\n",
      "    -         history_span loss: 9.1368\n",
      "    -      history_passage loss: 1.9848\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1015\n",
      "    -             emb_val other: 0.27627900\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 2: Step: 7292/9807; Global_step=35100; lr=2.476e-05; train time per batch = 1.52\n",
      "Train: global step = 35108; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9982\n",
      "    -                  end loss: 3.9579\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 9.1950\n",
      "    -      history_passage loss: 2.0039\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2109\n",
      "    -             emb_val other: 0.27599686\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.14672.35144\n",
      "Epoch: 2: Step: 7392/9807; Global_step=35200; lr=2.474e-05; train time per batch = 1.52\n",
      "Train: global step = 35208; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0033\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 1.9874\n",
      "    -         history_span loss: 8.9890\n",
      "    -      history_passage loss: 1.9834\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9699\n",
      "    -             emb_val other: 0.27565339\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 7492/9807; Global_step=35300; lr=2.473e-05; train time per batch = 1.52\n",
      "Train: global step = 35308; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9768\n",
      "    -                  end loss: 3.9439\n",
      "    -                 span loss: 7.9207\n",
      "    -              passage loss: 1.9858\n",
      "    -         history_span loss: 9.1428\n",
      "    -      history_passage loss: 1.9805\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0843\n",
      "    -             emb_val other: 0.27610594\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 2: Step: 7592/9807; Global_step=35400; lr=2.471e-05; train time per batch = 1.52\n",
      "Train: global step = 35408; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9830\n",
      "    -                  end loss: 3.9502\n",
      "    -                 span loss: 7.9332\n",
      "    -              passage loss: 2.0078\n",
      "    -         history_span loss: 9.0222\n",
      "    -      history_passage loss: 1.9964\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0151\n",
      "    -             emb_val other: 0.27700680\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.15290.35453\n",
      "Epoch: 2: Step: 7692/9807; Global_step=35500; lr=2.470e-05; train time per batch = 1.52\n",
      "Train: global step = 35508; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0041\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9565\n",
      "    -              passage loss: 1.9950\n",
      "    -         history_span loss: 9.0626\n",
      "    -      history_passage loss: 1.9956\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0643\n",
      "    -             emb_val other: 0.27561495\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 7792/9807; Global_step=35600; lr=2.468e-05; train time per batch = 1.52\n",
      "Train: global step = 35608; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9863\n",
      "    -         history_span loss: 9.0139\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9909\n",
      "    -             emb_val other: 0.27687666\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 2: Step: 7892/9807; Global_step=35700; lr=2.467e-05; train time per batch = 1.52\n",
      "Train: global step = 35708; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9516\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9912\n",
      "    -         history_span loss: 9.1053\n",
      "    -      history_passage loss: 1.9924\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0891\n",
      "    -             emb_val other: 0.27494881\n",
      "    -         eff_perturb other: 0.00000198\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.15904.35760\n",
      "Epoch: 2: Step: 7992/9807; Global_step=35800; lr=2.465e-05; train time per batch = 1.52\n",
      "Train: global step = 35808; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9422\n",
      "    -                 span loss: 7.9343\n",
      "    -              passage loss: 2.0183\n",
      "    -         history_span loss: 8.9779\n",
      "    -      history_passage loss: 2.0237\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0080\n",
      "    -             emb_val other: 0.27566722\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 2: Step: 8092/9807; Global_step=35900; lr=2.463e-05; train time per batch = 1.52\n",
      "Train: global step = 35908; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9864\n",
      "    -                  end loss: 3.9576\n",
      "    -                 span loss: 7.9440\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 9.1111\n",
      "    -      history_passage loss: 2.0060\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1164\n",
      "    -             emb_val other: 0.27756715\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 2: Step: 8192/9807; Global_step=36000; lr=2.462e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 8192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.16386.36001\n",
      "Train: global step = 36008; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9491\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 1.9911\n",
      "    -         history_span loss: 9.0270\n",
      "    -      history_passage loss: 1.9839\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0018\n",
      "    -             emb_val other: 0.27568942\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 2: Step: 8292/9807; Global_step=36100; lr=2.460e-05; train time per batch = 1.52\n",
      "Train: global step = 36108; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9813\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9369\n",
      "    -              passage loss: 2.0230\n",
      "    -         history_span loss: 9.2119\n",
      "    -      history_passage loss: 2.0249\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.2518\n",
      "    -             emb_val other: 0.27760538\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 2: Step: 8392/9807; Global_step=36200; lr=2.459e-05; train time per batch = 1.52\n",
      "Train: global step = 36208; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9575\n",
      "    -                 span loss: 7.9521\n",
      "    -              passage loss: 1.9859\n",
      "    -         history_span loss: 8.8231\n",
      "    -      history_passage loss: 1.9867\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8031\n",
      "    -             emb_val other: 0.27607766\n",
      "    -         eff_perturb other: 0.00000115\n",
      "\n",
      "Epoch: 2: Step: 8492/9807; Global_step=36300; lr=2.457e-05; train time per batch = 1.52\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.17000.36308\n",
      "Train: global step = 36308; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9419\n",
      "    -              passage loss: 2.0191\n",
      "    -         history_span loss: 9.0198\n",
      "    -      history_passage loss: 2.0162\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0518\n",
      "    -             emb_val other: 0.27463272\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 2: Step: 8592/9807; Global_step=36400; lr=2.456e-05; train time per batch = 1.52\n",
      "Train: global step = 36408; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9830\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9363\n",
      "    -              passage loss: 2.0282\n",
      "    -         history_span loss: 9.1196\n",
      "    -      history_passage loss: 2.0163\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1553\n",
      "    -             emb_val other: 0.27636725\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 8692/9807; Global_step=36500; lr=2.454e-05; train time per batch = 1.52\n",
      "Train: global step = 36508; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9949\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9510\n",
      "    -              passage loss: 1.9939\n",
      "    -         history_span loss: 9.1550\n",
      "    -      history_passage loss: 1.9905\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1424\n",
      "    -             emb_val other: 0.27596936\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 8792/9807; Global_step=36600; lr=2.453e-05; train time per batch = 1.52\n",
      "Train: global step = 36608; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9558\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 1.9530\n",
      "    -         history_span loss: 9.0384\n",
      "    -      history_passage loss: 1.9474\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9415\n",
      "    -             emb_val other: 0.27464107\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.17614.36615\n",
      "Epoch: 2: Step: 8892/9807; Global_step=36700; lr=2.451e-05; train time per batch = 1.52\n",
      "Train: global step = 36708; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0022\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9579\n",
      "    -              passage loss: 1.9688\n",
      "    -         history_span loss: 8.9426\n",
      "    -      history_passage loss: 1.9756\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8990\n",
      "    -             emb_val other: 0.27423498\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 8992/9807; Global_step=36800; lr=2.450e-05; train time per batch = 1.52\n",
      "Train: global step = 36808; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9583\n",
      "    -                 span loss: 7.9543\n",
      "    -              passage loss: 2.0039\n",
      "    -         history_span loss: 8.9355\n",
      "    -      history_passage loss: 1.9885\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9367\n",
      "    -             emb_val other: 0.27608261\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Epoch: 2: Step: 9092/9807; Global_step=36900; lr=2.448e-05; train time per batch = 1.52\n",
      "Train: global step = 36908; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9501\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 2.0191\n",
      "    -         history_span loss: 8.8831\n",
      "    -      history_passage loss: 2.0168\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9162\n",
      "    -             emb_val other: 0.27595818\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.18234.36925\n",
      "Epoch: 2: Step: 9192/9807; Global_step=37000; lr=2.447e-05; train time per batch = 1.52\n",
      "Validation: Epoch: 2 Step: 9192/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 37008; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9863\n",
      "    -                  end loss: 3.9528\n",
      "    -                 span loss: 7.9392\n",
      "    -              passage loss: 2.0133\n",
      "    -         history_span loss: 8.9163\n",
      "    -      history_passage loss: 2.0135\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9386\n",
      "    -             emb_val other: 0.27625901\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 9292/9807; Global_step=37100; lr=2.445e-05; train time per batch = 1.52\n",
      "Train: global step = 37108; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 1.9476\n",
      "    -         history_span loss: 8.8473\n",
      "    -      history_passage loss: 1.9534\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7556\n",
      "    -             emb_val other: 0.27441698\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.18690.37153\n",
      "Epoch: 2: Step: 9392/9807; Global_step=37200; lr=2.443e-05; train time per batch = 1.51\n",
      "Train: global step = 37208; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9943\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 1.9758\n",
      "    -         history_span loss: 9.0842\n",
      "    -      history_passage loss: 1.9733\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0346\n",
      "    -             emb_val other: 0.27620238\n",
      "    -         eff_perturb other: 0.00000224\n",
      "\n",
      "Epoch: 2: Step: 9492/9807; Global_step=37300; lr=2.442e-05; train time per batch = 1.51\n",
      "Train: global step = 37308; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9936\n",
      "    -                  end loss: 3.9584\n",
      "    -                 span loss: 7.9520\n",
      "    -              passage loss: 1.9933\n",
      "    -         history_span loss: 8.9989\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0032\n",
      "    -             emb_val other: 0.27428496\n",
      "    -         eff_perturb other: 0.00000184\n",
      "\n",
      "Epoch: 2: Step: 9592/9807; Global_step=37400; lr=2.440e-05; train time per batch = 1.51\n",
      "Train: global step = 37408; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0026\n",
      "    -                  end loss: 3.9422\n",
      "    -                 span loss: 7.9447\n",
      "    -              passage loss: 1.9826\n",
      "    -         history_span loss: 8.9168\n",
      "    -      history_passage loss: 1.9650\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8622\n",
      "    -             emb_val other: 0.27547741\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.19286.37451\n",
      "Epoch: 2: Step: 9692/9807; Global_step=37500; lr=2.439e-05; train time per batch = 1.52\n",
      "Train: global step = 37508; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9922\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9561\n",
      "    -              passage loss: 2.0053\n",
      "    -         history_span loss: 8.9281\n",
      "    -      history_passage loss: 2.0150\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9602\n",
      "    -             emb_val other: 0.27668667\n",
      "    -         eff_perturb other: 0.00000205\n",
      "\n",
      "Epoch: 2: Step: 9792/9807; Global_step=37600; lr=2.437e-05; train time per batch = 1.52\n",
      "Train: global step = 37608; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9551\n",
      "    -                 span loss: 7.9497\n",
      "    -              passage loss: 2.0189\n",
      "    -         history_span loss: 9.0019\n",
      "    -      history_passage loss: 2.0177\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0423\n",
      "    -             emb_val other: 0.27600163\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Avg. total Loss of epoch 2 =21.009\n",
      "================================================================================\n",
      "                                    Epoch 3\n",
      "================================================================================\n",
      "Epoch: 3: Step: 85/9807; Global_step=37700; lr=2.436e-05; train time per batch = 1.51\n",
      "Train: global step = 37715; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9612\n",
      "    -                 span loss: 7.9496\n",
      "    -              passage loss: 1.9811\n",
      "    -         history_span loss: 8.8367\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8011\n",
      "    -             emb_val other: 0.27620825\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 3: Step: 185/9807; Global_step=37800; lr=2.434e-05; train time per batch = 1.54\n",
      "Train: global step = 37815; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9991\n",
      "    -                  end loss: 3.9617\n",
      "    -                 span loss: 7.9607\n",
      "    -              passage loss: 2.0098\n",
      "    -         history_span loss: 8.9399\n",
      "    -      history_passage loss: 2.0145\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9812\n",
      "    -             emb_val other: 0.27573252\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.3.566.37898\n",
      "Epoch: 3: Step: 285/9807; Global_step=37900; lr=2.433e-05; train time per batch = 1.53\n",
      "Train: global step = 37915; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9870\n",
      "    -                  end loss: 3.9542\n",
      "    -                 span loss: 7.9412\n",
      "    -              passage loss: 1.9476\n",
      "    -         history_span loss: 9.0899\n",
      "    -      history_passage loss: 1.9434\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9737\n",
      "    -             emb_val other: 0.27555802\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 3: Step: 385/9807; Global_step=38000; lr=2.431e-05; train time per batch = 1.53\n",
      "Validation: Epoch: 3 Step: 385/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 38015; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9956\n",
      "    -                  end loss: 3.9491\n",
      "    -                 span loss: 7.9447\n",
      "    -              passage loss: 1.9884\n",
      "    -         history_span loss: 9.0301\n",
      "    -      history_passage loss: 1.9881\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0055\n",
      "    -             emb_val other: 0.27568346\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 3: Step: 485/9807; Global_step=38100; lr=2.430e-05; train time per batch = 1.53\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.3.996.38113\n",
      "Train: global step = 38115; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9888\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 1.9750\n",
      "    -         history_span loss: 9.0967\n",
      "    -      history_passage loss: 1.9683\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0338\n",
      "    -             emb_val other: 0.27612182\n",
      "    -         eff_perturb other: 0.00000177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2215d60",
   "metadata": {},
   "source": [
    "Dalam beberapa kali percobaan diatas, training dilakukan dalam num_epoch 20. Tetapi waktu yang dihabiskan sangat lama sekali. Apalagi eksperimen hanya menggunakan single GPU saja. Sehingga dilakukan pembatasan num_epoch menjadi 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19f8c7",
   "metadata": {},
   "source": [
    "Di bawah ini percobaan training final yang ada di dalam laporan akhir. Dimana diambil num_epoch : 3. Hasil menunjukkan Best EM = 1,64 dan Best F1 score = 14,27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64a2aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   3.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/train\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/train/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/14.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/11.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/6.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/20.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/16.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/8.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/17.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/10.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/7.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/18.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/5.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/13.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/15.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/4.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/9.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/12.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/19.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/train/3.pkl']\n",
      "Total data size: 19613\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 29421.0\n",
      "Updates per epoch (/gradient accumulation) = 9807\n",
      "Steps per epoch (dataloader) = 9807\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 29421.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9807; Global_step=100; lr=3.000e-06; train time per batch = 1.64\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9632\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 2.0337\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 2.0318\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1814\n",
      "    -             emb_val other: 0.27640125\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 200/9807; Global_step=200; lr=6.000e-06; train time per batch = 1.62\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.9984\n",
      "    -      history_passage loss: 2.0219\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0738\n",
      "    -             emb_val other: 0.27567434\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.492.246\n",
      "Epoch: 0: Step: 300/9807; Global_step=300; lr=9.000e-06; train time per batch = 1.61\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9624\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 2.0026\n",
      "    -         history_span loss: 9.1710\n",
      "    -      history_passage loss: 2.0065\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1850\n",
      "    -             emb_val other: 0.27575430\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 0: Step: 400/9807; Global_step=400; lr=1.200e-05; train time per batch = 1.60\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9713\n",
      "    -                  end loss: 3.9550\n",
      "    -                 span loss: 7.9263\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.1239\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1102\n",
      "    -             emb_val other: 0.27763033\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.990.495\n",
      "Epoch: 0: Step: 500/9807; Global_step=500; lr=1.500e-05; train time per batch = 1.60\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9462\n",
      "    -              passage loss: 2.0119\n",
      "    -         history_span loss: 9.1335\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1539\n",
      "    -             emb_val other: 0.27611369\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 600/9807; Global_step=600; lr=1.800e-05; train time per batch = 1.60\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9485\n",
      "    -                 span loss: 7.9449\n",
      "    -              passage loss: 2.0085\n",
      "    -         history_span loss: 9.0040\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0251\n",
      "    -             emb_val other: 0.27603605\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 0: Step: 700/9807; Global_step=700; lr=2.100e-05; train time per batch = 1.59\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9981\n",
      "    -                  end loss: 3.9470\n",
      "    -                 span loss: 7.9450\n",
      "    -              passage loss: 1.9715\n",
      "    -         history_span loss: 9.0247\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9632\n",
      "    -             emb_val other: 0.27524096\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1510.755\n",
      "Epoch: 0: Step: 800/9807; Global_step=800; lr=2.400e-05; train time per batch = 1.57\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9544\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 9.0084\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0025\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9111\n",
      "    -             emb_val other: 0.27514201\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 900/9807; Global_step=900; lr=2.700e-05; train time per batch = 1.56\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9441\n",
      "    -              passage loss: 2.0068\n",
      "    -         history_span loss: 9.1121\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1109\n",
      "    -             emb_val other: 0.27578896\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 1000/9807; Global_step=1000; lr=3.000e-05; train time per batch = 1.56\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9478\n",
      "    -              passage loss: 1.9977\n",
      "    -         history_span loss: 9.0316\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0367\n",
      "    -             emb_val other: 0.27602676\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.28\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.29\n",
      "Eval step 500 / 993; eval time per batch = 0.27\n",
      "Eval step 600 / 993; eval time per batch = 0.25\n",
      "Eval step 700 / 993; eval time per batch = 0.24\n",
      "Eval step 800 / 993; eval time per batch = 0.24\n",
      "Eval step 900 / 993; eval time per batch = 0.24\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "New best EM 1.64 on dev\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2000.1000\n",
      "New best F1 14.27 on dev\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2002.1001\n",
      "Epoch: 0: Step: 1100/9807; Global_step=1100; lr=2.989e-05; train time per batch = 1.55\n",
      "Train: global step = 1100; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9966\n",
      "    -                  end loss: 3.9467\n",
      "    -                 span loss: 7.9433\n",
      "    -              passage loss: 1.9663\n",
      "    -         history_span loss: 8.8642\n",
      "    -      history_passage loss: 1.9765\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8058\n",
      "    -             emb_val other: 0.27565560\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 1200/9807; Global_step=1200; lr=2.979e-05; train time per batch = 1.54\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9398\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 9.0099\n",
      "    -      history_passage loss: 1.9759\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9501\n",
      "    -             emb_val other: 0.27486575\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2590.1295\n",
      "Epoch: 0: Step: 1300/9807; Global_step=1300; lr=2.968e-05; train time per batch = 1.54\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9893\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 9.1465\n",
      "    -      history_passage loss: 1.9884\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1118\n",
      "    -             emb_val other: 0.27678522\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 0: Step: 1500/9807; Global_step=1500; lr=2.947e-05; train time per batch = 1.53\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9631\n",
      "    -                 span loss: 7.9515\n",
      "    -              passage loss: 1.9745\n",
      "    -         history_span loss: 8.9667\n",
      "    -      history_passage loss: 1.9744\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27560320\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3188.1594\n",
      "Epoch: 0: Step: 1600/9807; Global_step=1600; lr=2.937e-05; train time per batch = 1.53\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9506\n",
      "    -                 span loss: 7.9495\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9380\n",
      "    -             emb_val other: 0.27449915\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 1700/9807; Global_step=1700; lr=2.926e-05; train time per batch = 1.53\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9833\n",
      "    -                  end loss: 3.9679\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 2.0281\n",
      "    -         history_span loss: 8.8943\n",
      "    -      history_passage loss: 2.0275\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9579\n",
      "    -             emb_val other: 0.27573657\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 1800/9807; Global_step=1800; lr=2.916e-05; train time per batch = 1.53\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0051\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9573\n",
      "    -              passage loss: 2.0185\n",
      "    -         history_span loss: 9.1309\n",
      "    -      history_passage loss: 1.9999\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1602\n",
      "    -             emb_val other: 0.27481243\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3782.1891\n",
      "Epoch: 0: Step: 1900/9807; Global_step=1900; lr=2.905e-05; train time per batch = 1.52\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9947\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9821\n",
      "    -         history_span loss: 8.9765\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9583\n",
      "    -             emb_val other: 0.27541786\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 0: Step: 2000/9807; Global_step=2000; lr=2.894e-05; train time per batch = 1.52\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9504\n",
      "    -              passage loss: 2.0042\n",
      "    -         history_span loss: 9.1781\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1936\n",
      "    -             emb_val other: 0.27660093\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Epoch: 0: Step: 2100/9807; Global_step=2100; lr=2.884e-05; train time per batch = 1.52\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.8982\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9148\n",
      "    -             emb_val other: 0.27517632\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4210.2105\n",
      "Epoch: 0: Step: 2200/9807; Global_step=2200; lr=2.873e-05; train time per batch = 1.52\n",
      "Train: global step = 2200; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 1.9627\n",
      "    -         history_span loss: 9.1273\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0661\n",
      "    -             emb_val other: 0.27609926\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Epoch: 0: Step: 2300/9807; Global_step=2300; lr=2.863e-05; train time per batch = 1.52\n",
      "Train: global step = 2300; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9649\n",
      "    -                 span loss: 7.9566\n",
      "    -              passage loss: 1.9820\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9759\n",
      "    -             emb_val other: 0.27716950\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 2400/9807; Global_step=2400; lr=2.852e-05; train time per batch = 1.52\n",
      "Train: global step = 2400; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 1.9649\n",
      "    -         history_span loss: 8.8510\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7985\n",
      "    -             emb_val other: 0.27587956\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4806.2403\n",
      "Epoch: 0: Step: 2500/9807; Global_step=2500; lr=2.842e-05; train time per batch = 1.51\n",
      "Train: global step = 2500; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0134\n",
      "    -         history_span loss: 9.0348\n",
      "    -      history_passage loss: 2.0062\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0602\n",
      "    -             emb_val other: 0.27547652\n",
      "    -         eff_perturb other: 0.00000180\n",
      "\n",
      "Epoch: 0: Step: 2600/9807; Global_step=2600; lr=2.831e-05; train time per batch = 1.51\n",
      "Train: global step = 2600; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9932\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9891\n",
      "    -         history_span loss: 9.4932\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4753\n",
      "    -             emb_val other: 0.27565563\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 2700/9807; Global_step=2700; lr=2.821e-05; train time per batch = 1.51\n",
      "Train: global step = 2700; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9389\n",
      "    -              passage loss: 2.0001\n",
      "    -         history_span loss: 9.0556\n",
      "    -      history_passage loss: 2.0041\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0514\n",
      "    -             emb_val other: 0.27616084\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5412.2706\n",
      "Epoch: 0: Step: 2800/9807; Global_step=2800; lr=2.810e-05; train time per batch = 1.51\n",
      "Train: global step = 2800; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0017\n",
      "    -                  end loss: 3.9473\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 9.0647\n",
      "    -      history_passage loss: 2.0273\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.1264\n",
      "    -             emb_val other: 0.27552190\n",
      "    -         eff_perturb other: 0.00000165\n",
      "\n",
      "Epoch: 0: Step: 2900/9807; Global_step=2900; lr=2.799e-05; train time per batch = 1.51\n",
      "Train: global step = 2900; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9992\n",
      "    -                  end loss: 3.9601\n",
      "    -                 span loss: 7.9593\n",
      "    -              passage loss: 2.0177\n",
      "    -         history_span loss: 8.7420\n",
      "    -      history_passage loss: 2.0118\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7847\n",
      "    -             emb_val other: 0.27503952\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 0: Step: 3000/9807; Global_step=3000; lr=2.789e-05; train time per batch = 1.51\n",
      "Train: global step = 3000; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9958\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 2.0304\n",
      "    -         history_span loss: 9.3055\n",
      "    -      history_passage loss: 2.0239\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.3652\n",
      "    -             emb_val other: 0.27447194\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Validation: Epoch: 0 Step: 3000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "Epoch: 0: Step: 3100/9807; Global_step=3100; lr=2.778e-05; train time per batch = 1.51\n",
      "Train: global step = 3100; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 1.9869\n",
      "    -         history_span loss: 8.9978\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9847\n",
      "    -             emb_val other: 0.27495521\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 3200/9807; Global_step=3200; lr=2.768e-05; train time per batch = 1.51\n",
      "Train: global step = 3200; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9674\n",
      "    -                 span loss: 7.9642\n",
      "    -              passage loss: 1.9887\n",
      "    -         history_span loss: 9.2446\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2444\n",
      "    -             emb_val other: 0.27625531\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Epoch: 0: Step: 3300/9807; Global_step=3300; lr=2.757e-05; train time per batch = 1.51\n",
      "Train: global step = 3300; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9840\n",
      "    -                  end loss: 3.9533\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9677\n",
      "    -         history_span loss: 8.9238\n",
      "    -      history_passage loss: 1.9604\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8442\n",
      "    -             emb_val other: 0.27471855\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6626.3313\n",
      "Epoch: 0: Step: 3400/9807; Global_step=3400; lr=2.747e-05; train time per batch = 1.51\n",
      "Train: global step = 3400; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9916\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9465\n",
      "    -              passage loss: 2.0172\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0076\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0573\n",
      "    -             emb_val other: 0.27665561\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 0: Step: 3500/9807; Global_step=3500; lr=2.736e-05; train time per batch = 1.51\n",
      "Train: global step = 3500; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9990\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.8350\n",
      "    -      history_passage loss: 1.9761\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7858\n",
      "    -             emb_val other: 0.27657977\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 3600/9807; Global_step=3600; lr=2.726e-05; train time per batch = 1.51\n",
      "Train: global step = 3600; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9547\n",
      "    -              passage loss: 1.9921\n",
      "    -         history_span loss: 9.0610\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0550\n",
      "    -             emb_val other: 0.27563903\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7244.3622\n",
      "Epoch: 0: Step: 3700/9807; Global_step=3700; lr=2.715e-05; train time per batch = 1.51\n",
      "Train: global step = 3700; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9919\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9424\n",
      "    -              passage loss: 1.9793\n",
      "    -         history_span loss: 9.1845\n",
      "    -      history_passage loss: 1.9659\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1248\n",
      "    -             emb_val other: 0.27591288\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 0: Step: 3800/9807; Global_step=3800; lr=2.704e-05; train time per batch = 1.51\n",
      "Train: global step = 3800; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9619\n",
      "    -              passage loss: 2.0212\n",
      "    -         history_span loss: 9.0758\n",
      "    -      history_passage loss: 2.0128\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1252\n",
      "    -             emb_val other: 0.27534035\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 0: Step: 3900/9807; Global_step=3900; lr=2.694e-05; train time per batch = 1.51\n",
      "Train: global step = 3900; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9500\n",
      "    -                 span loss: 7.9317\n",
      "    -              passage loss: 1.9946\n",
      "    -         history_span loss: 9.1520\n",
      "    -      history_passage loss: 1.9912\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1251\n",
      "    -             emb_val other: 0.27604371\n",
      "    -         eff_perturb other: 0.00000214\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7860.3930\n",
      "Epoch: 0: Step: 4000/9807; Global_step=4000; lr=2.683e-05; train time per batch = 1.51\n",
      "Train: global step = 4000; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9801\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0101\n",
      "    -         history_span loss: 8.9339\n",
      "    -      history_passage loss: 2.0019\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9427\n",
      "    -             emb_val other: 0.27633986\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Validation: Epoch: 0 Step: 4000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.2000.1000\n",
      "Best F1 14.27 path = dialki.0.2000.1000\n",
      "Epoch: 0: Step: 4100/9807; Global_step=4100; lr=2.673e-05; train time per batch = 1.51\n",
      "Train: global step = 4100; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0003\n",
      "    -                  end loss: 3.9589\n",
      "    -                 span loss: 7.9592\n",
      "    -              passage loss: 2.0324\n",
      "    -         history_span loss: 8.7146\n",
      "    -      history_passage loss: 2.0309\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.7907\n",
      "    -             emb_val other: 0.27648199\n",
      "    -         eff_perturb other: 0.00000116\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8308.4154\n",
      "Epoch: 0: Step: 4200/9807; Global_step=4200; lr=2.662e-05; train time per batch = 1.51\n",
      "Train: global step = 4200; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9418\n",
      "    -              passage loss: 1.9919\n",
      "    -         history_span loss: 9.0778\n",
      "    -      history_passage loss: 2.0034\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0680\n",
      "    -             emb_val other: 0.27577877\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 4300/9807; Global_step=4300; lr=2.652e-05; train time per batch = 1.51\n",
      "Train: global step = 4300; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9977\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9517\n",
      "    -              passage loss: 2.0130\n",
      "    -         history_span loss: 8.9824\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0011\n",
      "    -             emb_val other: 0.27624288\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 4400/9807; Global_step=4400; lr=2.641e-05; train time per batch = 1.51\n",
      "Train: global step = 4400; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0000\n",
      "    -                  end loss: 3.9560\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 9.0291\n",
      "    -      history_passage loss: 2.0129\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0644\n",
      "    -             emb_val other: 0.27622613\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8920.4460\n",
      "Epoch: 0: Step: 4500/9807; Global_step=4500; lr=2.631e-05; train time per batch = 1.51\n",
      "Train: global step = 4500; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9997\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9507\n",
      "    -              passage loss: 1.9953\n",
      "    -         history_span loss: 8.9936\n",
      "    -      history_passage loss: 1.9969\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9907\n",
      "    -             emb_val other: 0.27563578\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 0: Step: 4600/9807; Global_step=4600; lr=2.620e-05; train time per batch = 1.51\n",
      "Train: global step = 4600; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9583\n",
      "    -                 span loss: 7.9457\n",
      "    -              passage loss: 2.0229\n",
      "    -         history_span loss: 9.1235\n",
      "    -      history_passage loss: 2.0170\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1671\n",
      "    -             emb_val other: 0.27427548\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Epoch: 0: Step: 4700/9807; Global_step=4700; lr=2.609e-05; train time per batch = 1.51\n",
      "Train: global step = 4700; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0021\n",
      "    -                  end loss: 3.9570\n",
      "    -                 span loss: 7.9591\n",
      "    -              passage loss: 2.0036\n",
      "    -         history_span loss: 9.1726\n",
      "    -      history_passage loss: 2.0127\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.2016\n",
      "    -             emb_val other: 0.27657488\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.9532.4766\n",
      "Epoch: 0: Step: 4800/9807; Global_step=4800; lr=2.599e-05; train time per batch = 1.51\n",
      "Train: global step = 4800; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9590\n",
      "    -                 span loss: 7.9510\n",
      "    -              passage loss: 2.0309\n",
      "    -         history_span loss: 8.9011\n",
      "    -      history_passage loss: 2.0195\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9577\n",
      "    -             emb_val other: 0.27667508\n",
      "    -         eff_perturb other: 0.00000173\n",
      "\n",
      "Epoch: 0: Step: 4900/9807; Global_step=4900; lr=2.588e-05; train time per batch = 1.51\n",
      "Train: global step = 4900; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9678\n",
      "    -                 span loss: 7.9654\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 9.0152\n",
      "    -      history_passage loss: 2.0047\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0489\n",
      "    -             emb_val other: 0.27501133\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 0: Step: 5000/9807; Global_step=5000; lr=2.578e-05; train time per batch = 1.51\n",
      "Train: global step = 5000; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0138\n",
      "    -         history_span loss: 8.7519\n",
      "    -      history_passage loss: 2.0133\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0032\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7887\n",
      "    -             emb_val other: 0.27501491\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Validation: Epoch: 0 Step: 5000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.10002.5001\n",
      "Epoch: 0: Step: 5100/9807; Global_step=5100; lr=2.567e-05; train time per batch = 1.51\n",
      "Train: global step = 5100; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9483\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 2.0113\n",
      "    -         history_span loss: 9.1551\n",
      "    -      history_passage loss: 2.0072\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.1705\n",
      "    -             emb_val other: 0.27676600\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 5200/9807; Global_step=5200; lr=2.557e-05; train time per batch = 1.51\n",
      "Train: global step = 5200; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9905\n",
      "    -                  end loss: 3.9620\n",
      "    -                 span loss: 7.9525\n",
      "    -              passage loss: 1.9980\n",
      "    -         history_span loss: 8.9436\n",
      "    -      history_passage loss: 2.0012\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9478\n",
      "    -             emb_val other: 0.27658525\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 5400/9807; Global_step=5400; lr=2.536e-05; train time per batch = 1.51\n",
      "Train: global step = 5400; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9505\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 8.9325\n",
      "    -      history_passage loss: 2.0088\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9552\n",
      "    -             emb_val other: 0.27502593\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 0: Step: 5500/9807; Global_step=5500; lr=2.525e-05; train time per batch = 1.51\n",
      "Train: global step = 5500; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9821\n",
      "    -                  end loss: 3.9645\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 8.7465\n",
      "    -      history_passage loss: 2.0040\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7553\n",
      "    -             emb_val other: 0.27686626\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 0: Step: 5600/9807; Global_step=5600; lr=2.514e-05; train time per batch = 1.51\n",
      "Train: global step = 5600; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9959\n",
      "    -                  end loss: 3.9593\n",
      "    -                 span loss: 7.9552\n",
      "    -              passage loss: 1.9798\n",
      "    -         history_span loss: 8.9386\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9246\n",
      "    -             emb_val other: 0.27575988\n",
      "    -         eff_perturb other: 0.00000189\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11234.5617\n",
      "Epoch: 0: Step: 5700/9807; Global_step=5700; lr=2.504e-05; train time per batch = 1.51\n",
      "Train: global step = 5700; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9995\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9604\n",
      "    -              passage loss: 1.9714\n",
      "    -         history_span loss: 9.1502\n",
      "    -      history_passage loss: 1.9738\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1123\n",
      "    -             emb_val other: 0.27628312\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 5800/9807; Global_step=5800; lr=2.493e-05; train time per batch = 1.51\n",
      "Train: global step = 5800; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8865\n",
      "    -      history_passage loss: 1.9816\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8554\n",
      "    -             emb_val other: 0.27609265\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 0: Step: 5900/9807; Global_step=5900; lr=2.483e-05; train time per batch = 1.51\n",
      "Train: global step = 5900; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9952\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 8.9279\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9442\n",
      "    -             emb_val other: 0.27519867\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11854.5927\n",
      "Epoch: 0: Step: 6000/9807; Global_step=6000; lr=2.472e-05; train time per batch = 1.51\n",
      "Train: global step = 6000; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9909\n",
      "    -                  end loss: 3.9507\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0018\n",
      "    -         history_span loss: 9.1625\n",
      "    -      history_passage loss: 1.9913\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1495\n",
      "    -             emb_val other: 0.27741668\n",
      "    -         eff_perturb other: 0.00000110\n",
      "\n",
      "Validation: Epoch: 0 Step: 6000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 6100/9807; Global_step=6100; lr=2.462e-05; train time per batch = 1.51\n",
      "Train: global step = 6100; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9927\n",
      "    -         history_span loss: 9.0373\n",
      "    -      history_passage loss: 1.9856\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0178\n",
      "    -             emb_val other: 0.27629897\n",
      "    -         eff_perturb other: 0.00000124\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.12308.6154\n",
      "Epoch: 0: Step: 6200/9807; Global_step=6200; lr=2.451e-05; train time per batch = 1.51\n",
      "Train: global step = 6200; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9985\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9602\n",
      "    -         history_span loss: 9.1018\n",
      "    -      history_passage loss: 1.9549\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0233\n",
      "    -             emb_val other: 0.27452242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 0: Step: 6300/9807; Global_step=6300; lr=2.441e-05; train time per batch = 1.51\n",
      "Train: global step = 6300; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9659\n",
      "    -         history_span loss: 9.1764\n",
      "    -      history_passage loss: 1.9571\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1010\n",
      "    -             emb_val other: 0.27559462\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 6400/9807; Global_step=6400; lr=2.430e-05; train time per batch = 1.51\n",
      "Train: global step = 6400; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9872\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0060\n",
      "    -         history_span loss: 9.0891\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0903\n",
      "    -             emb_val other: 0.27663863\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.12846.6423\n",
      "Epoch: 0: Step: 6500/9807; Global_step=6500; lr=2.419e-05; train time per batch = 1.51\n",
      "Train: global step = 6500; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0102\n",
      "    -                  end loss: 3.9483\n",
      "    -                 span loss: 7.9585\n",
      "    -              passage loss: 2.0067\n",
      "    -         history_span loss: 9.1157\n",
      "    -      history_passage loss: 1.9965\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1306\n",
      "    -             emb_val other: 0.27579606\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 6600/9807; Global_step=6600; lr=2.409e-05; train time per batch = 1.51\n",
      "Train: global step = 6600; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9619\n",
      "    -                 span loss: 7.9522\n",
      "    -              passage loss: 1.9880\n",
      "    -         history_span loss: 8.9048\n",
      "    -      history_passage loss: 1.9871\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8847\n",
      "    -             emb_val other: 0.27534875\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.13314.6657\n",
      "Epoch: 0: Step: 6700/9807; Global_step=6700; lr=2.398e-05; train time per batch = 1.51\n",
      "Train: global step = 6700; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0030\n",
      "    -                  end loss: 3.9497\n",
      "    -                 span loss: 7.9527\n",
      "    -              passage loss: 2.0075\n",
      "    -         history_span loss: 9.2673\n",
      "    -      history_passage loss: 1.9911\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.2750\n",
      "    -             emb_val other: 0.27513123\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 6800/9807; Global_step=6800; lr=2.388e-05; train time per batch = 1.51\n",
      "Train: global step = 6800; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9710\n",
      "    -                 span loss: 7.9558\n",
      "    -              passage loss: 1.9905\n",
      "    -         history_span loss: 8.9291\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9376\n",
      "    -             emb_val other: 0.27625322\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 6900/9807; Global_step=6900; lr=2.377e-05; train time per batch = 1.51\n",
      "Train: global step = 6900; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9607\n",
      "    -                 span loss: 7.9578\n",
      "    -              passage loss: 1.9862\n",
      "    -         history_span loss: 8.9226\n",
      "    -      history_passage loss: 1.9872\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9079\n",
      "    -             emb_val other: 0.27606720\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.13866.6933\n",
      "Epoch: 0: Step: 7000/9807; Global_step=7000; lr=2.367e-05; train time per batch = 1.51\n",
      "Train: global step = 7000; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9845\n",
      "    -                  end loss: 3.9657\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 2.0127\n",
      "    -         history_span loss: 8.9778\n",
      "    -      history_passage loss: 2.0107\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0100\n",
      "    -             emb_val other: 0.27585945\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Validation: Epoch: 0 Step: 7000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 7100/9807; Global_step=7100; lr=2.356e-05; train time per batch = 1.51\n",
      "Train: global step = 7100; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9880\n",
      "    -                  end loss: 3.9588\n",
      "    -                 span loss: 7.9468\n",
      "    -              passage loss: 1.9866\n",
      "    -         history_span loss: 9.0677\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0380\n",
      "    -             emb_val other: 0.27670929\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.14302.7151\n",
      "Epoch: 0: Step: 7200/9807; Global_step=7200; lr=2.346e-05; train time per batch = 1.51\n",
      "Train: global step = 7200; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9823\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9358\n",
      "    -              passage loss: 2.0028\n",
      "    -         history_span loss: 9.0188\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0087\n",
      "    -             emb_val other: 0.27722108\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 0: Step: 7300/9807; Global_step=7300; lr=2.335e-05; train time per batch = 1.51\n",
      "Train: global step = 7300; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0015\n",
      "    -                  end loss: 3.9547\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9340\n",
      "    -         history_span loss: 8.9996\n",
      "    -      history_passage loss: 1.9280\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8690\n",
      "    -             emb_val other: 0.27567086\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 7500/9807; Global_step=7500; lr=2.314e-05; train time per batch = 1.51\n",
      "Train: global step = 7500; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9502\n",
      "    -              passage loss: 1.9900\n",
      "    -         history_span loss: 8.9454\n",
      "    -      history_passage loss: 1.9809\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9201\n",
      "    -             emb_val other: 0.27629513\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 0: Step: 7600/9807; Global_step=7600; lr=2.303e-05; train time per batch = 1.51\n",
      "Train: global step = 7600; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9572\n",
      "    -                 span loss: 7.9489\n",
      "    -              passage loss: 1.9849\n",
      "    -         history_span loss: 8.8690\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8417\n",
      "    -             emb_val other: 0.27590010\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15364.7682\n",
      "Epoch: 0: Step: 7700/9807; Global_step=7700; lr=2.293e-05; train time per batch = 1.51\n",
      "Train: global step = 7700; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9545\n",
      "    -         history_span loss: 8.7893\n",
      "    -      history_passage loss: 1.9477\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.6940\n",
      "    -             emb_val other: 0.27498001\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 0: Step: 7800/9807; Global_step=7800; lr=2.282e-05; train time per batch = 1.51\n",
      "Train: global step = 7800; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9480\n",
      "    -                 span loss: 7.9394\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 9.0379\n",
      "    -      history_passage loss: 1.9992\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0284\n",
      "    -             emb_val other: 0.27694300\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 0: Step: 7900/9807; Global_step=7900; lr=2.272e-05; train time per batch = 1.51\n",
      "Train: global step = 7900; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9820\n",
      "    -                  end loss: 3.9698\n",
      "    -                 span loss: 7.9519\n",
      "    -              passage loss: 1.9882\n",
      "    -         history_span loss: 9.0342\n",
      "    -      history_passage loss: 2.0003\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 21.0271\n",
      "    -             emb_val other: 0.27663869\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15950.7975\n",
      "Epoch: 0: Step: 8000/9807; Global_step=8000; lr=2.261e-05; train time per batch = 1.51\n",
      "Train: global step = 8000; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9866\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9381\n",
      "    -              passage loss: 2.0139\n",
      "    -         history_span loss: 9.1433\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1490\n",
      "    -             emb_val other: 0.27531275\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Validation: Epoch: 0 Step: 8000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 8100/9807; Global_step=8100; lr=2.251e-05; train time per batch = 1.51\n",
      "Train: global step = 8100; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9886\n",
      "    -                  end loss: 3.9587\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 2.0223\n",
      "    -         history_span loss: 9.3031\n",
      "    -      history_passage loss: 2.0246\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.3551\n",
      "    -             emb_val other: 0.27587658\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.16378.8189\n",
      "Epoch: 0: Step: 8200/9807; Global_step=8200; lr=2.240e-05; train time per batch = 1.51\n",
      "Train: global step = 8200; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0027\n",
      "    -         history_span loss: 8.8936\n",
      "    -      history_passage loss: 2.0010\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9048\n",
      "    -             emb_val other: 0.27636260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 0: Step: 8300/9807; Global_step=8300; lr=2.229e-05; train time per batch = 1.51\n",
      "Train: global step = 8300; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9804\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9386\n",
      "    -              passage loss: 2.0099\n",
      "    -         history_span loss: 9.0721\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0882\n",
      "    -             emb_val other: 0.27487475\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Epoch: 0: Step: 8400/9807; Global_step=8400; lr=2.219e-05; train time per batch = 1.51\n",
      "Train: global step = 8400; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9980\n",
      "    -                  end loss: 3.9577\n",
      "    -                 span loss: 7.9557\n",
      "    -              passage loss: 1.9487\n",
      "    -         history_span loss: 9.0075\n",
      "    -      history_passage loss: 1.9532\n",
      "    -            adv_start loss: 0.0028\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9151\n",
      "    -             emb_val other: 0.27455506\n",
      "    -         eff_perturb other: 0.00000171\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.16892.8446\n",
      "Epoch: 0: Step: 8500/9807; Global_step=8500; lr=2.208e-05; train time per batch = 1.51\n",
      "Train: global step = 8500; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9457\n",
      "    -                 span loss: 7.9446\n",
      "    -              passage loss: 1.9601\n",
      "    -         history_span loss: 8.9329\n",
      "    -      history_passage loss: 1.9572\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8481\n",
      "    -             emb_val other: 0.27500150\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 0: Step: 8600/9807; Global_step=8600; lr=2.198e-05; train time per batch = 1.51\n",
      "Train: global step = 8600; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9842\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9406\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0033\n",
      "    -      history_passage loss: 1.9682\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9337\n",
      "    -             emb_val other: 0.27566877\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 0: Step: 8700/9807; Global_step=8700; lr=2.187e-05; train time per batch = 1.51\n",
      "Train: global step = 8700; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9873\n",
      "    -                  end loss: 3.9465\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 1.9752\n",
      "    -         history_span loss: 8.9455\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8744\n",
      "    -             emb_val other: 0.27678972\n",
      "    -         eff_perturb other: 0.00000158\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.17480.8740\n",
      "Epoch: 0: Step: 8800/9807; Global_step=8800; lr=2.177e-05; train time per batch = 1.51\n",
      "Train: global step = 8800; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9866\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 1.9971\n",
      "    -         history_span loss: 9.1325\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1259\n",
      "    -             emb_val other: 0.27586383\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 0: Step: 8900/9807; Global_step=8900; lr=2.166e-05; train time per batch = 1.51\n",
      "Train: global step = 8900; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9922\n",
      "    -                  end loss: 3.9505\n",
      "    -                 span loss: 7.9428\n",
      "    -              passage loss: 2.0165\n",
      "    -         history_span loss: 9.1788\n",
      "    -      history_passage loss: 2.0080\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2018\n",
      "    -             emb_val other: 0.27680466\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 0: Step: 9000/9807; Global_step=9000; lr=2.156e-05; train time per batch = 1.51\n",
      "Train: global step = 9000; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9530\n",
      "    -              passage loss: 1.9855\n",
      "    -         history_span loss: 8.9586\n",
      "    -      history_passage loss: 1.9868\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9368\n",
      "    -             emb_val other: 0.27589667\n",
      "    -         eff_perturb other: 0.00000156\n",
      "\n",
      "Validation: Epoch: 0 Step: 9000/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18002.9001\n",
      "Epoch: 0: Step: 9100/9807; Global_step=9100; lr=2.145e-05; train time per batch = 1.51\n",
      "Train: global step = 9100; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9521\n",
      "    -                 span loss: 7.9469\n",
      "    -              passage loss: 1.9518\n",
      "    -         history_span loss: 8.8601\n",
      "    -      history_passage loss: 1.9453\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7592\n",
      "    -             emb_val other: 0.27497700\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Epoch: 0: Step: 9200/9807; Global_step=9200; lr=2.134e-05; train time per batch = 1.51\n",
      "Train: global step = 9200; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9967\n",
      "    -                  end loss: 3.9602\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 1.9984\n",
      "    -         history_span loss: 8.8960\n",
      "    -      history_passage loss: 1.9915\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8974\n",
      "    -             emb_val other: 0.27608368\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Epoch: 0: Step: 9300/9807; Global_step=9300; lr=2.124e-05; train time per batch = 1.51\n",
      "Train: global step = 9300; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9948\n",
      "    -                  end loss: 3.9539\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0071\n",
      "    -         history_span loss: 8.7872\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8144\n",
      "    -             emb_val other: 0.27703959\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18624.9312\n",
      "Epoch: 0: Step: 9400/9807; Global_step=9400; lr=2.113e-05; train time per batch = 1.51\n",
      "Train: global step = 9400; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9802\n",
      "    -                  end loss: 3.9523\n",
      "    -                 span loss: 7.9325\n",
      "    -              passage loss: 1.9874\n",
      "    -         history_span loss: 8.9604\n",
      "    -      history_passage loss: 1.9973\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9316\n",
      "    -             emb_val other: 0.27661490\n",
      "    -         eff_perturb other: 0.00000169\n",
      "\n",
      "Epoch: 0: Step: 9500/9807; Global_step=9500; lr=2.103e-05; train time per batch = 1.51\n",
      "Train: global step = 9500; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9854\n",
      "    -                  end loss: 3.9623\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.9132\n",
      "    -      history_passage loss: 1.9998\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9060\n",
      "    -             emb_val other: 0.27795157\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 0: Step: 9600/9807; Global_step=9600; lr=2.092e-05; train time per batch = 1.51\n",
      "Train: global step = 9600; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0013\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 2.0271\n",
      "    -         history_span loss: 9.1246\n",
      "    -      history_passage loss: 2.0232\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1903\n",
      "    -             emb_val other: 0.27589342\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.19240.9620\n",
      "Epoch: 0: Step: 9700/9807; Global_step=9700; lr=2.082e-05; train time per batch = 1.51\n",
      "Train: global step = 9700; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9540\n",
      "    -                 span loss: 7.9445\n",
      "    -              passage loss: 2.0051\n",
      "    -         history_span loss: 8.8303\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.8410\n",
      "    -             emb_val other: 0.27555186\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 0: Step: 9800/9807; Global_step=9800; lr=2.071e-05; train time per batch = 1.51\n",
      "Train: global step = 9800; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9462\n",
      "    -                 span loss: 7.9521\n",
      "    -              passage loss: 1.9917\n",
      "    -         history_span loss: 8.8695\n",
      "    -      history_passage loss: 1.9898\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.8560\n",
      "    -             emb_val other: 0.27552018\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Avg. total Loss of epoch 0 =21.009\n",
      "================================================================================\n",
      "                                    Epoch 1\n",
      "================================================================================\n",
      "Epoch: 1: Step: 93/9807; Global_step=9900; lr=2.061e-05; train time per batch = 1.48\n",
      "Train: global step = 9907; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0029\n",
      "    -                  end loss: 3.9627\n",
      "    -                 span loss: 7.9656\n",
      "    -              passage loss: 1.9664\n",
      "    -         history_span loss: 9.1381\n",
      "    -      history_passage loss: 1.9804\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1069\n",
      "    -             emb_val other: 0.27560779\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 1: Step: 193/9807; Global_step=10000; lr=2.050e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 10007; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9898\n",
      "    -                  end loss: 3.9626\n",
      "    -                 span loss: 7.9523\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8406\n",
      "    -      history_passage loss: 2.0330\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9080\n",
      "    -             emb_val other: 0.27706259\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.450.10032\n",
      "Epoch: 1: Step: 293/9807; Global_step=10100; lr=2.039e-05; train time per batch = 1.49\n",
      "Train: global step = 10107; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9914\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9455\n",
      "    -              passage loss: 1.9941\n",
      "    -         history_span loss: 8.9621\n",
      "    -      history_passage loss: 1.9966\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9546\n",
      "    -             emb_val other: 0.27553037\n",
      "    -         eff_perturb other: 0.00000218\n",
      "\n",
      "Epoch: 1: Step: 393/9807; Global_step=10200; lr=2.029e-05; train time per batch = 1.49\n",
      "Train: global step = 10207; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9535\n",
      "    -                 span loss: 7.9383\n",
      "    -              passage loss: 1.9966\n",
      "    -         history_span loss: 9.0171\n",
      "    -      history_passage loss: 1.9910\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9965\n",
      "    -             emb_val other: 0.27761611\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 1: Step: 493/9807; Global_step=10300; lr=2.018e-05; train time per batch = 1.50\n",
      "Train: global step = 10307; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9439\n",
      "    -              passage loss: 2.0243\n",
      "    -         history_span loss: 9.0539\n",
      "    -      history_passage loss: 2.0236\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0998\n",
      "    -             emb_val other: 0.27513096\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1068.10341\n",
      "Epoch: 1: Step: 593/9807; Global_step=10400; lr=2.008e-05; train time per batch = 1.50\n",
      "Train: global step = 10407; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9925\n",
      "    -                  end loss: 3.9637\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 1.9771\n",
      "    -         history_span loss: 9.0702\n",
      "    -      history_passage loss: 1.9713\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.0310\n",
      "    -             emb_val other: 0.27559817\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 1: Step: 693/9807; Global_step=10500; lr=1.997e-05; train time per batch = 1.50\n",
      "Train: global step = 10507; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9862\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9616\n",
      "    -         history_span loss: 9.1537\n",
      "    -      history_passage loss: 1.9504\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0657\n",
      "    -             emb_val other: 0.27465016\n",
      "    -         eff_perturb other: 0.00000194\n",
      "\n",
      "Epoch: 1: Step: 793/9807; Global_step=10600; lr=1.987e-05; train time per batch = 1.50\n",
      "Train: global step = 10607; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9474\n",
      "    -                 span loss: 7.9425\n",
      "    -              passage loss: 2.0218\n",
      "    -         history_span loss: 9.1308\n",
      "    -      history_passage loss: 2.0081\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1599\n",
      "    -             emb_val other: 0.27554685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1690.10652\n",
      "Epoch: 1: Step: 893/9807; Global_step=10700; lr=1.976e-05; train time per batch = 1.50\n",
      "Train: global step = 10707; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9969\n",
      "    -                  end loss: 3.9427\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9863\n",
      "    -         history_span loss: 9.0427\n",
      "    -      history_passage loss: 1.9700\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0058\n",
      "    -                total loss: 20.9979\n",
      "    -             emb_val other: 0.27506685\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 1: Step: 993/9807; Global_step=10800; lr=1.966e-05; train time per batch = 1.50\n",
      "Train: global step = 10807; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9928\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9570\n",
      "    -              passage loss: 2.0037\n",
      "    -         history_span loss: 9.1359\n",
      "    -      history_passage loss: 2.0053\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1566\n",
      "    -             emb_val other: 0.27612543\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 1093/9807; Global_step=10900; lr=1.955e-05; train time per batch = 1.50\n",
      "Train: global step = 10907; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9513\n",
      "    -                 span loss: 7.9413\n",
      "    -              passage loss: 1.9920\n",
      "    -         history_span loss: 8.9912\n",
      "    -      history_passage loss: 1.9923\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9697\n",
      "    -             emb_val other: 0.27564260\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2310.10962\n",
      "Epoch: 1: Step: 1193/9807; Global_step=11000; lr=1.944e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 1193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 11007; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9524\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0002\n",
      "    -         history_span loss: 8.9556\n",
      "    -      history_passage loss: 2.0030\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9563\n",
      "    -             emb_val other: 0.27449274\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 1293/9807; Global_step=11100; lr=1.934e-05; train time per batch = 1.50\n",
      "Train: global step = 11107; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9924\n",
      "    -                  end loss: 3.9605\n",
      "    -                 span loss: 7.9529\n",
      "    -              passage loss: 2.0373\n",
      "    -         history_span loss: 8.9785\n",
      "    -      history_passage loss: 2.0198\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0424\n",
      "    -             emb_val other: 0.27660847\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2754.11184\n",
      "Epoch: 1: Step: 1393/9807; Global_step=11200; lr=1.923e-05; train time per batch = 1.50\n",
      "Train: global step = 11207; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9964\n",
      "    -         history_span loss: 9.0059\n",
      "    -      history_passage loss: 1.9928\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9984\n",
      "    -             emb_val other: 0.27549130\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 1: Step: 1493/9807; Global_step=11300; lr=1.913e-05; train time per batch = 1.50\n",
      "Train: global step = 11307; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9459\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.0162\n",
      "    -      history_passage loss: 2.0050\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0327\n",
      "    -             emb_val other: 0.27677551\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Epoch: 1: Step: 1593/9807; Global_step=11400; lr=1.902e-05; train time per batch = 1.50\n",
      "Train: global step = 11407; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 1.9735\n",
      "    -         history_span loss: 9.0643\n",
      "    -      history_passage loss: 1.9732\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0106\n",
      "    -             emb_val other: 0.27586836\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.3380.11497\n",
      "Epoch: 1: Step: 1693/9807; Global_step=11500; lr=1.892e-05; train time per batch = 1.50\n",
      "Train: global step = 11507; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9879\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 1.9864\n",
      "    -         history_span loss: 9.3993\n",
      "    -      history_passage loss: 1.9836\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.3589\n",
      "    -             emb_val other: 0.27617666\n",
      "    -         eff_perturb other: 0.00000160\n",
      "\n",
      "Epoch: 1: Step: 1793/9807; Global_step=11600; lr=1.881e-05; train time per batch = 1.50\n",
      "Train: global step = 11607; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9973\n",
      "    -                  end loss: 3.9546\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 2.0093\n",
      "    -         history_span loss: 9.1000\n",
      "    -      history_passage loss: 2.0057\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1207\n",
      "    -             emb_val other: 0.27521113\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 1: Step: 1893/9807; Global_step=11700; lr=1.871e-05; train time per batch = 1.50\n",
      "Train: global step = 11707; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9787\n",
      "    -                  end loss: 3.9464\n",
      "    -                 span loss: 7.9251\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 9.3338\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2336\n",
      "    -             emb_val other: 0.27513120\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 1993/9807; Global_step=11800; lr=1.860e-05; train time per batch = 1.50\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4000.11807\n",
      "Train: global step = 11807; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0008\n",
      "    -                  end loss: 3.9575\n",
      "    -                 span loss: 7.9583\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 8.8437\n",
      "    -      history_passage loss: 1.9642\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7785\n",
      "    -             emb_val other: 0.27490121\n",
      "    -         eff_perturb other: 0.00000137\n",
      "\n",
      "Epoch: 1: Step: 2093/9807; Global_step=11900; lr=1.849e-05; train time per batch = 1.50\n",
      "Train: global step = 11907; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9949\n",
      "    -                  end loss: 3.9365\n",
      "    -                 span loss: 7.9313\n",
      "    -              passage loss: 1.9860\n",
      "    -         history_span loss: 8.7881\n",
      "    -      history_passage loss: 1.9851\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7457\n",
      "    -             emb_val other: 0.27495745\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 2193/9807; Global_step=12000; lr=1.839e-05; train time per batch = 1.49\n",
      "Validation: Epoch: 1 Step: 2193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 12007; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9474\n",
      "    -              passage loss: 1.9609\n",
      "    -         history_span loss: 8.9000\n",
      "    -      history_passage loss: 1.9619\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8250\n",
      "    -             emb_val other: 0.27509722\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4456.12035\n",
      "Epoch: 1: Step: 2293/9807; Global_step=12100; lr=1.828e-05; train time per batch = 1.49\n",
      "Train: global step = 12107; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9901\n",
      "    -                  end loss: 3.9636\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 2.0200\n",
      "    -         history_span loss: 8.9210\n",
      "    -      history_passage loss: 2.0130\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9650\n",
      "    -             emb_val other: 0.27607048\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 2393/9807; Global_step=12200; lr=1.818e-05; train time per batch = 1.49\n",
      "Train: global step = 12207; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0035\n",
      "    -                  end loss: 3.9610\n",
      "    -                 span loss: 7.9645\n",
      "    -              passage loss: 2.0016\n",
      "    -         history_span loss: 8.8582\n",
      "    -      history_passage loss: 2.0002\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8790\n",
      "    -             emb_val other: 0.27457252\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 1: Step: 2493/9807; Global_step=12300; lr=1.807e-05; train time per batch = 1.49\n",
      "Train: global step = 12307; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9890\n",
      "    -                  end loss: 3.9511\n",
      "    -                 span loss: 7.9401\n",
      "    -              passage loss: 1.9669\n",
      "    -         history_span loss: 8.8598\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7912\n",
      "    -             emb_val other: 0.27571741\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5068.12341\n",
      "Epoch: 1: Step: 2593/9807; Global_step=12400; lr=1.797e-05; train time per batch = 1.49\n",
      "Train: global step = 12407; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9904\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0020\n",
      "    -         history_span loss: 9.0364\n",
      "    -      history_passage loss: 2.0154\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0523\n",
      "    -             emb_val other: 0.27602518\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Epoch: 1: Step: 2693/9807; Global_step=12500; lr=1.786e-05; train time per batch = 1.50\n",
      "Train: global step = 12507; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0024\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9590\n",
      "    -              passage loss: 2.0391\n",
      "    -         history_span loss: 9.1507\n",
      "    -      history_passage loss: 2.0310\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2343\n",
      "    -             emb_val other: 0.27676222\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 2793/9807; Global_step=12600; lr=1.776e-05; train time per batch = 1.50\n",
      "Train: global step = 12607; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9493\n",
      "    -              passage loss: 1.9819\n",
      "    -         history_span loss: 9.1731\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1477\n",
      "    -             emb_val other: 0.27653170\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5682.12648\n",
      "Epoch: 1: Step: 2893/9807; Global_step=12700; lr=1.765e-05; train time per batch = 1.50\n",
      "Train: global step = 12707; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9931\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0141\n",
      "    -         history_span loss: 8.9224\n",
      "    -      history_passage loss: 2.0176\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9636\n",
      "    -             emb_val other: 0.27731833\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 1: Step: 2993/9807; Global_step=12800; lr=1.754e-05; train time per batch = 1.50\n",
      "Train: global step = 12807; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9498\n",
      "    -                 span loss: 7.9416\n",
      "    -              passage loss: 2.0105\n",
      "    -         history_span loss: 9.0754\n",
      "    -      history_passage loss: 2.0168\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1033\n",
      "    -             emb_val other: 0.27521381\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 3093/9807; Global_step=12900; lr=1.744e-05; train time per batch = 1.50\n",
      "Train: global step = 12907; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9875\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9397\n",
      "    -              passage loss: 1.9785\n",
      "    -         history_span loss: 9.2084\n",
      "    -      history_passage loss: 1.9822\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1605\n",
      "    -             emb_val other: 0.27617440\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6302.12958\n",
      "Epoch: 1: Step: 3193/9807; Global_step=13000; lr=1.733e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 3193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 13007; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9939\n",
      "    -                  end loss: 3.9520\n",
      "    -                 span loss: 7.9459\n",
      "    -              passage loss: 1.9879\n",
      "    -         history_span loss: 8.8245\n",
      "    -      history_passage loss: 1.9782\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0031\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7940\n",
      "    -             emb_val other: 0.27349240\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 1: Step: 3293/9807; Global_step=13100; lr=1.723e-05; train time per batch = 1.50\n",
      "Train: global step = 13107; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9868\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9512\n",
      "    -              passage loss: 1.9606\n",
      "    -         history_span loss: 9.0673\n",
      "    -      history_passage loss: 1.9737\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0120\n",
      "    -             emb_val other: 0.27484637\n",
      "    -         eff_perturb other: 0.00000183\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6760.13187\n",
      "Epoch: 1: Step: 3393/9807; Global_step=13200; lr=1.712e-05; train time per batch = 1.50\n",
      "Train: global step = 13207; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0121\n",
      "    -                  end loss: 3.9609\n",
      "    -                 span loss: 7.9731\n",
      "    -              passage loss: 1.9739\n",
      "    -         history_span loss: 8.9081\n",
      "    -      history_passage loss: 1.9829\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8917\n",
      "    -             emb_val other: 0.27607408\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 1: Step: 3493/9807; Global_step=13300; lr=1.702e-05; train time per batch = 1.50\n",
      "Train: global step = 13307; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9860\n",
      "    -                  end loss: 3.9722\n",
      "    -                 span loss: 7.9582\n",
      "    -              passage loss: 2.0262\n",
      "    -         history_span loss: 8.9862\n",
      "    -      history_passage loss: 2.0211\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0458\n",
      "    -             emb_val other: 0.27722073\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 1: Step: 3593/9807; Global_step=13400; lr=1.691e-05; train time per batch = 1.50\n",
      "Train: global step = 13407; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0042\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9605\n",
      "    -              passage loss: 2.0115\n",
      "    -         history_span loss: 8.6957\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.7369\n",
      "    -             emb_val other: 0.27645412\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7376.13495\n",
      "Epoch: 1: Step: 3693/9807; Global_step=13500; lr=1.681e-05; train time per batch = 1.50\n",
      "Train: global step = 13507; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9531\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0182\n",
      "    -         history_span loss: 8.9357\n",
      "    -      history_passage loss: 2.0033\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9625\n",
      "    -             emb_val other: 0.27678561\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 3793/9807; Global_step=13600; lr=1.670e-05; train time per batch = 1.50\n",
      "Train: global step = 13607; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9431\n",
      "    -              passage loss: 1.9814\n",
      "    -         history_span loss: 8.9165\n",
      "    -      history_passage loss: 1.9802\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8742\n",
      "    -             emb_val other: 0.27615097\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 1: Step: 3893/9807; Global_step=13700; lr=1.659e-05; train time per batch = 1.50\n",
      "Train: global step = 13707; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9906\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9487\n",
      "    -              passage loss: 2.0195\n",
      "    -         history_span loss: 8.8802\n",
      "    -      history_passage loss: 2.0086\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9146\n",
      "    -             emb_val other: 0.27567688\n",
      "    -         eff_perturb other: 0.00000186\n",
      "\n",
      "Epoch: 1: Step: 3993/9807; Global_step=13800; lr=1.649e-05; train time per batch = 1.50\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7996.13805\n",
      "Train: global step = 13807; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9817\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9384\n",
      "    -              passage loss: 1.9747\n",
      "    -         history_span loss: 9.1005\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0428\n",
      "    -             emb_val other: 0.27584198\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 1: Step: 4093/9807; Global_step=13900; lr=1.638e-05; train time per batch = 1.50\n",
      "Train: global step = 13907; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0001\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9568\n",
      "    -              passage loss: 2.0142\n",
      "    -         history_span loss: 9.0730\n",
      "    -      history_passage loss: 1.9901\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0873\n",
      "    -             emb_val other: 0.27592555\n",
      "    -         eff_perturb other: 0.00000161\n",
      "\n",
      "Epoch: 1: Step: 4193/9807; Global_step=14000; lr=1.628e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 4193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 14007; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9423\n",
      "    -                 span loss: 7.9391\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 8.8066\n",
      "    -      history_passage loss: 2.0011\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.8130\n",
      "    -             emb_val other: 0.27769196\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8444.14029\n",
      "Epoch: 1: Step: 4393/9807; Global_step=14200; lr=1.607e-05; train time per batch = 1.50\n",
      "Train: global step = 14207; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0068\n",
      "    -                  end loss: 3.9543\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9753\n",
      "    -         history_span loss: 8.9842\n",
      "    -      history_passage loss: 1.9703\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9436\n",
      "    -             emb_val other: 0.27614722\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 1: Step: 4493/9807; Global_step=14300; lr=1.596e-05; train time per batch = 1.50\n",
      "Train: global step = 14307; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9921\n",
      "    -                  end loss: 3.9616\n",
      "    -                 span loss: 7.9536\n",
      "    -              passage loss: 1.9903\n",
      "    -         history_span loss: 8.8295\n",
      "    -      history_passage loss: 1.9891\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8198\n",
      "    -             emb_val other: 0.27651179\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9058.14336\n",
      "Epoch: 1: Step: 4593/9807; Global_step=14400; lr=1.586e-05; train time per batch = 1.50\n",
      "Train: global step = 14407; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9562\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 2.0128\n",
      "    -         history_span loss: 9.0327\n",
      "    -      history_passage loss: 2.0048\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0571\n",
      "    -             emb_val other: 0.27614293\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 4693/9807; Global_step=14500; lr=1.575e-05; train time per batch = 1.50\n",
      "Train: global step = 14507; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9937\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9817\n",
      "    -         history_span loss: 9.0039\n",
      "    -      history_passage loss: 1.9922\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9795\n",
      "    -             emb_val other: 0.27605405\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 4793/9807; Global_step=14600; lr=1.564e-05; train time per batch = 1.50\n",
      "Train: global step = 14607; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0075\n",
      "    -                  end loss: 3.9538\n",
      "    -                 span loss: 7.9612\n",
      "    -              passage loss: 2.0136\n",
      "    -         history_span loss: 9.2063\n",
      "    -      history_passage loss: 1.9997\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2358\n",
      "    -             emb_val other: 0.27626783\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9680.14647\n",
      "Epoch: 1: Step: 4893/9807; Global_step=14700; lr=1.554e-05; train time per batch = 1.50\n",
      "Train: global step = 14707; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9578\n",
      "    -                 span loss: 7.9524\n",
      "    -              passage loss: 1.9926\n",
      "    -         history_span loss: 9.1422\n",
      "    -      history_passage loss: 1.9823\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.1243\n",
      "    -             emb_val other: 0.27685645\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 1: Step: 4993/9807; Global_step=14800; lr=1.543e-05; train time per batch = 1.50\n",
      "Train: global step = 14807; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9816\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9350\n",
      "    -              passage loss: 1.9892\n",
      "    -         history_span loss: 9.0125\n",
      "    -      history_passage loss: 1.9762\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9652\n",
      "    -             emb_val other: 0.27527630\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 1: Step: 5093/9807; Global_step=14900; lr=1.533e-05; train time per batch = 1.50\n",
      "Train: global step = 14907; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0028\n",
      "    -                  end loss: 3.9548\n",
      "    -                 span loss: 7.9576\n",
      "    -              passage loss: 1.9846\n",
      "    -         history_span loss: 9.0158\n",
      "    -      history_passage loss: 1.9847\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9973\n",
      "    -             emb_val other: 0.27496317\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10298.14956\n",
      "Epoch: 1: Step: 5193/9807; Global_step=15000; lr=1.522e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 5193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 15007; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9534\n",
      "    -              passage loss: 1.9693\n",
      "    -         history_span loss: 9.0368\n",
      "    -      history_passage loss: 1.9753\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9873\n",
      "    -             emb_val other: 0.27540338\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 1: Step: 5293/9807; Global_step=15100; lr=1.512e-05; train time per batch = 1.50\n",
      "Train: global step = 15107; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9934\n",
      "    -                  end loss: 3.9669\n",
      "    -                 span loss: 7.9603\n",
      "    -              passage loss: 1.9839\n",
      "    -         history_span loss: 8.8100\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.7952\n",
      "    -             emb_val other: 0.27592626\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10746.15180\n",
      "Epoch: 1: Step: 5393/9807; Global_step=15200; lr=1.501e-05; train time per batch = 1.50\n",
      "Train: global step = 15207; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9855\n",
      "    -                  end loss: 3.9606\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 2.0035\n",
      "    -         history_span loss: 8.9616\n",
      "    -      history_passage loss: 2.0101\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9751\n",
      "    -             emb_val other: 0.27645674\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Epoch: 1: Step: 5493/9807; Global_step=15300; lr=1.491e-05; train time per batch = 1.50\n",
      "Train: global step = 15307; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9736\n",
      "    -                  end loss: 3.9512\n",
      "    -                 span loss: 7.9248\n",
      "    -              passage loss: 2.0459\n",
      "    -         history_span loss: 8.8868\n",
      "    -      history_passage loss: 2.0403\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9527\n",
      "    -             emb_val other: 0.27541244\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 5593/9807; Global_step=15400; lr=1.480e-05; train time per batch = 1.50\n",
      "Train: global step = 15407; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0059\n",
      "    -                  end loss: 3.9551\n",
      "    -                 span loss: 7.9610\n",
      "    -              passage loss: 1.9593\n",
      "    -         history_span loss: 9.0491\n",
      "    -      history_passage loss: 1.9657\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 20.9861\n",
      "    -             emb_val other: 0.27585569\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.11360.15487\n",
      "Epoch: 1: Step: 5693/9807; Global_step=15500; lr=1.469e-05; train time per batch = 1.50\n",
      "Train: global step = 15507; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9927\n",
      "    -                  end loss: 3.9574\n",
      "    -                 span loss: 7.9500\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 9.0387\n",
      "    -      history_passage loss: 2.0067\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0563\n",
      "    -             emb_val other: 0.27559242\n",
      "    -         eff_perturb other: 0.00000148\n",
      "\n",
      "Epoch: 1: Step: 5793/9807; Global_step=15600; lr=1.459e-05; train time per batch = 1.50\n",
      "Train: global step = 15607; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9869\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9410\n",
      "    -              passage loss: 2.0076\n",
      "    -         history_span loss: 9.2745\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2814\n",
      "    -             emb_val other: 0.27620414\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 1: Step: 5893/9807; Global_step=15700; lr=1.448e-05; train time per batch = 1.50\n",
      "Train: global step = 15707; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9944\n",
      "    -                  end loss: 3.9635\n",
      "    -                 span loss: 7.9580\n",
      "    -              passage loss: 2.0303\n",
      "    -         history_span loss: 9.1783\n",
      "    -      history_passage loss: 2.0191\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.2424\n",
      "    -             emb_val other: 0.27538690\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.11970.15792\n",
      "Epoch: 1: Step: 5993/9807; Global_step=15800; lr=1.438e-05; train time per batch = 1.50\n",
      "Train: global step = 15807; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9887\n",
      "    -                  end loss: 3.9596\n",
      "    -                 span loss: 7.9483\n",
      "    -              passage loss: 2.0006\n",
      "    -         history_span loss: 8.9798\n",
      "    -      history_passage loss: 1.9983\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9839\n",
      "    -             emb_val other: 0.27662101\n",
      "    -         eff_perturb other: 0.00000162\n",
      "\n",
      "Epoch: 1: Step: 6093/9807; Global_step=15900; lr=1.427e-05; train time per batch = 1.50\n",
      "Train: global step = 15907; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9892\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 2.0088\n",
      "    -         history_span loss: 8.9674\n",
      "    -      history_passage loss: 2.0163\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9944\n",
      "    -             emb_val other: 0.27684483\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6193/9807; Global_step=16000; lr=1.417e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 6193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 16007; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9682\n",
      "    -                 span loss: 7.9638\n",
      "    -              passage loss: 1.9705\n",
      "    -         history_span loss: 8.8223\n",
      "    -      history_passage loss: 1.9758\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.7868\n",
      "    -             emb_val other: 0.27515936\n",
      "    -         eff_perturb other: 0.00000178\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12416.16015\n",
      "Epoch: 1: Step: 6293/9807; Global_step=16100; lr=1.406e-05; train time per batch = 1.50\n",
      "Train: global step = 16107; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9929\n",
      "    -                  end loss: 3.9475\n",
      "    -                 span loss: 7.9404\n",
      "    -              passage loss: 2.0220\n",
      "    -         history_span loss: 8.8795\n",
      "    -      history_passage loss: 2.0121\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9077\n",
      "    -             emb_val other: 0.27588502\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 1: Step: 6393/9807; Global_step=16200; lr=1.396e-05; train time per batch = 1.50\n",
      "Train: global step = 16207; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9785\n",
      "    -                  end loss: 3.9608\n",
      "    -                 span loss: 7.9393\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 9.2224\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2166\n",
      "    -             emb_val other: 0.27573889\n",
      "    -         eff_perturb other: 0.00000123\n",
      "\n",
      "Epoch: 1: Step: 6493/9807; Global_step=16300; lr=1.385e-05; train time per batch = 1.50\n",
      "Train: global step = 16307; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9563\n",
      "    -                 span loss: 7.9482\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 8.8765\n",
      "    -      history_passage loss: 2.0119\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9205\n",
      "    -             emb_val other: 0.27598554\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13026.16320\n",
      "Epoch: 1: Step: 6593/9807; Global_step=16400; lr=1.374e-05; train time per batch = 1.50\n",
      "Train: global step = 16407; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9976\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9535\n",
      "    -              passage loss: 2.0410\n",
      "    -         history_span loss: 9.0682\n",
      "    -      history_passage loss: 2.0264\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1463\n",
      "    -             emb_val other: 0.27549431\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 1: Step: 6693/9807; Global_step=16500; lr=1.364e-05; train time per batch = 1.50\n",
      "Train: global step = 16507; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0065\n",
      "    -                  end loss: 3.9522\n",
      "    -                 span loss: 7.9588\n",
      "    -              passage loss: 1.9778\n",
      "    -         history_span loss: 8.9854\n",
      "    -      history_passage loss: 1.9844\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9615\n",
      "    -             emb_val other: 0.27585372\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6793/9807; Global_step=16600; lr=1.353e-05; train time per batch = 1.50\n",
      "Train: global step = 16607; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9809\n",
      "    -                  end loss: 3.9671\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 1.9419\n",
      "    -         history_span loss: 9.1481\n",
      "    -      history_passage loss: 1.9449\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0363\n",
      "    -             emb_val other: 0.27662677\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13640.16627\n",
      "Epoch: 1: Step: 6893/9807; Global_step=16700; lr=1.343e-05; train time per batch = 1.50\n",
      "Train: global step = 16707; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0060\n",
      "    -                  end loss: 3.9519\n",
      "    -                 span loss: 7.9579\n",
      "    -              passage loss: 1.9736\n",
      "    -         history_span loss: 9.1705\n",
      "    -      history_passage loss: 1.9587\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1156\n",
      "    -             emb_val other: 0.27487966\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 1: Step: 6993/9807; Global_step=16800; lr=1.332e-05; train time per batch = 1.50\n",
      "Train: global step = 16807; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9955\n",
      "    -                  end loss: 3.9417\n",
      "    -                 span loss: 7.9373\n",
      "    -              passage loss: 1.9723\n",
      "    -         history_span loss: 9.0560\n",
      "    -      history_passage loss: 1.9721\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9909\n",
      "    -             emb_val other: 0.27508208\n",
      "    -         eff_perturb other: 0.00000174\n",
      "\n",
      "Epoch: 1: Step: 7093/9807; Global_step=16900; lr=1.322e-05; train time per batch = 1.50\n",
      "Train: global step = 16907; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0100\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9635\n",
      "    -              passage loss: 2.0089\n",
      "    -         history_span loss: 9.0971\n",
      "    -      history_passage loss: 1.9994\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1221\n",
      "    -             emb_val other: 0.27543363\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14260.16937\n",
      "Epoch: 1: Step: 7193/9807; Global_step=17000; lr=1.311e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 7193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 17007; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9961\n",
      "    -                  end loss: 3.9515\n",
      "    -                 span loss: 7.9476\n",
      "    -              passage loss: 1.9769\n",
      "    -         history_span loss: 9.1368\n",
      "    -      history_passage loss: 1.9848\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1015\n",
      "    -             emb_val other: 0.27627900\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 1: Step: 7293/9807; Global_step=17100; lr=1.301e-05; train time per batch = 1.50\n",
      "Train: global step = 17107; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9982\n",
      "    -                  end loss: 3.9579\n",
      "    -                 span loss: 7.9562\n",
      "    -              passage loss: 2.0034\n",
      "    -         history_span loss: 9.1950\n",
      "    -      history_passage loss: 2.0039\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2109\n",
      "    -             emb_val other: 0.27599686\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14714.17164\n",
      "Epoch: 1: Step: 7393/9807; Global_step=17200; lr=1.290e-05; train time per batch = 1.50\n",
      "Train: global step = 17207; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0033\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9560\n",
      "    -              passage loss: 1.9874\n",
      "    -         history_span loss: 8.9890\n",
      "    -      history_passage loss: 1.9834\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9699\n",
      "    -             emb_val other: 0.27565339\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 7493/9807; Global_step=17300; lr=1.279e-05; train time per batch = 1.50\n",
      "Train: global step = 17307; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9768\n",
      "    -                  end loss: 3.9439\n",
      "    -                 span loss: 7.9207\n",
      "    -              passage loss: 1.9858\n",
      "    -         history_span loss: 9.1428\n",
      "    -      history_passage loss: 1.9805\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0843\n",
      "    -             emb_val other: 0.27610594\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 1: Step: 7593/9807; Global_step=17400; lr=1.269e-05; train time per batch = 1.50\n",
      "Train: global step = 17407; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9830\n",
      "    -                  end loss: 3.9502\n",
      "    -                 span loss: 7.9332\n",
      "    -              passage loss: 2.0078\n",
      "    -         history_span loss: 9.0222\n",
      "    -      history_passage loss: 1.9964\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0151\n",
      "    -             emb_val other: 0.27700680\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.15336.17475\n",
      "Epoch: 1: Step: 7693/9807; Global_step=17500; lr=1.258e-05; train time per batch = 1.50\n",
      "Train: global step = 17507; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0041\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9565\n",
      "    -              passage loss: 1.9950\n",
      "    -         history_span loss: 9.0626\n",
      "    -      history_passage loss: 1.9956\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0643\n",
      "    -             emb_val other: 0.27561495\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 7793/9807; Global_step=17600; lr=1.248e-05; train time per batch = 1.50\n",
      "Train: global step = 17607; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9918\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9477\n",
      "    -              passage loss: 1.9863\n",
      "    -         history_span loss: 9.0139\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9909\n",
      "    -             emb_val other: 0.27687666\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 1: Step: 7893/9807; Global_step=17700; lr=1.237e-05; train time per batch = 1.50\n",
      "Train: global step = 17707; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9516\n",
      "    -                 span loss: 7.9466\n",
      "    -              passage loss: 1.9912\n",
      "    -         history_span loss: 9.1053\n",
      "    -      history_passage loss: 1.9924\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0891\n",
      "    -             emb_val other: 0.27494881\n",
      "    -         eff_perturb other: 0.00000198\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.15958.17786\n",
      "Epoch: 1: Step: 7993/9807; Global_step=17800; lr=1.227e-05; train time per batch = 1.50\n",
      "Train: global step = 17807; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9422\n",
      "    -                 span loss: 7.9343\n",
      "    -              passage loss: 2.0183\n",
      "    -         history_span loss: 8.9779\n",
      "    -      history_passage loss: 2.0237\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0080\n",
      "    -             emb_val other: 0.27566722\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Epoch: 1: Step: 8093/9807; Global_step=17900; lr=1.216e-05; train time per batch = 1.50\n",
      "Train: global step = 17907; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9864\n",
      "    -                  end loss: 3.9576\n",
      "    -                 span loss: 7.9440\n",
      "    -              passage loss: 2.0000\n",
      "    -         history_span loss: 9.1111\n",
      "    -      history_passage loss: 2.0060\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1164\n",
      "    -             emb_val other: 0.27756715\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 1: Step: 8193/9807; Global_step=18000; lr=1.206e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 8193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 18007; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9491\n",
      "    -                 span loss: 7.9461\n",
      "    -              passage loss: 1.9911\n",
      "    -         history_span loss: 9.0270\n",
      "    -      history_passage loss: 1.9839\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0018\n",
      "    -             emb_val other: 0.27568942\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.16404.18009\n",
      "Epoch: 1: Step: 8293/9807; Global_step=18100; lr=1.195e-05; train time per batch = 1.50\n",
      "Train: global step = 18107; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9813\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9369\n",
      "    -              passage loss: 2.0230\n",
      "    -         history_span loss: 9.2119\n",
      "    -      history_passage loss: 2.0249\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.2518\n",
      "    -             emb_val other: 0.27760538\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 1: Step: 8393/9807; Global_step=18200; lr=1.184e-05; train time per batch = 1.50\n",
      "Train: global step = 18207; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9575\n",
      "    -                 span loss: 7.9521\n",
      "    -              passage loss: 1.9859\n",
      "    -         history_span loss: 8.8231\n",
      "    -      history_passage loss: 1.9867\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.8031\n",
      "    -             emb_val other: 0.27607766\n",
      "    -         eff_perturb other: 0.00000115\n",
      "\n",
      "Epoch: 1: Step: 8493/9807; Global_step=18300; lr=1.174e-05; train time per batch = 1.50\n",
      "Train: global step = 18307; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9902\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9419\n",
      "    -              passage loss: 2.0191\n",
      "    -         history_span loss: 9.0198\n",
      "    -      history_passage loss: 2.0162\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0518\n",
      "    -             emb_val other: 0.27463272\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.17014.18314\n",
      "Epoch: 1: Step: 8593/9807; Global_step=18400; lr=1.163e-05; train time per batch = 1.50\n",
      "Train: global step = 18407; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9830\n",
      "    -                  end loss: 3.9534\n",
      "    -                 span loss: 7.9363\n",
      "    -              passage loss: 2.0282\n",
      "    -         history_span loss: 9.1196\n",
      "    -      history_passage loss: 2.0163\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.1553\n",
      "    -             emb_val other: 0.27636725\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 1: Step: 8693/9807; Global_step=18500; lr=1.153e-05; train time per batch = 1.50\n",
      "Train: global step = 18507; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9949\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9510\n",
      "    -              passage loss: 1.9939\n",
      "    -         history_span loss: 9.1550\n",
      "    -      history_passage loss: 1.9905\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.1424\n",
      "    -             emb_val other: 0.27596936\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 1: Step: 8793/9807; Global_step=18600; lr=1.142e-05; train time per batch = 1.50\n",
      "Train: global step = 18607; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9917\n",
      "    -                  end loss: 3.9558\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 1.9530\n",
      "    -         history_span loss: 9.0384\n",
      "    -      history_passage loss: 1.9474\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9415\n",
      "    -             emb_val other: 0.27464107\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.17608.18611\n",
      "Epoch: 1: Step: 8893/9807; Global_step=18700; lr=1.132e-05; train time per batch = 1.50\n",
      "Train: global step = 18707; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0022\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9579\n",
      "    -              passage loss: 1.9688\n",
      "    -         history_span loss: 8.9426\n",
      "    -      history_passage loss: 1.9756\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8990\n",
      "    -             emb_val other: 0.27423498\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 1: Step: 8993/9807; Global_step=18800; lr=1.121e-05; train time per batch = 1.50\n",
      "Train: global step = 18807; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9960\n",
      "    -                  end loss: 3.9583\n",
      "    -                 span loss: 7.9543\n",
      "    -              passage loss: 2.0039\n",
      "    -         history_span loss: 8.9355\n",
      "    -      history_passage loss: 1.9885\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9367\n",
      "    -             emb_val other: 0.27608261\n",
      "    -         eff_perturb other: 0.00000168\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.18058.18836\n",
      "Epoch: 1: Step: 9093/9807; Global_step=18900; lr=1.111e-05; train time per batch = 1.50\n",
      "Train: global step = 18907; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9501\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 2.0191\n",
      "    -         history_span loss: 8.8831\n",
      "    -      history_passage loss: 2.0168\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9162\n",
      "    -             emb_val other: 0.27595818\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 9193/9807; Global_step=19000; lr=1.100e-05; train time per batch = 1.50\n",
      "Validation: Epoch: 1 Step: 9193/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 19007; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9863\n",
      "    -                  end loss: 3.9528\n",
      "    -                 span loss: 7.9392\n",
      "    -              passage loss: 2.0133\n",
      "    -         history_span loss: 8.9163\n",
      "    -      history_passage loss: 2.0135\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.9386\n",
      "    -             emb_val other: 0.27625901\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.18442.19028\n",
      "Epoch: 1: Step: 9293/9807; Global_step=19100; lr=1.089e-05; train time per batch = 1.50\n",
      "Train: global step = 19107; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9968\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 1.9476\n",
      "    -         history_span loss: 8.8473\n",
      "    -      history_passage loss: 1.9534\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7556\n",
      "    -             emb_val other: 0.27441698\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 1: Step: 9393/9807; Global_step=19200; lr=1.079e-05; train time per batch = 1.50\n",
      "Train: global step = 19207; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9943\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9475\n",
      "    -              passage loss: 1.9758\n",
      "    -         history_span loss: 9.0842\n",
      "    -      history_passage loss: 1.9733\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0346\n",
      "    -             emb_val other: 0.27620238\n",
      "    -         eff_perturb other: 0.00000224\n",
      "\n",
      "Epoch: 1: Step: 9493/9807; Global_step=19300; lr=1.068e-05; train time per batch = 1.50\n",
      "Train: global step = 19307; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9936\n",
      "    -                  end loss: 3.9584\n",
      "    -                 span loss: 7.9520\n",
      "    -              passage loss: 1.9933\n",
      "    -         history_span loss: 8.9989\n",
      "    -      history_passage loss: 2.0032\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0032\n",
      "    -             emb_val other: 0.27428496\n",
      "    -         eff_perturb other: 0.00000184\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.19040.19327\n",
      "Epoch: 1: Step: 9593/9807; Global_step=19400; lr=1.058e-05; train time per batch = 1.50\n",
      "Train: global step = 19407; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0026\n",
      "    -                  end loss: 3.9422\n",
      "    -                 span loss: 7.9447\n",
      "    -              passage loss: 1.9826\n",
      "    -         history_span loss: 8.9168\n",
      "    -      history_passage loss: 1.9650\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8622\n",
      "    -             emb_val other: 0.27547741\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 1: Step: 9693/9807; Global_step=19500; lr=1.047e-05; train time per batch = 1.50\n",
      "Train: global step = 19507; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9922\n",
      "    -                  end loss: 3.9639\n",
      "    -                 span loss: 7.9561\n",
      "    -              passage loss: 2.0053\n",
      "    -         history_span loss: 8.9281\n",
      "    -      history_passage loss: 2.0150\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9602\n",
      "    -             emb_val other: 0.27668667\n",
      "    -         eff_perturb other: 0.00000205\n",
      "\n",
      "Epoch: 1: Step: 9793/9807; Global_step=19600; lr=1.037e-05; train time per batch = 1.50\n",
      "Train: global step = 19607; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9946\n",
      "    -                  end loss: 3.9551\n",
      "    -                 span loss: 7.9497\n",
      "    -              passage loss: 2.0189\n",
      "    -         history_span loss: 9.0019\n",
      "    -      history_passage loss: 2.0177\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0423\n",
      "    -             emb_val other: 0.27600163\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Avg. total Loss of epoch 1 =21.009\n",
      "================================================================================\n",
      "                                    Epoch 2\n",
      "================================================================================\n",
      "Epoch: 2: Step: 86/9807; Global_step=19700; lr=1.026e-05; train time per batch = 1.48\n",
      "Train: global step = 19714; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9612\n",
      "    -                 span loss: 7.9496\n",
      "    -              passage loss: 1.9811\n",
      "    -         history_span loss: 8.8367\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8011\n",
      "    -             emb_val other: 0.27620825\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 2: Step: 186/9807; Global_step=19800; lr=1.016e-05; train time per batch = 1.48\n",
      "Train: global step = 19814; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9991\n",
      "    -                  end loss: 3.9617\n",
      "    -                 span loss: 7.9607\n",
      "    -              passage loss: 2.0098\n",
      "    -         history_span loss: 8.9399\n",
      "    -      history_passage loss: 2.0145\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9812\n",
      "    -             emb_val other: 0.27573252\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 2: Step: 286/9807; Global_step=19900; lr=1.005e-05; train time per batch = 1.47\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.596.19912\n",
      "Train: global step = 19914; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9870\n",
      "    -                  end loss: 3.9542\n",
      "    -                 span loss: 7.9412\n",
      "    -              passage loss: 1.9476\n",
      "    -         history_span loss: 9.0899\n",
      "    -      history_passage loss: 1.9434\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9737\n",
      "    -             emb_val other: 0.27555802\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 2: Step: 386/9807; Global_step=20000; lr=9.944e-06; train time per batch = 1.46\n",
      "Validation: Epoch: 2 Step: 386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 20014; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9956\n",
      "    -                  end loss: 3.9491\n",
      "    -                 span loss: 7.9447\n",
      "    -              passage loss: 1.9884\n",
      "    -         history_span loss: 9.0301\n",
      "    -      history_passage loss: 1.9881\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0055\n",
      "    -             emb_val other: 0.27568346\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 486/9807; Global_step=20100; lr=9.839e-06; train time per batch = 1.47\n",
      "Train: global step = 20114; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9888\n",
      "    -                  end loss: 3.9532\n",
      "    -                 span loss: 7.9420\n",
      "    -              passage loss: 1.9750\n",
      "    -         history_span loss: 9.0967\n",
      "    -      history_passage loss: 1.9683\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0338\n",
      "    -             emb_val other: 0.27612182\n",
      "    -         eff_perturb other: 0.00000177\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.1028.20128\n",
      "Epoch: 2: Step: 586/9807; Global_step=20200; lr=9.733e-06; train time per batch = 1.47\n",
      "Train: global step = 20214; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9943\n",
      "    -                  end loss: 3.9529\n",
      "    -                 span loss: 7.9472\n",
      "    -              passage loss: 1.9890\n",
      "    -         history_span loss: 9.0840\n",
      "    -      history_passage loss: 1.9880\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.0587\n",
      "    -             emb_val other: 0.27649754\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 2: Step: 686/9807; Global_step=20300; lr=9.628e-06; train time per batch = 1.46\n",
      "Train: global step = 20314; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9867\n",
      "    -                  end loss: 3.9472\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 1.9896\n",
      "    -         history_span loss: 9.0659\n",
      "    -      history_passage loss: 1.9848\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0281\n",
      "    -             emb_val other: 0.27526978\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 786/9807; Global_step=20400; lr=9.522e-06; train time per batch = 1.47\n",
      "Train: global step = 20414; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9987\n",
      "    -                  end loss: 3.9657\n",
      "    -                 span loss: 7.9644\n",
      "    -              passage loss: 1.9965\n",
      "    -         history_span loss: 9.0415\n",
      "    -      history_passage loss: 1.9996\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.0545\n",
      "    -             emb_val other: 0.27615395\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.1616.20422\n",
      "Epoch: 2: Step: 886/9807; Global_step=20500; lr=9.417e-06; train time per batch = 1.47\n",
      "Train: global step = 20514; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9588\n",
      "    -                 span loss: 7.9459\n",
      "    -              passage loss: 1.9661\n",
      "    -         history_span loss: 9.0165\n",
      "    -      history_passage loss: 1.9725\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9577\n",
      "    -             emb_val other: 0.27618298\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 2: Step: 986/9807; Global_step=20600; lr=9.311e-06; train time per batch = 1.47\n",
      "Train: global step = 20614; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9954\n",
      "    -                  end loss: 3.9595\n",
      "    -                 span loss: 7.9549\n",
      "    -              passage loss: 1.9680\n",
      "    -         history_span loss: 9.1080\n",
      "    -      history_passage loss: 1.9649\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0495\n",
      "    -             emb_val other: 0.27567473\n",
      "    -         eff_perturb other: 0.00000167\n",
      "\n",
      "Epoch: 2: Step: 1086/9807; Global_step=20700; lr=9.206e-06; train time per batch = 1.47\n",
      "Train: global step = 20714; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9809\n",
      "    -                  end loss: 3.9568\n",
      "    -                 span loss: 7.9377\n",
      "    -              passage loss: 2.0293\n",
      "    -         history_span loss: 9.0002\n",
      "    -      history_passage loss: 2.0281\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0503\n",
      "    -             emb_val other: 0.27576452\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2212.20720\n",
      "Epoch: 2: Step: 1186/9807; Global_step=20800; lr=9.100e-06; train time per batch = 1.48\n",
      "Train: global step = 20814; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9973\n",
      "    -                  end loss: 3.9642\n",
      "    -                 span loss: 7.9615\n",
      "    -              passage loss: 2.0196\n",
      "    -         history_span loss: 9.1938\n",
      "    -      history_passage loss: 2.0176\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.2443\n",
      "    -             emb_val other: 0.27675000\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Epoch: 2: Step: 1286/9807; Global_step=20900; lr=8.994e-06; train time per batch = 1.48\n",
      "Train: global step = 20914; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9936\n",
      "    -                  end loss: 3.9666\n",
      "    -                 span loss: 7.9602\n",
      "    -              passage loss: 1.9729\n",
      "    -         history_span loss: 8.9944\n",
      "    -      history_passage loss: 1.9905\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9736\n",
      "    -             emb_val other: 0.27597618\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 1386/9807; Global_step=21000; lr=8.889e-06; train time per batch = 1.48\n",
      "Validation: Epoch: 2 Step: 1386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2774.21001\n",
      "Train: global step = 21014; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9894\n",
      "    -                  end loss: 3.9579\n",
      "    -                 span loss: 7.9473\n",
      "    -              passage loss: 2.0168\n",
      "    -         history_span loss: 8.9637\n",
      "    -      history_passage loss: 2.0069\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9863\n",
      "    -             emb_val other: 0.27700108\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 2: Step: 1486/9807; Global_step=21100; lr=8.783e-06; train time per batch = 1.48\n",
      "Train: global step = 21114; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9894\n",
      "    -                  end loss: 3.9663\n",
      "    -                 span loss: 7.9557\n",
      "    -              passage loss: 2.0028\n",
      "    -         history_span loss: 8.8743\n",
      "    -      history_passage loss: 2.0018\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.8897\n",
      "    -             emb_val other: 0.27527326\n",
      "    -         eff_perturb other: 0.00000174\n",
      "\n",
      "Epoch: 2: Step: 1586/9807; Global_step=21200; lr=8.678e-06; train time per batch = 1.48\n",
      "Train: global step = 21214; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9945\n",
      "    -                  end loss: 3.9538\n",
      "    -                 span loss: 7.9483\n",
      "    -              passage loss: 2.0231\n",
      "    -         history_span loss: 9.1806\n",
      "    -      history_passage loss: 2.0007\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.2066\n",
      "    -             emb_val other: 0.27626452\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 2: Step: 1686/9807; Global_step=21300; lr=8.572e-06; train time per batch = 1.48\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.3380.21304\n",
      "Train: global step = 21314; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9970\n",
      "    -                  end loss: 3.9640\n",
      "    -                 span loss: 7.9609\n",
      "    -              passage loss: 1.9908\n",
      "    -         history_span loss: 8.9660\n",
      "    -      history_passage loss: 1.9904\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9619\n",
      "    -             emb_val other: 0.27524939\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Epoch: 2: Step: 1786/9807; Global_step=21400; lr=8.467e-06; train time per batch = 1.49\n",
      "Train: global step = 21414; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9993\n",
      "    -                  end loss: 3.9554\n",
      "    -                 span loss: 7.9546\n",
      "    -              passage loss: 2.0300\n",
      "    -         history_span loss: 8.8733\n",
      "    -      history_passage loss: 2.0387\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0056\n",
      "    -                total loss: 20.9551\n",
      "    -             emb_val other: 0.27607477\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Epoch: 2: Step: 1886/9807; Global_step=21500; lr=8.361e-06; train time per batch = 1.49\n",
      "Train: global step = 21514; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9979\n",
      "    -                  end loss: 3.9517\n",
      "    -                 span loss: 7.9496\n",
      "    -              passage loss: 1.9871\n",
      "    -         history_span loss: 9.0512\n",
      "    -      history_passage loss: 1.9880\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.0274\n",
      "    -             emb_val other: 0.27555451\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 2: Step: 1986/9807; Global_step=21600; lr=8.256e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.3988.21608\n",
      "Train: global step = 21614; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9849\n",
      "    -                  end loss: 3.9497\n",
      "    -                 span loss: 7.9346\n",
      "    -              passage loss: 1.9939\n",
      "    -         history_span loss: 9.0335\n",
      "    -      history_passage loss: 1.9894\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0054\n",
      "    -             emb_val other: 0.27659789\n",
      "    -         eff_perturb other: 0.00000154\n",
      "\n",
      "Epoch: 2: Step: 2086/9807; Global_step=21700; lr=8.150e-06; train time per batch = 1.49\n",
      "Train: global step = 21714; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9954\n",
      "    -                  end loss: 3.9458\n",
      "    -                 span loss: 7.9413\n",
      "    -              passage loss: 2.0110\n",
      "    -         history_span loss: 9.2110\n",
      "    -      history_passage loss: 2.0051\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.2217\n",
      "    -             emb_val other: 0.27519888\n",
      "    -         eff_perturb other: 0.00000133\n",
      "\n",
      "Epoch: 2: Step: 2186/9807; Global_step=21800; lr=8.044e-06; train time per batch = 1.49\n",
      "Train: global step = 21814; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9895\n",
      "    -                  end loss: 3.9590\n",
      "    -                 span loss: 7.9484\n",
      "    -              passage loss: 2.0007\n",
      "    -         history_span loss: 9.2007\n",
      "    -      history_passage loss: 2.0040\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0057\n",
      "    -                total loss: 21.2116\n",
      "    -             emb_val other: 0.27665153\n",
      "    -         eff_perturb other: 0.00000195\n",
      "\n",
      "Epoch: 2: Step: 2286/9807; Global_step=21900; lr=7.939e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.4586.21907\n",
      "Train: global step = 21914; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9883\n",
      "    -                  end loss: 3.9618\n",
      "    -                 span loss: 7.9501\n",
      "    -              passage loss: 2.0144\n",
      "    -         history_span loss: 8.9626\n",
      "    -      history_passage loss: 2.0186\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9976\n",
      "    -             emb_val other: 0.27642620\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 2: Step: 2386/9807; Global_step=22000; lr=7.833e-06; train time per batch = 1.49\n",
      "Validation: Epoch: 2 Step: 2386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 22014; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9894\n",
      "    -                  end loss: 3.9564\n",
      "    -                 span loss: 7.9458\n",
      "    -              passage loss: 2.0055\n",
      "    -         history_span loss: 8.9737\n",
      "    -      history_passage loss: 1.9972\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9767\n",
      "    -             emb_val other: 0.27628481\n",
      "    -         eff_perturb other: 0.00000122\n",
      "\n",
      "Epoch: 2: Step: 2486/9807; Global_step=22100; lr=7.728e-06; train time per batch = 1.49\n",
      "Train: global step = 22114; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9986\n",
      "    -                  end loss: 3.9416\n",
      "    -                 span loss: 7.9402\n",
      "    -              passage loss: 2.0120\n",
      "    -         history_span loss: 8.9074\n",
      "    -      history_passage loss: 2.0113\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.9272\n",
      "    -             emb_val other: 0.27572978\n",
      "    -         eff_perturb other: 0.00000146\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.5010.22119\n",
      "Epoch: 2: Step: 2586/9807; Global_step=22200; lr=7.622e-06; train time per batch = 1.49\n",
      "Train: global step = 22214; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9920\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9565\n",
      "    -              passage loss: 1.9916\n",
      "    -         history_span loss: 8.9222\n",
      "    -      history_passage loss: 1.9846\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9117\n",
      "    -             emb_val other: 0.27581078\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 2: Step: 2686/9807; Global_step=22300; lr=7.517e-06; train time per batch = 1.49\n",
      "Train: global step = 22314; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9964\n",
      "    -                  end loss: 3.9528\n",
      "    -                 span loss: 7.9492\n",
      "    -              passage loss: 2.0082\n",
      "    -         history_span loss: 9.0427\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0028\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 21.0560\n",
      "    -             emb_val other: 0.27555966\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 2: Step: 2786/9807; Global_step=22400; lr=7.411e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.5596.22412\n",
      "Train: global step = 22414; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0058\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9625\n",
      "    -              passage loss: 2.0021\n",
      "    -         history_span loss: 9.0610\n",
      "    -      history_passage loss: 1.9984\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.0816\n",
      "    -             emb_val other: 0.27566847\n",
      "    -         eff_perturb other: 0.00000128\n",
      "\n",
      "Epoch: 2: Step: 2886/9807; Global_step=22500; lr=7.306e-06; train time per batch = 1.49\n",
      "Train: global step = 22514; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9997\n",
      "    -                  end loss: 3.9539\n",
      "    -                 span loss: 7.9536\n",
      "    -              passage loss: 2.0030\n",
      "    -         history_span loss: 9.2729\n",
      "    -      history_passage loss: 2.0107\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.2938\n",
      "    -             emb_val other: 0.27564436\n",
      "    -         eff_perturb other: 0.00000159\n",
      "\n",
      "Epoch: 2: Step: 2986/9807; Global_step=22600; lr=7.200e-06; train time per batch = 1.49\n",
      "Train: global step = 22614; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9832\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9446\n",
      "    -              passage loss: 1.9995\n",
      "    -         history_span loss: 8.9837\n",
      "    -      history_passage loss: 2.0037\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9849\n",
      "    -             emb_val other: 0.27552283\n",
      "    -         eff_perturb other: 0.00000130\n",
      "\n",
      "Epoch: 2: Step: 3086/9807; Global_step=22700; lr=7.094e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.6180.22704\n",
      "Train: global step = 22714; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9953\n",
      "    -                  end loss: 3.9480\n",
      "    -                 span loss: 7.9432\n",
      "    -              passage loss: 2.0046\n",
      "    -         history_span loss: 9.0893\n",
      "    -      history_passage loss: 2.0040\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0968\n",
      "    -             emb_val other: 0.27694938\n",
      "    -         eff_perturb other: 0.00000136\n",
      "\n",
      "Epoch: 2: Step: 3186/9807; Global_step=22800; lr=6.989e-06; train time per batch = 1.49\n",
      "Train: global step = 22814; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9796\n",
      "    -                  end loss: 3.9541\n",
      "    -                 span loss: 7.9338\n",
      "    -              passage loss: 1.9894\n",
      "    -         history_span loss: 9.0028\n",
      "    -      history_passage loss: 1.9621\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.9407\n",
      "    -             emb_val other: 0.27688548\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Epoch: 2: Step: 3286/9807; Global_step=22900; lr=6.883e-06; train time per batch = 1.49\n",
      "Train: global step = 22914; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9950\n",
      "    -                  end loss: 3.9577\n",
      "    -                 span loss: 7.9527\n",
      "    -              passage loss: 1.9585\n",
      "    -         history_span loss: 9.0421\n",
      "    -      history_passage loss: 1.9535\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.9610\n",
      "    -             emb_val other: 0.27504155\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 23014; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9718\n",
      "    -                  end loss: 3.9644\n",
      "    -                 span loss: 7.9362\n",
      "    -              passage loss: 1.9993\n",
      "    -         history_span loss: 8.9604\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9500\n",
      "    -             emb_val other: 0.27598509\n",
      "    -         eff_perturb other: 0.00000141\n",
      "\n",
      "Epoch: 2: Step: 3486/9807; Global_step=23100; lr=6.672e-06; train time per batch = 1.49\n",
      "Train: global step = 23114; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0072\n",
      "    -                  end loss: 3.9549\n",
      "    -                 span loss: 7.9620\n",
      "    -              passage loss: 1.9908\n",
      "    -         history_span loss: 8.8800\n",
      "    -      history_passage loss: 2.0043\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.8912\n",
      "    -             emb_val other: 0.27562594\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 2: Step: 3586/9807; Global_step=23200; lr=6.567e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7192.23210\n",
      "Train: global step = 23214; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9915\n",
      "    -                  end loss: 3.9514\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0259\n",
      "    -         history_span loss: 9.0960\n",
      "    -      history_passage loss: 2.0214\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 21.1407\n",
      "    -             emb_val other: 0.27572447\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 2: Step: 3686/9807; Global_step=23300; lr=6.461e-06; train time per batch = 1.49\n",
      "Train: global step = 23314; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9825\n",
      "    -                  end loss: 3.9571\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 2.0252\n",
      "    -         history_span loss: 8.9070\n",
      "    -      history_passage loss: 2.0268\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0042\n",
      "    -                total loss: 20.9500\n",
      "    -             emb_val other: 0.27669933\n",
      "    -         eff_perturb other: 0.00000126\n",
      "\n",
      "Epoch: 2: Step: 3786/9807; Global_step=23400; lr=6.356e-06; train time per batch = 1.49\n",
      "Train: global step = 23414; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9848\n",
      "    -                  end loss: 3.9581\n",
      "    -                 span loss: 7.9428\n",
      "    -              passage loss: 1.9681\n",
      "    -         history_span loss: 9.0364\n",
      "    -      history_passage loss: 1.9738\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9767\n",
      "    -             emb_val other: 0.27579758\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Epoch: 2: Step: 3886/9807; Global_step=23500; lr=6.250e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7776.23502\n",
      "Train: global step = 23514; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9842\n",
      "    -                  end loss: 3.9641\n",
      "    -                 span loss: 7.9483\n",
      "    -              passage loss: 2.0247\n",
      "    -         history_span loss: 8.8856\n",
      "    -      history_passage loss: 2.0192\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.9334\n",
      "    -             emb_val other: 0.27656487\n",
      "    -         eff_perturb other: 0.00000164\n",
      "\n",
      "Epoch: 2: Step: 3986/9807; Global_step=23600; lr=6.144e-06; train time per batch = 1.49\n",
      "Train: global step = 23614; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9926\n",
      "    -                  end loss: 3.9503\n",
      "    -                 span loss: 7.9429\n",
      "    -              passage loss: 2.0277\n",
      "    -         history_span loss: 9.3951\n",
      "    -      history_passage loss: 2.0109\n",
      "    -            adv_start loss: 0.0034\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 21.4355\n",
      "    -             emb_val other: 0.27506652\n",
      "    -         eff_perturb other: 0.00000178\n",
      "\n",
      "Epoch: 2: Step: 4086/9807; Global_step=23700; lr=6.039e-06; train time per batch = 1.49\n",
      "Train: global step = 23714; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9940\n",
      "    -                  end loss: 3.9545\n",
      "    -                 span loss: 7.9485\n",
      "    -              passage loss: 1.9906\n",
      "    -         history_span loss: 9.0733\n",
      "    -      history_passage loss: 1.9861\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0521\n",
      "    -             emb_val other: 0.27487162\n",
      "    -         eff_perturb other: 0.00000143\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.8356.23792\n",
      "Epoch: 2: Step: 4186/9807; Global_step=23800; lr=5.933e-06; train time per batch = 1.49\n",
      "Train: global step = 23814; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9880\n",
      "    -                  end loss: 3.9502\n",
      "    -                 span loss: 7.9382\n",
      "    -              passage loss: 2.0472\n",
      "    -         history_span loss: 8.7764\n",
      "    -      history_passage loss: 2.0399\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0056\n",
      "    -                total loss: 20.8615\n",
      "    -             emb_val other: 0.27669168\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Epoch: 2: Step: 4286/9807; Global_step=23900; lr=5.828e-06; train time per batch = 1.49\n",
      "Train: global step = 23914; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9925\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9481\n",
      "    -              passage loss: 2.0247\n",
      "    -         history_span loss: 8.8274\n",
      "    -      history_passage loss: 2.0215\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8742\n",
      "    -             emb_val other: 0.27697909\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 4386/9807; Global_step=24000; lr=5.722e-06; train time per batch = 1.49\n",
      "Validation: Epoch: 2 Step: 4386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.8782.24005\n",
      "Train: global step = 24014; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9963\n",
      "    -                  end loss: 3.9614\n",
      "    -                 span loss: 7.9577\n",
      "    -              passage loss: 1.9535\n",
      "    -         history_span loss: 9.1088\n",
      "    -      history_passage loss: 1.9503\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0265\n",
      "    -             emb_val other: 0.27298841\n",
      "    -         eff_perturb other: 0.00000157\n",
      "\n",
      "Epoch: 2: Step: 4486/9807; Global_step=24100; lr=5.617e-06; train time per batch = 1.49\n",
      "Train: global step = 24114; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9726\n",
      "    -                  end loss: 3.9605\n",
      "    -                 span loss: 7.9331\n",
      "    -              passage loss: 2.0234\n",
      "    -         history_span loss: 8.9150\n",
      "    -      history_passage loss: 2.0289\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9554\n",
      "    -             emb_val other: 0.27675641\n",
      "    -         eff_perturb other: 0.00000149\n",
      "\n",
      "Epoch: 2: Step: 4586/9807; Global_step=24200; lr=5.511e-06; train time per batch = 1.49\n",
      "Train: global step = 24214; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9944\n",
      "    -                  end loss: 3.9565\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 1.9659\n",
      "    -         history_span loss: 8.9390\n",
      "    -      history_passage loss: 1.9693\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0047\n",
      "    -                total loss: 20.8794\n",
      "    -             emb_val other: 0.27625558\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.9370.24299\n",
      "Epoch: 2: Step: 4686/9807; Global_step=24300; lr=5.406e-06; train time per batch = 1.49\n",
      "Train: global step = 24314; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9954\n",
      "    -                  end loss: 3.9510\n",
      "    -                 span loss: 7.9463\n",
      "    -              passage loss: 1.9743\n",
      "    -         history_span loss: 8.8065\n",
      "    -      history_passage loss: 1.9848\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 20.7646\n",
      "    -             emb_val other: 0.27505636\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 4786/9807; Global_step=24400; lr=5.300e-06; train time per batch = 1.49\n",
      "Train: global step = 24414; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0060\n",
      "    -                  end loss: 3.9473\n",
      "    -                 span loss: 7.9533\n",
      "    -              passage loss: 2.0115\n",
      "    -         history_span loss: 9.1286\n",
      "    -      history_passage loss: 2.0087\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0044\n",
      "    -                total loss: 21.1547\n",
      "    -             emb_val other: 0.27534747\n",
      "    -         eff_perturb other: 0.00000120\n",
      "\n",
      "Epoch: 2: Step: 4886/9807; Global_step=24500; lr=5.194e-06; train time per batch = 1.49\n",
      "Train: global step = 24514; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9997\n",
      "    -                  end loss: 3.9585\n",
      "    -                 span loss: 7.9581\n",
      "    -              passage loss: 1.9657\n",
      "    -         history_span loss: 9.1907\n",
      "    -      history_passage loss: 1.9623\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1316\n",
      "    -             emb_val other: 0.27593571\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.9952.24590\n",
      "Epoch: 2: Step: 4986/9807; Global_step=24600; lr=5.089e-06; train time per batch = 1.49\n",
      "Train: global step = 24614; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9993\n",
      "    -                  end loss: 3.9567\n",
      "    -                 span loss: 7.9559\n",
      "    -              passage loss: 1.9658\n",
      "    -         history_span loss: 9.0288\n",
      "    -      history_passage loss: 1.9665\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.9719\n",
      "    -             emb_val other: 0.27474475\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 5086/9807; Global_step=24700; lr=4.983e-06; train time per batch = 1.48\n",
      "Train: global step = 24714; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9951\n",
      "    -                  end loss: 3.9557\n",
      "    -                 span loss: 7.9508\n",
      "    -              passage loss: 1.9696\n",
      "    -         history_span loss: 8.9457\n",
      "    -      history_passage loss: 1.9760\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0026\n",
      "    -        adv_relevance loss: 0.0054\n",
      "    -                total loss: 20.8976\n",
      "    -             emb_val other: 0.27440789\n",
      "    -         eff_perturb other: 0.00000218\n",
      "\n",
      "Epoch: 2: Step: 5186/9807; Global_step=24800; lr=4.878e-06; train time per batch = 1.48\n",
      "Train: global step = 24814; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0031\n",
      "    -                  end loss: 3.9672\n",
      "    -                 span loss: 7.9703\n",
      "    -              passage loss: 2.0158\n",
      "    -         history_span loss: 9.2503\n",
      "    -      history_passage loss: 2.0098\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.3010\n",
      "    -             emb_val other: 0.27595791\n",
      "    -         eff_perturb other: 0.00000138\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.10548.24888\n",
      "Epoch: 2: Step: 5286/9807; Global_step=24900; lr=4.772e-06; train time per batch = 1.48\n",
      "Train: global step = 24914; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9998\n",
      "    -                  end loss: 3.9501\n",
      "    -                 span loss: 7.9499\n",
      "    -              passage loss: 1.9361\n",
      "    -         history_span loss: 9.0005\n",
      "    -      history_passage loss: 1.9310\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8726\n",
      "    -             emb_val other: 0.27281722\n",
      "    -         eff_perturb other: 0.00000156\n",
      "\n",
      "Epoch: 2: Step: 5386/9807; Global_step=25000; lr=4.667e-06; train time per batch = 1.48\n",
      "Validation: Epoch: 2 Step: 5386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 25014; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9912\n",
      "    -                  end loss: 3.9577\n",
      "    -                 span loss: 7.9489\n",
      "    -              passage loss: 1.9691\n",
      "    -         history_span loss: 8.7751\n",
      "    -      history_passage loss: 1.9771\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 20.7277\n",
      "    -             emb_val other: 0.27486336\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 6686/9807; Global_step=26300; lr=3.294e-06; train time per batch = 1.49\n",
      "Train: global step = 26314; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9967\n",
      "    -                  end loss: 3.9589\n",
      "    -                 span loss: 7.9556\n",
      "    -              passage loss: 1.9900\n",
      "    -         history_span loss: 8.9563\n",
      "    -      history_passage loss: 1.9907\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9452\n",
      "    -             emb_val other: 0.27465042\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 2: Step: 6786/9807; Global_step=26400; lr=3.189e-06; train time per batch = 1.49\n",
      "Train: global step = 26414; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9908\n",
      "    -                  end loss: 3.9572\n",
      "    -                 span loss: 7.9480\n",
      "    -              passage loss: 2.0209\n",
      "    -         history_span loss: 9.0089\n",
      "    -      history_passage loss: 2.0250\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0580\n",
      "    -             emb_val other: 0.27568167\n",
      "    -         eff_perturb other: 0.00000140\n",
      "\n",
      "Epoch: 2: Step: 6886/9807; Global_step=26500; lr=3.083e-06; train time per batch = 1.49\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.13798.26513\n",
      "Train: global step = 26514; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9837\n",
      "    -                  end loss: 3.9472\n",
      "    -                 span loss: 7.9310\n",
      "    -              passage loss: 2.0139\n",
      "    -         history_span loss: 9.0032\n",
      "    -      history_passage loss: 2.0058\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0106\n",
      "    -             emb_val other: 0.27608189\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 6986/9807; Global_step=26600; lr=2.978e-06; train time per batch = 1.49\n",
      "Train: global step = 26614; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0024\n",
      "    -                  end loss: 3.9524\n",
      "    -                 span loss: 7.9549\n",
      "    -              passage loss: 2.0201\n",
      "    -         history_span loss: 8.9214\n",
      "    -      history_passage loss: 2.0317\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 20.9857\n",
      "    -             emb_val other: 0.27593344\n",
      "    -         eff_perturb other: 0.00000202\n",
      "\n",
      "Epoch: 2: Step: 7086/9807; Global_step=26700; lr=2.872e-06; train time per batch = 1.49\n",
      "Train: global step = 26714; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9874\n",
      "    -                  end loss: 3.9606\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 1.9812\n",
      "    -         history_span loss: 9.0639\n",
      "    -      history_passage loss: 1.9832\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0310\n",
      "    -             emb_val other: 0.27552372\n",
      "    -         eff_perturb other: 0.00000150\n",
      "\n",
      "Epoch: 2: Step: 7186/9807; Global_step=26800; lr=2.767e-06; train time per batch = 1.49\n",
      "Train: global step = 26814; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0011\n",
      "    -                  end loss: 3.9606\n",
      "    -                 span loss: 7.9617\n",
      "    -              passage loss: 1.9908\n",
      "    -         history_span loss: 8.8861\n",
      "    -      history_passage loss: 1.9921\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 20.8852\n",
      "    -             emb_val other: 0.27602383\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.14412.26820\n",
      "Epoch: 2: Step: 7286/9807; Global_step=26900; lr=2.661e-06; train time per batch = 1.49\n",
      "Train: global step = 26914; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9957\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9518\n",
      "    -              passage loss: 1.9991\n",
      "    -         history_span loss: 8.8152\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 20.8183\n",
      "    -             emb_val other: 0.27740484\n",
      "    -         eff_perturb other: 0.00000125\n",
      "\n",
      "Epoch: 2: Step: 7386/9807; Global_step=27000; lr=2.556e-06; train time per batch = 1.49\n",
      "Validation: Epoch: 2 Step: 7386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 27014; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9943\n",
      "    -                  end loss: 3.9545\n",
      "    -                 span loss: 7.9488\n",
      "    -              passage loss: 1.9920\n",
      "    -         history_span loss: 8.9457\n",
      "    -      history_passage loss: 2.0043\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0045\n",
      "    -                total loss: 20.9425\n",
      "    -             emb_val other: 0.27660328\n",
      "    -         eff_perturb other: 0.00000127\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.14856.27042\n",
      "Epoch: 2: Step: 7486/9807; Global_step=27100; lr=2.450e-06; train time per batch = 1.49\n",
      "Train: global step = 27114; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9954\n",
      "    -                  end loss: 3.9499\n",
      "    -                 span loss: 7.9453\n",
      "    -              passage loss: 2.0229\n",
      "    -         history_span loss: 8.9966\n",
      "    -      history_passage loss: 2.0149\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0330\n",
      "    -             emb_val other: 0.27702001\n",
      "    -         eff_perturb other: 0.00000129\n",
      "\n",
      "Epoch: 2: Step: 7586/9807; Global_step=27200; lr=2.344e-06; train time per batch = 1.49\n",
      "Train: global step = 27214; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9879\n",
      "    -                  end loss: 3.9600\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 1.9983\n",
      "    -         history_span loss: 8.9117\n",
      "    -      history_passage loss: 2.0002\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 20.9134\n",
      "    -             emb_val other: 0.27567497\n",
      "    -         eff_perturb other: 0.00000118\n",
      "\n",
      "Epoch: 2: Step: 7686/9807; Global_step=27300; lr=2.239e-06; train time per batch = 1.49\n",
      "Train: global step = 27314; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9819\n",
      "    -                  end loss: 3.9478\n",
      "    -                 span loss: 7.9297\n",
      "    -              passage loss: 1.9972\n",
      "    -         history_span loss: 9.1402\n",
      "    -      history_passage loss: 2.0030\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.1250\n",
      "    -             emb_val other: 0.27501893\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 7786/9807; Global_step=27400; lr=2.133e-06; train time per batch = 1.49\n",
      "Train: global step = 27414; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9839\n",
      "    -                  end loss: 3.9569\n",
      "    -                 span loss: 7.9408\n",
      "    -              passage loss: 1.9862\n",
      "    -         history_span loss: 9.1552\n",
      "    -      history_passage loss: 1.9733\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.1099\n",
      "    -             emb_val other: 0.27609921\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 7886/9807; Global_step=27500; lr=2.028e-06; train time per batch = 1.49\n",
      "Train: global step = 27514; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9871\n",
      "    -                  end loss: 3.9525\n",
      "    -                 span loss: 7.9396\n",
      "    -              passage loss: 2.0145\n",
      "    -         history_span loss: 8.8953\n",
      "    -      history_passage loss: 2.0008\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9056\n",
      "    -             emb_val other: 0.27621108\n",
      "    -         eff_perturb other: 0.00000135\n",
      "\n",
      "Epoch: 2: Step: 7986/9807; Global_step=27600; lr=1.922e-06; train time per batch = 1.49\n",
      "Train: global step = 27614; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9951\n",
      "    -                  end loss: 3.9471\n",
      "    -                 span loss: 7.9422\n",
      "    -              passage loss: 1.9876\n",
      "    -         history_span loss: 9.1526\n",
      "    -      history_passage loss: 1.9720\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.1064\n",
      "    -             emb_val other: 0.27547282\n",
      "    -         eff_perturb other: 0.00000153\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.16042.27635\n",
      "Epoch: 2: Step: 8086/9807; Global_step=27700; lr=1.817e-06; train time per batch = 1.49\n",
      "Train: global step = 27714; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9989\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9545\n",
      "    -              passage loss: 2.0052\n",
      "    -         history_span loss: 9.1048\n",
      "    -      history_passage loss: 1.9981\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0056\n",
      "    -                total loss: 21.1202\n",
      "    -             emb_val other: 0.27718425\n",
      "    -         eff_perturb other: 0.00000172\n",
      "\n",
      "Epoch: 2: Step: 8186/9807; Global_step=27800; lr=1.711e-06; train time per batch = 1.49\n",
      "Train: global step = 27814; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9986\n",
      "    -                  end loss: 3.9612\n",
      "    -                 span loss: 7.9598\n",
      "    -              passage loss: 1.9775\n",
      "    -         history_span loss: 8.9769\n",
      "    -      history_passage loss: 1.9804\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9490\n",
      "    -             emb_val other: 0.27505991\n",
      "    -         eff_perturb other: 0.00000155\n",
      "\n",
      "Epoch: 2: Step: 8286/9807; Global_step=27900; lr=1.606e-06; train time per batch = 1.49\n",
      "Train: global step = 27914; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9951\n",
      "    -                  end loss: 3.9539\n",
      "    -                 span loss: 7.9490\n",
      "    -              passage loss: 2.0092\n",
      "    -         history_span loss: 8.9967\n",
      "    -      history_passage loss: 2.0086\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0201\n",
      "    -             emb_val other: 0.27494818\n",
      "    -         eff_perturb other: 0.00000152\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.16644.27936\n",
      "Epoch: 2: Step: 8386/9807; Global_step=28000; lr=1.500e-06; train time per batch = 1.49\n",
      "Validation: Epoch: 2 Step: 8386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.26\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.27\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Train: global step = 28014; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0020\n",
      "    -                  end loss: 3.9664\n",
      "    -                 span loss: 7.9684\n",
      "    -              passage loss: 2.0051\n",
      "    -         history_span loss: 9.0814\n",
      "    -      history_passage loss: 2.0107\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0055\n",
      "    -                total loss: 21.1212\n",
      "    -             emb_val other: 0.27712867\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 2: Step: 8486/9807; Global_step=28100; lr=1.394e-06; train time per batch = 1.49\n",
      "Train: global step = 28114; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9999\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9526\n",
      "    -              passage loss: 2.0102\n",
      "    -         history_span loss: 9.2445\n",
      "    -      history_passage loss: 2.0131\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.2735\n",
      "    -             emb_val other: 0.27609423\n",
      "    -         eff_perturb other: 0.00000134\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.17092.28160\n",
      "Epoch: 2: Step: 8586/9807; Global_step=28200; lr=1.289e-06; train time per batch = 1.49\n",
      "Train: global step = 28214; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0049\n",
      "    -                  end loss: 3.9527\n",
      "    -                 span loss: 7.9576\n",
      "    -              passage loss: 1.9337\n",
      "    -         history_span loss: 9.1471\n",
      "    -      history_passage loss: 1.9379\n",
      "    -            adv_start loss: 0.0029\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0049\n",
      "    -                total loss: 21.0287\n",
      "    -             emb_val other: 0.27467406\n",
      "    -         eff_perturb other: 0.00000190\n",
      "\n",
      "Epoch: 2: Step: 8686/9807; Global_step=28300; lr=1.183e-06; train time per batch = 1.49\n",
      "Train: global step = 28314; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9876\n",
      "    -                  end loss: 3.9556\n",
      "    -                 span loss: 7.9432\n",
      "    -              passage loss: 2.0235\n",
      "    -         history_span loss: 9.0591\n",
      "    -      history_passage loss: 2.0167\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0989\n",
      "    -             emb_val other: 0.27689233\n",
      "    -         eff_perturb other: 0.00000121\n",
      "\n",
      "Epoch: 2: Step: 8786/9807; Global_step=28400; lr=1.078e-06; train time per batch = 1.49\n",
      "Train: global step = 28414; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9924\n",
      "    -                  end loss: 3.9647\n",
      "    -                 span loss: 7.9572\n",
      "    -              passage loss: 2.0182\n",
      "    -         history_span loss: 8.9935\n",
      "    -      history_passage loss: 2.0126\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0051\n",
      "    -                total loss: 21.0358\n",
      "    -             emb_val other: 0.27632520\n",
      "    -         eff_perturb other: 0.00000131\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.17704.28466\n",
      "Epoch: 2: Step: 8886/9807; Global_step=28500; lr=9.722e-07; train time per batch = 1.49\n",
      "Train: global step = 28514; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0017\n",
      "    -                  end loss: 3.9559\n",
      "    -                 span loss: 7.9576\n",
      "    -              passage loss: 1.9969\n",
      "    -         history_span loss: 9.0449\n",
      "    -      history_passage loss: 1.9910\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 21.0430\n",
      "    -             emb_val other: 0.27490193\n",
      "    -         eff_perturb other: 0.00000145\n",
      "\n",
      "Epoch: 2: Step: 8986/9807; Global_step=28600; lr=8.666e-07; train time per batch = 1.49\n",
      "Train: global step = 28614; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9956\n",
      "    -                  end loss: 3.9582\n",
      "    -                 span loss: 7.9538\n",
      "    -              passage loss: 2.0133\n",
      "    -         history_span loss: 8.9200\n",
      "    -      history_passage loss: 2.0183\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.9591\n",
      "    -             emb_val other: 0.27550572\n",
      "    -         eff_perturb other: 0.00000139\n",
      "\n",
      "Epoch: 2: Step: 9086/9807; Global_step=28700; lr=7.611e-07; train time per batch = 1.49\n",
      "Train: global step = 28714; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9872\n",
      "    -                  end loss: 3.9619\n",
      "    -                 span loss: 7.9491\n",
      "    -              passage loss: 2.0331\n",
      "    -         history_span loss: 8.9571\n",
      "    -      history_passage loss: 2.0349\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0048\n",
      "    -                total loss: 21.0282\n",
      "    -             emb_val other: 0.27595976\n",
      "    -         eff_perturb other: 0.00000166\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.18308.28768\n",
      "Epoch: 2: Step: 9186/9807; Global_step=28800; lr=6.555e-07; train time per batch = 1.49\n",
      "Train: global step = 28814; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9832\n",
      "    -                  end loss: 3.9568\n",
      "    -                 span loss: 7.9400\n",
      "    -              passage loss: 1.9902\n",
      "    -         history_span loss: 9.0229\n",
      "    -      history_passage loss: 1.9787\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0046\n",
      "    -                total loss: 20.9834\n",
      "    -             emb_val other: 0.27764824\n",
      "    -         eff_perturb other: 0.00000151\n",
      "\n",
      "Epoch: 2: Step: 9286/9807; Global_step=28900; lr=5.499e-07; train time per batch = 1.49\n",
      "Train: global step = 28914; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0013\n",
      "    -                  end loss: 3.9592\n",
      "    -                 span loss: 7.9605\n",
      "    -              passage loss: 1.9569\n",
      "    -         history_span loss: 8.9006\n",
      "    -      history_passage loss: 1.9632\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 20.8353\n",
      "    -             emb_val other: 0.27703846\n",
      "    -         eff_perturb other: 0.00000144\n",
      "\n",
      "Epoch: 2: Step: 9386/9807; Global_step=29000; lr=4.444e-07; train time per batch = 1.49\n",
      "Validation: Epoch: 2 Step: 9386/9807\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.28\n",
      "Eval step 200 / 993; eval time per batch = 0.28\n",
      "Eval step 300 / 993; eval time per batch = 0.28\n",
      "Eval step 400 / 993; eval time per batch = 0.29\n",
      "Eval step 500 / 993; eval time per batch = 0.26\n",
      "Eval step 600 / 993; eval time per batch = 0.25\n",
      "Eval step 700 / 993; eval time per batch = 0.24\n",
      "Eval step 800 / 993; eval time per batch = 0.24\n",
      "Eval step 900 / 993; eval time per batch = 0.24\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Curr EM 1.64\n",
      "Curr F1 14.27\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.18774.29001\n",
      "Train: global step = 29014; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9991\n",
      "    -                  end loss: 3.9561\n",
      "    -                 span loss: 7.9551\n",
      "    -              passage loss: 1.9960\n",
      "    -         history_span loss: 8.9443\n",
      "    -      history_passage loss: 2.0024\n",
      "    -            adv_start loss: 0.0031\n",
      "    -              adv_end loss: 0.0030\n",
      "    -        adv_relevance loss: 0.0057\n",
      "    -                total loss: 20.9569\n",
      "    -             emb_val other: 0.27553880\n",
      "    -         eff_perturb other: 0.00000147\n",
      "\n",
      "Epoch: 2: Step: 9486/9807; Global_step=29100; lr=3.388e-07; train time per batch = 1.49\n",
      "Train: global step = 29114; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9827\n",
      "    -                  end loss: 3.9566\n",
      "    -                 span loss: 7.9394\n",
      "    -              passage loss: 1.9769\n",
      "    -         history_span loss: 9.1281\n",
      "    -      history_passage loss: 1.9701\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0029\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0690\n",
      "    -             emb_val other: 0.27676803\n",
      "    -         eff_perturb other: 0.00000142\n",
      "\n",
      "Epoch: 2: Step: 9586/9807; Global_step=29200; lr=2.333e-07; train time per batch = 1.49\n",
      "Train: global step = 29214; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9984\n",
      "    -                  end loss: 3.9495\n",
      "    -                 span loss: 7.9479\n",
      "    -              passage loss: 1.9521\n",
      "    -         history_span loss: 9.1011\n",
      "    -      history_passage loss: 1.9480\n",
      "    -            adv_start loss: 0.0030\n",
      "    -              adv_end loss: 0.0027\n",
      "    -        adv_relevance loss: 0.0050\n",
      "    -                total loss: 21.0028\n",
      "    -             emb_val other: 0.27635902\n",
      "    -         eff_perturb other: 0.00000132\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.19254.29241\n",
      "Epoch: 2: Step: 9686/9807; Global_step=29300; lr=1.277e-07; train time per batch = 1.49\n",
      "Train: global step = 29314; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 4.0010\n",
      "    -                  end loss: 3.9526\n",
      "    -                 span loss: 7.9537\n",
      "    -              passage loss: 2.0058\n",
      "    -         history_span loss: 9.0643\n",
      "    -      history_passage loss: 1.9916\n",
      "    -            adv_start loss: 0.0032\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0053\n",
      "    -                total loss: 21.0718\n",
      "    -             emb_val other: 0.27578735\n",
      "    -         eff_perturb other: 0.00000171\n",
      "\n",
      "Epoch: 2: Step: 9786/9807; Global_step=29400; lr=2.217e-08; train time per batch = 1.49\n",
      "Train: global step = 29414; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9857\n",
      "    -                  end loss: 3.9558\n",
      "    -                 span loss: 7.9415\n",
      "    -              passage loss: 1.9993\n",
      "    -         history_span loss: 9.0133\n",
      "    -      history_passage loss: 2.0095\n",
      "    -            adv_start loss: 0.0033\n",
      "    -              adv_end loss: 0.0028\n",
      "    -        adv_relevance loss: 0.0052\n",
      "    -                total loss: 21.0202\n",
      "    -             emb_val other: 0.27588755\n",
      "    -         eff_perturb other: 0.00000163\n",
      "\n",
      "Avg. total Loss of epoch 2 =21.013\n",
      "================================================================================\n",
      "                               Training finished.\n",
      "================================================================================\n",
      "Best EM 1.64 path = dialki.0.10000.5000\n",
      "Best F1 14.27 path = dialki.0.10000.5000\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train_longformer.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a449a5",
   "metadata": {},
   "source": [
    "Hasil dari checkpoint training final yang berada pada folder dialdoc/exp dipindah ke dalam folder dialdoc/exp-finallongformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3235f",
   "metadata": {},
   "source": [
    "Kemudian dilakukan inference berdasarkan checkpoint sistem usulan yang dipilih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "384f4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   dialdoc/exp-finallongformer/dialki.2.19254.29241\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   dialdoc/inference\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/allenai/longformer-base-4096\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   None\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files dialdoc/exp-finallongformer/dialki.2.19254.29241\n",
      "Reading saved model from dialdoc/exp-finallongformer/dialki.2.19254.29241\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 50265 to 50269\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Loading checkpoint @epoch = 2, offset = 19254, global_step = 29241, \n",
      "Loading model weights from saved state ...\n",
      "No train files are specified. Run validation.\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_longformerlongformerlongformer/dev\n",
      "Data paths: ['./dialdoc/cache/cls_longformerlongformerlongformer/dev/2.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/0.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/1.pkl', './dialdoc/cache/cls_longformerlongformerlongformer/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.27\n",
      "Eval step 200 / 993; eval time per batch = 0.27\n",
      "Eval step 300 / 993; eval time per batch = 0.27\n",
      "Eval step 400 / 993; eval time per batch = 0.28\n",
      "Eval step 500 / 993; eval time per batch = 0.25\n",
      "Eval step 600 / 993; eval time per batch = 0.24\n",
      "Eval step 700 / 993; eval time per batch = 0.23\n",
      "Eval step 800 / 993; eval time per batch = 0.23\n",
      "Eval step 900 / 993; eval time per batch = 0.23\n",
      "eval_top_docs = 20\n",
      "F1 = 14.27\n",
      "Passage@1 = 16.31; Passage@2 = 33.63; Passage@3 = 46.00; \n",
      "Rank 1 passage: EM@1 = 1.64; EM@2 = 2.74; EM@3 = 3.58; \n",
      "Rank 2 passage: EM@1 = 1.51; EM@2 = 3.10; EM@3 = 4.03; \n",
      "Rank 3 passage: EM@1 = 1.23; EM@2 = 2.44; EM@3 = 3.42; \n",
      "\n",
      "Saving prediction results to  dialdoc/inference\n"
     ]
    }
   ],
   "source": [
    "!bash run_eval_longformer.sh 'dialdoc dialdoc/exp-finallongformer/dialki.2.19254.29241' 'dialdoc/inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218d36f",
   "metadata": {},
   "source": [
    "# Lakukan komparasi dengan baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1177a5a",
   "metadata": {},
   "source": [
    "Untuk melakukan komparasi lakukan rename pada file /models/_init__asli.py menjadi /models/_init__.py dan file /models/_init__.py yang merupakan konfigurasi longformer disimpan menjadi nama lain. Jika ingin melakukan training sistem usulan kembali ganti lagi file init konfigurasi longformer menjadi _init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e56056",
   "metadata": {},
   "source": [
    "Percobaan training baseline.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ceef3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = 0 device = device(type='cuda', index=0) n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_bert/dev\n",
      "device                         -->   cuda:0\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   0\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/bert-base-uncased\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_bert/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 30522 to 30526\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/opt/conda/lib/python3.8/site-packages/amp_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20getCurrentCUDAStreamEa')\n",
      "Data dir: ./dialdoc/cache/cls_bert/train\n",
      "Data paths: ['./dialdoc/cache/cls_bert/train/2.pkl', './dialdoc/cache/cls_bert/train/14.pkl', './dialdoc/cache/cls_bert/train/11.pkl', './dialdoc/cache/cls_bert/train/6.pkl', './dialdoc/cache/cls_bert/train/20.pkl', './dialdoc/cache/cls_bert/train/16.pkl', './dialdoc/cache/cls_bert/train/8.pkl', './dialdoc/cache/cls_bert/train/17.pkl', './dialdoc/cache/cls_bert/train/10.pkl', './dialdoc/cache/cls_bert/train/7.pkl', './dialdoc/cache/cls_bert/train/0.pkl', './dialdoc/cache/cls_bert/train/18.pkl', './dialdoc/cache/cls_bert/train/5.pkl', './dialdoc/cache/cls_bert/train/13.pkl', './dialdoc/cache/cls_bert/train/15.pkl', './dialdoc/cache/cls_bert/train/1.pkl', './dialdoc/cache/cls_bert/train/4.pkl', './dialdoc/cache/cls_bert/train/9.pkl', './dialdoc/cache/cls_bert/train/12.pkl', './dialdoc/cache/cls_bert/train/19.pkl', './dialdoc/cache/cls_bert/train/3.pkl']\n",
      "Total data size: 19604\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 196040.0\n",
      "Updates per epoch (/gradient accumulation) = 9802\n",
      "Steps per epoch (dataloader) = 9802\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 196040.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9802; Global_step=100; lr=3.000e-06; train time per batch = 0.80\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9134\n",
      "    -                  end loss: 3.9172\n",
      "    -                 span loss: 7.8306\n",
      "    -              passage loss: 1.9012\n",
      "    -         history_span loss: 8.8594\n",
      "    -      history_passage loss: 1.9430\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6475\n",
      "    -             emb_val other: 0.42788172\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Epoch: 0: Step: 200/9802; Global_step=200; lr=6.000e-06; train time per batch = 0.77\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9245\n",
      "    -                  end loss: 3.8963\n",
      "    -                 span loss: 7.8208\n",
      "    -              passage loss: 1.8939\n",
      "    -         history_span loss: 8.5231\n",
      "    -      history_passage loss: 1.9454\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.2912\n",
      "    -             emb_val other: 0.42901614\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.544.272\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch: 0: Step: 300/9802; Global_step=300; lr=9.000e-06; train time per batch = 0.77\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9047\n",
      "    -                 span loss: 7.8257\n",
      "    -              passage loss: 1.9636\n",
      "    -         history_span loss: 8.7784\n",
      "    -      history_passage loss: 2.0128\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6959\n",
      "    -             emb_val other: 0.42889991\n",
      "    -         eff_perturb other: 0.00000243\n",
      "\n",
      "Epoch: 0: Step: 400/9802; Global_step=400; lr=1.200e-05; train time per batch = 0.77\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9263\n",
      "    -                  end loss: 3.8933\n",
      "    -                 span loss: 7.8195\n",
      "    -              passage loss: 1.9297\n",
      "    -         history_span loss: 8.7178\n",
      "    -      history_passage loss: 1.9684\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5475\n",
      "    -             emb_val other: 0.42864746\n",
      "    -         eff_perturb other: 0.00000249\n",
      "\n",
      "Epoch: 0: Step: 500/9802; Global_step=500; lr=1.500e-05; train time per batch = 0.78\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9076\n",
      "    -                  end loss: 3.9076\n",
      "    -                 span loss: 7.8153\n",
      "    -              passage loss: 1.9498\n",
      "    -         history_span loss: 8.6568\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5386\n",
      "    -             emb_val other: 0.42985418\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1052.526\n",
      "Epoch: 0: Step: 600/9802; Global_step=600; lr=1.800e-05; train time per batch = 0.78\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9050\n",
      "    -                  end loss: 3.8983\n",
      "    -                 span loss: 7.8033\n",
      "    -              passage loss: 1.9642\n",
      "    -         history_span loss: 8.6777\n",
      "    -      history_passage loss: 2.0158\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5771\n",
      "    -             emb_val other: 0.42747933\n",
      "    -         eff_perturb other: 0.00000240\n",
      "\n",
      "Epoch: 0: Step: 700/9802; Global_step=700; lr=2.100e-05; train time per batch = 0.78\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9166\n",
      "    -                  end loss: 3.9156\n",
      "    -                 span loss: 7.8322\n",
      "    -              passage loss: 1.9499\n",
      "    -         history_span loss: 8.7951\n",
      "    -      history_passage loss: 1.9859\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.6830\n",
      "    -             emb_val other: 0.42899603\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1556.778\n",
      "Epoch: 0: Step: 800/9802; Global_step=800; lr=2.400e-05; train time per batch = 0.78\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9204\n",
      "    -                  end loss: 3.9058\n",
      "    -                 span loss: 7.8262\n",
      "    -              passage loss: 1.9575\n",
      "    -         history_span loss: 8.7997\n",
      "    -      history_passage loss: 2.0137\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0083\n",
      "    -                total loss: 20.7140\n",
      "    -             emb_val other: 0.42724243\n",
      "    -         eff_perturb other: 0.00000254\n",
      "\n",
      "Epoch: 0: Step: 900/9802; Global_step=900; lr=2.700e-05; train time per batch = 0.78\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9059\n",
      "    -                  end loss: 3.9069\n",
      "    -                 span loss: 7.8128\n",
      "    -              passage loss: 1.9359\n",
      "    -         history_span loss: 8.7146\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.5828\n",
      "    -             emb_val other: 0.42680719\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 0: Step: 1000/9802; Global_step=1000; lr=3.000e-05; train time per batch = 0.78\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9164\n",
      "    -                  end loss: 3.9167\n",
      "    -                 span loss: 7.8331\n",
      "    -              passage loss: 1.9400\n",
      "    -         history_span loss: 8.7323\n",
      "    -      history_passage loss: 1.9766\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5963\n",
      "    -             emb_val other: 0.42730319\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.10\n",
      "Eval step 200 / 993; eval time per batch = 0.12\n",
      "Eval step 300 / 993; eval time per batch = 0.12\n",
      "Eval step 400 / 993; eval time per batch = 0.12\n",
      "Eval step 500 / 993; eval time per batch = 0.11\n",
      "Eval step 600 / 993; eval time per batch = 0.11\n",
      "Eval step 700 / 993; eval time per batch = 0.10\n",
      "Eval step 800 / 993; eval time per batch = 0.10\n",
      "Eval step 900 / 993; eval time per batch = 0.10\n",
      "eval_top_docs = 20\n",
      "F1 = 12.89\n",
      "Passage@1 = 11.58; Passage@2 = 26.14; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.57; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.21; EM@2 = 2.44; EM@3 = 3.65; \n",
      "Rank 3 passage: EM@1 = 1.26; EM@2 = 2.37; EM@3 = 3.25; \n",
      "\n",
      "New best EM 1.36 on dev\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2000.1000\n",
      "New best F1 12.89 on dev\n",
      "Curr EM 1.36\n",
      "Curr F1 12.89\n",
      "Best EM 1.36 path = dialki.0.2000.1000\n",
      "Best F1 12.89 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2002.1001\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be2b1a",
   "metadata": {},
   "source": [
    "Percobaan training baseline yang final...dengan setting num_epoch : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b66ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   None\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_bert/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   3.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   None\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/bert-base-uncased\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   ./dialdoc/cache/cls_bert/train\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "Resize embedding from 30522 to 30526\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Data dir: ./dialdoc/cache/cls_bert/train\n",
      "Data paths: ['./dialdoc/cache/cls_bert/train/2.pkl', './dialdoc/cache/cls_bert/train/14.pkl', './dialdoc/cache/cls_bert/train/11.pkl', './dialdoc/cache/cls_bert/train/6.pkl', './dialdoc/cache/cls_bert/train/20.pkl', './dialdoc/cache/cls_bert/train/16.pkl', './dialdoc/cache/cls_bert/train/8.pkl', './dialdoc/cache/cls_bert/train/17.pkl', './dialdoc/cache/cls_bert/train/10.pkl', './dialdoc/cache/cls_bert/train/7.pkl', './dialdoc/cache/cls_bert/train/0.pkl', './dialdoc/cache/cls_bert/train/18.pkl', './dialdoc/cache/cls_bert/train/5.pkl', './dialdoc/cache/cls_bert/train/13.pkl', './dialdoc/cache/cls_bert/train/15.pkl', './dialdoc/cache/cls_bert/train/1.pkl', './dialdoc/cache/cls_bert/train/4.pkl', './dialdoc/cache/cls_bert/train/9.pkl', './dialdoc/cache/cls_bert/train/12.pkl', './dialdoc/cache/cls_bert/train/19.pkl', './dialdoc/cache/cls_bert/train/3.pkl']\n",
      "Total data size: 19604\n",
      "================================================================================\n",
      "                                    Training\n",
      "================================================================================\n",
      "Total updates = 29406.0\n",
      "Updates per epoch (/gradient accumulation) = 9802\n",
      "Steps per epoch (dataloader) = 9802\n",
      "Gradient accumulation steps = 1\n",
      "Start offset of the epoch 0 (dataset) = step 0\n",
      "Updated step of the epoch 0 (dataloader) = step 0\n",
      "Total remaining updates = 29406.0\n",
      "================================================================================\n",
      "                                    Epoch 0\n",
      "================================================================================\n",
      "Epoch: 0: Step: 100/9802; Global_step=100; lr=3.000e-06; train time per batch = 0.77\n",
      "Train: global step = 100; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9298\n",
      "    -                  end loss: 3.9027\n",
      "    -                 span loss: 7.8325\n",
      "    -              passage loss: 1.9297\n",
      "    -         history_span loss: 8.5935\n",
      "    -      history_passage loss: 1.9794\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.4531\n",
      "    -             emb_val other: 0.42699850\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 0: Step: 200/9802; Global_step=200; lr=6.000e-06; train time per batch = 0.75\n",
      "Train: global step = 200; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9212\n",
      "    -                  end loss: 3.9132\n",
      "    -                 span loss: 7.8344\n",
      "    -              passage loss: 1.9219\n",
      "    -         history_span loss: 8.7079\n",
      "    -      history_passage loss: 1.9509\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.5243\n",
      "    -             emb_val other: 0.42834699\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 0: Step: 300/9802; Global_step=300; lr=9.000e-06; train time per batch = 0.75\n",
      "Train: global step = 300; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9295\n",
      "    -                  end loss: 3.9115\n",
      "    -                 span loss: 7.8410\n",
      "    -              passage loss: 1.9446\n",
      "    -         history_span loss: 8.7216\n",
      "    -      history_passage loss: 1.9868\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6068\n",
      "    -             emb_val other: 0.42823124\n",
      "    -         eff_perturb other: 0.00000275\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.718.359\n",
      "Epoch: 0: Step: 400/9802; Global_step=400; lr=1.200e-05; train time per batch = 0.75\n",
      "Train: global step = 400; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9056\n",
      "    -                  end loss: 3.9020\n",
      "    -                 span loss: 7.8076\n",
      "    -              passage loss: 1.9021\n",
      "    -         history_span loss: 8.8622\n",
      "    -      history_passage loss: 1.9559\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.6392\n",
      "    -             emb_val other: 0.42797568\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Epoch: 0: Step: 500/9802; Global_step=500; lr=1.500e-05; train time per batch = 0.75\n",
      "Train: global step = 500; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9083\n",
      "    -                  end loss: 3.9093\n",
      "    -                 span loss: 7.8176\n",
      "    -              passage loss: 1.9201\n",
      "    -         history_span loss: 8.8157\n",
      "    -      history_passage loss: 1.9562\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6262\n",
      "    -             emb_val other: 0.42839557\n",
      "    -         eff_perturb other: 0.00000281\n",
      "\n",
      "Epoch: 0: Step: 600/9802; Global_step=600; lr=1.800e-05; train time per batch = 0.75\n",
      "Train: global step = 600; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9320\n",
      "    -                  end loss: 3.9095\n",
      "    -                 span loss: 7.8415\n",
      "    -              passage loss: 1.9487\n",
      "    -         history_span loss: 8.6845\n",
      "    -      history_passage loss: 1.9913\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0069\n",
      "    -                total loss: 20.5775\n",
      "    -             emb_val other: 0.42779872\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 0: Step: 700/9802; Global_step=700; lr=2.100e-05; train time per batch = 0.74\n",
      "Train: global step = 700; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9214\n",
      "    -                  end loss: 3.9043\n",
      "    -                 span loss: 7.8258\n",
      "    -              passage loss: 1.9475\n",
      "    -         history_span loss: 8.8851\n",
      "    -      history_passage loss: 1.9918\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7669\n",
      "    -             emb_val other: 0.42758608\n",
      "    -         eff_perturb other: 0.00000251\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.1436.718\n",
      "Epoch: 0: Step: 800/9802; Global_step=800; lr=2.400e-05; train time per batch = 0.75\n",
      "Train: global step = 800; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9148\n",
      "    -                  end loss: 3.9008\n",
      "    -                 span loss: 7.8156\n",
      "    -              passage loss: 1.9289\n",
      "    -         history_span loss: 8.7301\n",
      "    -      history_passage loss: 1.9676\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5581\n",
      "    -             emb_val other: 0.43008989\n",
      "    -         eff_perturb other: 0.00000266\n",
      "\n",
      "Epoch: 0: Step: 900/9802; Global_step=900; lr=2.700e-05; train time per batch = 0.74\n",
      "Train: global step = 900; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.8997\n",
      "    -                  end loss: 3.9058\n",
      "    -                 span loss: 7.8056\n",
      "    -              passage loss: 1.9034\n",
      "    -         history_span loss: 8.7982\n",
      "    -      history_passage loss: 1.9443\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5621\n",
      "    -             emb_val other: 0.42769814\n",
      "    -         eff_perturb other: 0.00000296\n",
      "\n",
      "Epoch: 0: Step: 1000/9802; Global_step=1000; lr=3.000e-05; train time per batch = 0.75\n",
      "Train: global step = 1000; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9056\n",
      "    -                  end loss: 3.8937\n",
      "    -                 span loss: 7.7992\n",
      "    -              passage loss: 1.9604\n",
      "    -         history_span loss: 8.7024\n",
      "    -      history_passage loss: 1.9848\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5641\n",
      "    -             emb_val other: 0.43037191\n",
      "    -         eff_perturb other: 0.00000246\n",
      "\n",
      "Validation: Epoch: 0 Step: 1000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "New best EM 1.36 on dev\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2000.1000\n",
      "New best F1 12.90 on dev\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.2000.1000\n",
      "Best F1 12.90 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2066.1033\n",
      "Epoch: 0: Step: 1200/9802; Global_step=1200; lr=2.979e-05; train time per batch = 0.74\n",
      "Train: global step = 1200; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9150\n",
      "    -                  end loss: 3.9031\n",
      "    -                 span loss: 7.8182\n",
      "    -              passage loss: 1.9269\n",
      "    -         history_span loss: 8.8342\n",
      "    -      history_passage loss: 1.9843\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6785\n",
      "    -             emb_val other: 0.42781466\n",
      "    -         eff_perturb other: 0.00000274\n",
      "\n",
      "Epoch: 0: Step: 1300/9802; Global_step=1300; lr=2.968e-05; train time per batch = 0.74\n",
      "Train: global step = 1300; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9157\n",
      "    -                  end loss: 3.9133\n",
      "    -                 span loss: 7.8290\n",
      "    -              passage loss: 1.9275\n",
      "    -         history_span loss: 8.7391\n",
      "    -      history_passage loss: 1.9706\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.5810\n",
      "    -             emb_val other: 0.42765647\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.2782.1391\n",
      "Epoch: 0: Step: 1400/9802; Global_step=1400; lr=2.958e-05; train time per batch = 0.74\n",
      "Train: global step = 1400; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9238\n",
      "    -                  end loss: 3.8930\n",
      "    -                 span loss: 7.8168\n",
      "    -              passage loss: 1.9617\n",
      "    -         history_span loss: 8.8091\n",
      "    -      history_passage loss: 1.9964\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6994\n",
      "    -             emb_val other: 0.42686230\n",
      "    -         eff_perturb other: 0.00000243\n",
      "\n",
      "Epoch: 0: Step: 1500/9802; Global_step=1500; lr=2.947e-05; train time per batch = 0.74\n",
      "Train: global step = 1500; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9230\n",
      "    -                  end loss: 3.9086\n",
      "    -                 span loss: 7.8316\n",
      "    -              passage loss: 1.9411\n",
      "    -         history_span loss: 8.8362\n",
      "    -      history_passage loss: 1.9876\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.7111\n",
      "    -             emb_val other: 0.42893130\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 0: Step: 1600/9802; Global_step=1600; lr=2.937e-05; train time per batch = 0.74\n",
      "Train: global step = 1600; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9073\n",
      "    -                  end loss: 3.9100\n",
      "    -                 span loss: 7.8173\n",
      "    -              passage loss: 1.9181\n",
      "    -         history_span loss: 8.6726\n",
      "    -      history_passage loss: 1.9796\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5037\n",
      "    -             emb_val other: 0.42682341\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 0: Step: 1700/9802; Global_step=1700; lr=2.926e-05; train time per batch = 0.74\n",
      "Train: global step = 1700; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9282\n",
      "    -                  end loss: 3.9095\n",
      "    -                 span loss: 7.8377\n",
      "    -              passage loss: 1.8986\n",
      "    -         history_span loss: 8.6903\n",
      "    -      history_passage loss: 1.9482\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.4919\n",
      "    -             emb_val other: 0.42932695\n",
      "    -         eff_perturb other: 0.00000290\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.3492.1746\n",
      "Epoch: 0: Step: 1800/9802; Global_step=1800; lr=2.916e-05; train time per batch = 0.74\n",
      "Train: global step = 1800; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9072\n",
      "    -                  end loss: 3.9187\n",
      "    -                 span loss: 7.8258\n",
      "    -              passage loss: 1.9369\n",
      "    -         history_span loss: 8.7796\n",
      "    -      history_passage loss: 2.0190\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0083\n",
      "    -                total loss: 20.6783\n",
      "    -             emb_val other: 0.42596993\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 0: Step: 1900/9802; Global_step=1900; lr=2.905e-05; train time per batch = 0.74\n",
      "Train: global step = 1900; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9228\n",
      "    -                  end loss: 3.9121\n",
      "    -                 span loss: 7.8349\n",
      "    -              passage loss: 1.9070\n",
      "    -         history_span loss: 8.8278\n",
      "    -      history_passage loss: 1.9460\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0077\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.6296\n",
      "    -             emb_val other: 0.42657870\n",
      "    -         eff_perturb other: 0.00000290\n",
      "\n",
      "Epoch: 0: Step: 2000/9802; Global_step=2000; lr=2.894e-05; train time per batch = 0.74\n",
      "Train: global step = 2000; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9276\n",
      "    -                  end loss: 3.9125\n",
      "    -                 span loss: 7.8401\n",
      "    -              passage loss: 1.8999\n",
      "    -         history_span loss: 8.7514\n",
      "    -      history_passage loss: 1.9717\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.5761\n",
      "    -             emb_val other: 0.42799240\n",
      "    -         eff_perturb other: 0.00000278\n",
      "\n",
      "Validation: Epoch: 0 Step: 2000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.10\n",
      "Eval step 200 / 993; eval time per batch = 0.11\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.11\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.2000.1000\n",
      "Best F1 12.90 path = dialki.0.2000.1000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4122.2061\n",
      "Epoch: 0: Step: 2100/9802; Global_step=2100; lr=2.884e-05; train time per batch = 0.74\n",
      "Train: global step = 2100; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9147\n",
      "    -                  end loss: 3.9069\n",
      "    -                 span loss: 7.8216\n",
      "    -              passage loss: 1.8937\n",
      "    -         history_span loss: 8.9262\n",
      "    -      history_passage loss: 1.9366\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6899\n",
      "    -             emb_val other: 0.42912117\n",
      "    -         eff_perturb other: 0.00000281\n",
      "\n",
      "Epoch: 0: Step: 2200/9802; Global_step=2200; lr=2.873e-05; train time per batch = 0.74\n",
      "Train: global step = 2200; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9221\n",
      "    -                  end loss: 3.9128\n",
      "    -                 span loss: 7.8349\n",
      "    -              passage loss: 1.9220\n",
      "    -         history_span loss: 8.6437\n",
      "    -      history_passage loss: 1.9646\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.4789\n",
      "    -             emb_val other: 0.42596218\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 0: Step: 2300/9802; Global_step=2300; lr=2.863e-05; train time per batch = 0.74\n",
      "Train: global step = 2300; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9140\n",
      "    -                  end loss: 3.9059\n",
      "    -                 span loss: 7.8199\n",
      "    -              passage loss: 1.9141\n",
      "    -         history_span loss: 8.7590\n",
      "    -      history_passage loss: 1.9666\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.5717\n",
      "    -             emb_val other: 0.42973647\n",
      "    -         eff_perturb other: 0.00000274\n",
      "\n",
      "Epoch: 0: Step: 2400/9802; Global_step=2400; lr=2.852e-05; train time per batch = 0.74\n",
      "Train: global step = 2400; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9287\n",
      "    -                  end loss: 3.8998\n",
      "    -                 span loss: 7.8285\n",
      "    -              passage loss: 1.9042\n",
      "    -         history_span loss: 8.7512\n",
      "    -      history_passage loss: 1.9648\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5626\n",
      "    -             emb_val other: 0.42738512\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.4850.2425\n",
      "Epoch: 0: Step: 2500/9802; Global_step=2500; lr=2.842e-05; train time per batch = 0.74\n",
      "Train: global step = 2500; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9303\n",
      "    -                  end loss: 3.9234\n",
      "    -                 span loss: 7.8537\n",
      "    -              passage loss: 1.9334\n",
      "    -         history_span loss: 8.7250\n",
      "    -      history_passage loss: 1.9850\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6117\n",
      "    -             emb_val other: 0.42881534\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 0: Step: 2600/9802; Global_step=2600; lr=2.831e-05; train time per batch = 0.74\n",
      "Train: global step = 2600; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9275\n",
      "    -                  end loss: 3.9077\n",
      "    -                 span loss: 7.8352\n",
      "    -              passage loss: 1.9437\n",
      "    -         history_span loss: 8.6348\n",
      "    -      history_passage loss: 1.9889\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5199\n",
      "    -             emb_val other: 0.42759529\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Epoch: 0: Step: 2700/9802; Global_step=2700; lr=2.820e-05; train time per batch = 0.74\n",
      "Train: global step = 2700; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9126\n",
      "    -                  end loss: 3.9044\n",
      "    -                 span loss: 7.8170\n",
      "    -              passage loss: 1.9794\n",
      "    -         history_span loss: 8.5654\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.4770\n",
      "    -             emb_val other: 0.42948553\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.5572.2786\n",
      "Epoch: 0: Step: 2800/9802; Global_step=2800; lr=2.810e-05; train time per batch = 0.74\n",
      "Train: global step = 2800; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9224\n",
      "    -                  end loss: 3.8990\n",
      "    -                 span loss: 7.8214\n",
      "    -              passage loss: 1.9116\n",
      "    -         history_span loss: 8.8361\n",
      "    -      history_passage loss: 1.9806\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6621\n",
      "    -             emb_val other: 0.42638782\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 0: Step: 2900/9802; Global_step=2900; lr=2.799e-05; train time per batch = 0.74\n",
      "Train: global step = 2900; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9054\n",
      "    -                  end loss: 3.8942\n",
      "    -                 span loss: 7.7996\n",
      "    -              passage loss: 1.9027\n",
      "    -         history_span loss: 8.7517\n",
      "    -      history_passage loss: 1.9554\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5266\n",
      "    -             emb_val other: 0.42812973\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Epoch: 0: Step: 3000/9802; Global_step=3000; lr=2.789e-05; train time per batch = 0.74\n",
      "Train: global step = 3000; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9207\n",
      "    -                  end loss: 3.9099\n",
      "    -                 span loss: 7.8306\n",
      "    -              passage loss: 1.9247\n",
      "    -         history_span loss: 9.0017\n",
      "    -      history_passage loss: 1.9670\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.8411\n",
      "    -             emb_val other: 0.42859283\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Validation: Epoch: 0 Step: 3000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.2000.1000\n",
      "Best F1 12.90 path = dialki.0.2000.1000\n",
      "Epoch: 0: Step: 3100/9802; Global_step=3100; lr=2.778e-05; train time per batch = 0.74\n",
      "Train: global step = 3100; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9168\n",
      "    -                  end loss: 3.8917\n",
      "    -                 span loss: 7.8085\n",
      "    -              passage loss: 1.9284\n",
      "    -         history_span loss: 8.5963\n",
      "    -      history_passage loss: 1.9719\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4223\n",
      "    -             emb_val other: 0.42970565\n",
      "    -         eff_perturb other: 0.00000285\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6220.3110\n",
      "Epoch: 0: Step: 3200/9802; Global_step=3200; lr=2.768e-05; train time per batch = 0.74\n",
      "Train: global step = 3200; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9299\n",
      "    -                  end loss: 3.9024\n",
      "    -                 span loss: 7.8324\n",
      "    -              passage loss: 1.9561\n",
      "    -         history_span loss: 8.7546\n",
      "    -      history_passage loss: 1.9994\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6565\n",
      "    -             emb_val other: 0.42683169\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Epoch: 0: Step: 3300/9802; Global_step=3300; lr=2.757e-05; train time per batch = 0.74\n",
      "Train: global step = 3300; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9037\n",
      "    -                  end loss: 3.9110\n",
      "    -                 span loss: 7.8147\n",
      "    -              passage loss: 1.9577\n",
      "    -         history_span loss: 8.7286\n",
      "    -      history_passage loss: 1.9875\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6036\n",
      "    -             emb_val other: 0.42793074\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Epoch: 0: Step: 3400/9802; Global_step=3400; lr=2.747e-05; train time per batch = 0.74\n",
      "Train: global step = 3400; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9296\n",
      "    -                  end loss: 3.8968\n",
      "    -                 span loss: 7.8264\n",
      "    -              passage loss: 1.9201\n",
      "    -         history_span loss: 8.8045\n",
      "    -      history_passage loss: 1.9716\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.6355\n",
      "    -             emb_val other: 0.42923397\n",
      "    -         eff_perturb other: 0.00000277\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.6954.3477\n",
      "Epoch: 0: Step: 3500/9802; Global_step=3500; lr=2.736e-05; train time per batch = 0.74\n",
      "Train: global step = 3500; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9158\n",
      "    -                  end loss: 3.9212\n",
      "    -                 span loss: 7.8370\n",
      "    -              passage loss: 1.9015\n",
      "    -         history_span loss: 8.7680\n",
      "    -      history_passage loss: 1.9493\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5667\n",
      "    -             emb_val other: 0.42899784\n",
      "    -         eff_perturb other: 0.00000278\n",
      "\n",
      "Epoch: 0: Step: 3600/9802; Global_step=3600; lr=2.725e-05; train time per batch = 0.74\n",
      "Train: global step = 3600; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9109\n",
      "    -                  end loss: 3.9152\n",
      "    -                 span loss: 7.8260\n",
      "    -              passage loss: 1.8751\n",
      "    -         history_span loss: 8.6161\n",
      "    -      history_passage loss: 1.9120\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0077\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.3376\n",
      "    -             emb_val other: 0.43006837\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 0: Step: 3700/9802; Global_step=3700; lr=2.715e-05; train time per batch = 0.74\n",
      "Train: global step = 3700; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9221\n",
      "    -                  end loss: 3.9129\n",
      "    -                 span loss: 7.8350\n",
      "    -              passage loss: 1.9106\n",
      "    -         history_span loss: 8.6465\n",
      "    -      history_passage loss: 1.9678\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.4704\n",
      "    -             emb_val other: 0.42729533\n",
      "    -         eff_perturb other: 0.00000274\n",
      "\n",
      "Epoch: 0: Step: 3800/9802; Global_step=3800; lr=2.704e-05; train time per batch = 0.74\n",
      "Train: global step = 3800; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.8971\n",
      "    -                 span loss: 7.8159\n",
      "    -              passage loss: 1.8907\n",
      "    -         history_span loss: 8.7346\n",
      "    -      history_passage loss: 1.9458\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5023\n",
      "    -             emb_val other: 0.42959130\n",
      "    -         eff_perturb other: 0.00000291\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.7686.3843\n",
      "Epoch: 0: Step: 4000/9802; Global_step=4000; lr=2.683e-05; train time per batch = 0.73\n",
      "Train: global step = 4000; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9128\n",
      "    -                  end loss: 3.9084\n",
      "    -                 span loss: 7.8212\n",
      "    -              passage loss: 1.9137\n",
      "    -         history_span loss: 8.7149\n",
      "    -      history_passage loss: 1.9439\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5053\n",
      "    -             emb_val other: 0.42827395\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Validation: Epoch: 0 Step: 4000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.2000.1000\n",
      "Best F1 12.90 path = dialki.0.2000.1000\n",
      "Epoch: 0: Step: 4100/9802; Global_step=4100; lr=2.673e-05; train time per batch = 0.73\n",
      "Train: global step = 4100; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9213\n",
      "    -                  end loss: 3.9031\n",
      "    -                 span loss: 7.8244\n",
      "    -              passage loss: 1.9601\n",
      "    -         history_span loss: 8.7631\n",
      "    -      history_passage loss: 1.9909\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6506\n",
      "    -             emb_val other: 0.42765906\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.8324.4162\n",
      "Epoch: 0: Step: 4200/9802; Global_step=4200; lr=2.662e-05; train time per batch = 0.73\n",
      "Train: global step = 4200; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9304\n",
      "    -                  end loss: 3.9049\n",
      "    -                 span loss: 7.8353\n",
      "    -              passage loss: 1.8870\n",
      "    -         history_span loss: 8.8195\n",
      "    -      history_passage loss: 1.9474\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0077\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6007\n",
      "    -             emb_val other: 0.42793074\n",
      "    -         eff_perturb other: 0.00000284\n",
      "\n",
      "Epoch: 0: Step: 4300/9802; Global_step=4300; lr=2.651e-05; train time per batch = 0.73\n",
      "Train: global step = 4300; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9242\n",
      "    -                  end loss: 3.9163\n",
      "    -                 span loss: 7.8405\n",
      "    -              passage loss: 1.9084\n",
      "    -         history_span loss: 8.8500\n",
      "    -      history_passage loss: 1.9526\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6670\n",
      "    -             emb_val other: 0.42937607\n",
      "    -         eff_perturb other: 0.00000289\n",
      "\n",
      "Epoch: 0: Step: 4400/9802; Global_step=4400; lr=2.641e-05; train time per batch = 0.74\n",
      "Train: global step = 4400; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9261\n",
      "    -                  end loss: 3.9171\n",
      "    -                 span loss: 7.8432\n",
      "    -              passage loss: 1.9191\n",
      "    -         history_span loss: 8.9159\n",
      "    -      history_passage loss: 1.9450\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7410\n",
      "    -             emb_val other: 0.42966533\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 0: Step: 4500/9802; Global_step=4500; lr=2.630e-05; train time per batch = 0.74\n",
      "Train: global step = 4500; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9125\n",
      "    -                  end loss: 3.9022\n",
      "    -                 span loss: 7.8147\n",
      "    -              passage loss: 1.9188\n",
      "    -         history_span loss: 8.9200\n",
      "    -      history_passage loss: 1.9770\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.7487\n",
      "    -             emb_val other: 0.42801124\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.9036.4518\n",
      "Epoch: 0: Step: 4600/9802; Global_step=4600; lr=2.620e-05; train time per batch = 0.74\n",
      "Train: global step = 4600; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9086\n",
      "    -                  end loss: 3.9160\n",
      "    -                 span loss: 7.8246\n",
      "    -              passage loss: 1.9123\n",
      "    -         history_span loss: 8.7502\n",
      "    -      history_passage loss: 1.9548\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5592\n",
      "    -             emb_val other: 0.42957455\n",
      "    -         eff_perturb other: 0.00000288\n",
      "\n",
      "Epoch: 0: Step: 4700/9802; Global_step=4700; lr=2.609e-05; train time per batch = 0.74\n",
      "Train: global step = 4700; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.8962\n",
      "    -                 span loss: 7.8150\n",
      "    -              passage loss: 1.9441\n",
      "    -         history_span loss: 8.6812\n",
      "    -      history_passage loss: 1.9867\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5392\n",
      "    -             emb_val other: 0.42925197\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 0: Step: 4800/9802; Global_step=4800; lr=2.599e-05; train time per batch = 0.74\n",
      "Train: global step = 4800; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9130\n",
      "    -                  end loss: 3.9111\n",
      "    -                 span loss: 7.8241\n",
      "    -              passage loss: 1.9352\n",
      "    -         history_span loss: 8.6402\n",
      "    -      history_passage loss: 1.9950\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5087\n",
      "    -             emb_val other: 0.42816061\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.9736.4868\n",
      "Epoch: 0: Step: 4900/9802; Global_step=4900; lr=2.588e-05; train time per batch = 0.74\n",
      "Train: global step = 4900; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9212\n",
      "    -                  end loss: 3.9072\n",
      "    -                 span loss: 7.8284\n",
      "    -              passage loss: 1.9626\n",
      "    -         history_span loss: 8.8866\n",
      "    -      history_passage loss: 2.0070\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0084\n",
      "    -                total loss: 20.8064\n",
      "    -             emb_val other: 0.42736220\n",
      "    -         eff_perturb other: 0.00000261\n",
      "\n",
      "Epoch: 0: Step: 5000/9802; Global_step=5000; lr=2.578e-05; train time per batch = 0.74\n",
      "Train: global step = 5000; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9084\n",
      "    -                  end loss: 3.8901\n",
      "    -                 span loss: 7.7985\n",
      "    -              passage loss: 1.9407\n",
      "    -         history_span loss: 8.6045\n",
      "    -      history_passage loss: 1.9937\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.4488\n",
      "    -             emb_val other: 0.42819309\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Validation: Epoch: 0 Step: 5000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 5100/9802; Global_step=5100; lr=2.567e-05; train time per batch = 0.74\n",
      "Train: global step = 5100; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9191\n",
      "    -                  end loss: 3.9097\n",
      "    -                 span loss: 7.8288\n",
      "    -              passage loss: 1.9777\n",
      "    -         history_span loss: 8.6881\n",
      "    -      history_passage loss: 2.0198\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6298\n",
      "    -             emb_val other: 0.42823577\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.10360.5180\n",
      "Epoch: 0: Step: 5200/9802; Global_step=5200; lr=2.556e-05; train time per batch = 0.74\n",
      "Train: global step = 5200; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9135\n",
      "    -                  end loss: 3.9176\n",
      "    -                 span loss: 7.8312\n",
      "    -              passage loss: 1.9586\n",
      "    -         history_span loss: 8.7622\n",
      "    -      history_passage loss: 2.0073\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6737\n",
      "    -             emb_val other: 0.42867741\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Epoch: 0: Step: 5300/9802; Global_step=5300; lr=2.546e-05; train time per batch = 0.74\n",
      "Train: global step = 5300; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9246\n",
      "    -                  end loss: 3.9116\n",
      "    -                 span loss: 7.8362\n",
      "    -              passage loss: 1.9529\n",
      "    -         history_span loss: 8.9386\n",
      "    -      history_passage loss: 1.9843\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.8251\n",
      "    -             emb_val other: 0.42935485\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 0: Step: 5400/9802; Global_step=5400; lr=2.535e-05; train time per batch = 0.74\n",
      "Train: global step = 5400; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9269\n",
      "    -                  end loss: 3.9059\n",
      "    -                 span loss: 7.8328\n",
      "    -              passage loss: 1.9432\n",
      "    -         history_span loss: 8.8365\n",
      "    -      history_passage loss: 1.9938\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.7238\n",
      "    -             emb_val other: 0.43042961\n",
      "    -         eff_perturb other: 0.00000254\n",
      "\n",
      "Epoch: 0: Step: 5500/9802; Global_step=5500; lr=2.525e-05; train time per batch = 0.74\n",
      "Train: global step = 5500; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9109\n",
      "    -                  end loss: 3.9068\n",
      "    -                 span loss: 7.8176\n",
      "    -              passage loss: 1.9240\n",
      "    -         history_span loss: 8.6435\n",
      "    -      history_passage loss: 1.9627\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.4634\n",
      "    -             emb_val other: 0.42935148\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11064.5532\n",
      "Epoch: 0: Step: 5600/9802; Global_step=5600; lr=2.514e-05; train time per batch = 0.74\n",
      "Train: global step = 5600; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9085\n",
      "    -                  end loss: 3.8902\n",
      "    -                 span loss: 7.7987\n",
      "    -              passage loss: 1.9697\n",
      "    -         history_span loss: 8.8842\n",
      "    -      history_passage loss: 1.9995\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.7649\n",
      "    -             emb_val other: 0.42825240\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 0: Step: 5700/9802; Global_step=5700; lr=2.504e-05; train time per batch = 0.74\n",
      "Train: global step = 5700; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9178\n",
      "    -                  end loss: 3.8976\n",
      "    -                 span loss: 7.8153\n",
      "    -              passage loss: 1.9438\n",
      "    -         history_span loss: 8.7173\n",
      "    -      history_passage loss: 1.9975\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.5849\n",
      "    -             emb_val other: 0.42690226\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Epoch: 0: Step: 5800/9802; Global_step=5800; lr=2.493e-05; train time per batch = 0.74\n",
      "Train: global step = 5800; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9217\n",
      "    -                  end loss: 3.8946\n",
      "    -                 span loss: 7.8163\n",
      "    -              passage loss: 1.9190\n",
      "    -         history_span loss: 8.5176\n",
      "    -      history_passage loss: 1.9703\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0076\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.3336\n",
      "    -             emb_val other: 0.42829958\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.11776.5888\n",
      "Epoch: 0: Step: 5900/9802; Global_step=5900; lr=2.483e-05; train time per batch = 0.74\n",
      "Train: global step = 5900; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9136\n",
      "    -                  end loss: 3.9099\n",
      "    -                 span loss: 7.8235\n",
      "    -              passage loss: 1.9238\n",
      "    -         history_span loss: 8.7970\n",
      "    -      history_passage loss: 1.9767\n",
      "    -            adv_start loss: 0.0062\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6275\n",
      "    -             emb_val other: 0.42538083\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 0: Step: 6000/9802; Global_step=6000; lr=2.472e-05; train time per batch = 0.74\n",
      "Train: global step = 6000; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9009\n",
      "    -                  end loss: 3.9031\n",
      "    -                 span loss: 7.8040\n",
      "    -              passage loss: 1.9448\n",
      "    -         history_span loss: 8.7975\n",
      "    -      history_passage loss: 1.9702\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6312\n",
      "    -             emb_val other: 0.43004212\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Validation: Epoch: 0 Step: 6000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 6100/9802; Global_step=6100; lr=2.461e-05; train time per batch = 0.74\n",
      "Train: global step = 6100; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9118\n",
      "    -                  end loss: 3.9144\n",
      "    -                 span loss: 7.8262\n",
      "    -              passage loss: 1.9034\n",
      "    -         history_span loss: 8.8432\n",
      "    -      history_passage loss: 1.9609\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.6510\n",
      "    -             emb_val other: 0.42897287\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.12388.6194\n",
      "Epoch: 0: Step: 6200/9802; Global_step=6200; lr=2.451e-05; train time per batch = 0.74\n",
      "Train: global step = 6200; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9116\n",
      "    -                  end loss: 3.9059\n",
      "    -                 span loss: 7.8175\n",
      "    -              passage loss: 1.9598\n",
      "    -         history_span loss: 8.8431\n",
      "    -      history_passage loss: 1.9991\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.7314\n",
      "    -             emb_val other: 0.42820576\n",
      "    -         eff_perturb other: 0.00000246\n",
      "\n",
      "Epoch: 0: Step: 6300/9802; Global_step=6300; lr=2.440e-05; train time per batch = 0.74\n",
      "Train: global step = 6300; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9085\n",
      "    -                  end loss: 3.9216\n",
      "    -                 span loss: 7.8301\n",
      "    -              passage loss: 1.9070\n",
      "    -         history_span loss: 8.6582\n",
      "    -      history_passage loss: 1.9692\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.4802\n",
      "    -             emb_val other: 0.42738074\n",
      "    -         eff_perturb other: 0.00000275\n",
      "\n",
      "Epoch: 0: Step: 6400/9802; Global_step=6400; lr=2.430e-05; train time per batch = 0.74\n",
      "Train: global step = 6400; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9197\n",
      "    -                  end loss: 3.8971\n",
      "    -                 span loss: 7.8169\n",
      "    -              passage loss: 1.9050\n",
      "    -         history_span loss: 8.7280\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5272\n",
      "    -             emb_val other: 0.42944562\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 0: Step: 6500/9802; Global_step=6500; lr=2.419e-05; train time per batch = 0.74\n",
      "Train: global step = 6500; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9197\n",
      "    -                  end loss: 3.8916\n",
      "    -                 span loss: 7.8113\n",
      "    -              passage loss: 1.9218\n",
      "    -         history_span loss: 8.9743\n",
      "    -      history_passage loss: 1.9560\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.7798\n",
      "    -             emb_val other: 0.43003762\n",
      "    -         eff_perturb other: 0.00000284\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.13084.6542\n",
      "Epoch: 0: Step: 6700/9802; Global_step=6700; lr=2.398e-05; train time per batch = 0.74\n",
      "Train: global step = 6700; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9170\n",
      "    -                  end loss: 3.9049\n",
      "    -                 span loss: 7.8218\n",
      "    -              passage loss: 1.9557\n",
      "    -         history_span loss: 8.5874\n",
      "    -      history_passage loss: 2.0043\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4837\n",
      "    -             emb_val other: 0.42839798\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 0: Step: 6800/9802; Global_step=6800; lr=2.387e-05; train time per batch = 0.74\n",
      "Train: global step = 6800; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9219\n",
      "    -                  end loss: 3.9048\n",
      "    -                 span loss: 7.8267\n",
      "    -              passage loss: 1.9084\n",
      "    -         history_span loss: 8.8030\n",
      "    -      history_passage loss: 1.9391\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5879\n",
      "    -             emb_val other: 0.42810738\n",
      "    -         eff_perturb other: 0.00000274\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.13782.6891\n",
      "Epoch: 0: Step: 6900/9802; Global_step=6900; lr=2.377e-05; train time per batch = 0.74\n",
      "Train: global step = 6900; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9150\n",
      "    -                  end loss: 3.9025\n",
      "    -                 span loss: 7.8175\n",
      "    -              passage loss: 1.8876\n",
      "    -         history_span loss: 8.6054\n",
      "    -      history_passage loss: 1.9579\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0084\n",
      "    -                total loss: 20.3836\n",
      "    -             emb_val other: 0.42768514\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 0: Step: 7000/9802; Global_step=7000; lr=2.366e-05; train time per batch = 0.74\n",
      "Train: global step = 7000; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9149\n",
      "    -                  end loss: 3.9037\n",
      "    -                 span loss: 7.8186\n",
      "    -              passage loss: 1.9413\n",
      "    -         history_span loss: 8.5609\n",
      "    -      history_passage loss: 1.9780\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4108\n",
      "    -             emb_val other: 0.42894921\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Validation: Epoch: 0 Step: 7000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 7100/9802; Global_step=7100; lr=2.356e-05; train time per batch = 0.74\n",
      "Train: global step = 7100; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9175\n",
      "    -                  end loss: 3.9023\n",
      "    -                 span loss: 7.8197\n",
      "    -              passage loss: 1.9328\n",
      "    -         history_span loss: 8.7132\n",
      "    -      history_passage loss: 1.9683\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5457\n",
      "    -             emb_val other: 0.42791298\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 0: Step: 7200/9802; Global_step=7200; lr=2.345e-05; train time per batch = 0.74\n",
      "Train: global step = 7200; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.8921\n",
      "    -                 span loss: 7.8109\n",
      "    -              passage loss: 1.9308\n",
      "    -         history_span loss: 8.7662\n",
      "    -      history_passage loss: 1.9734\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5975\n",
      "    -             emb_val other: 0.42796406\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.14408.7204\n",
      "Epoch: 0: Step: 7300/9802; Global_step=7300; lr=2.335e-05; train time per batch = 0.74\n",
      "Train: global step = 7300; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9187\n",
      "    -                  end loss: 3.9142\n",
      "    -                 span loss: 7.8328\n",
      "    -              passage loss: 1.9119\n",
      "    -         history_span loss: 8.5540\n",
      "    -      history_passage loss: 1.9722\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.3845\n",
      "    -             emb_val other: 0.42850074\n",
      "    -         eff_perturb other: 0.00000288\n",
      "\n",
      "Epoch: 0: Step: 7400/9802; Global_step=7400; lr=2.324e-05; train time per batch = 0.74\n",
      "Train: global step = 7400; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9160\n",
      "    -                  end loss: 3.9020\n",
      "    -                 span loss: 7.8180\n",
      "    -              passage loss: 1.9061\n",
      "    -         history_span loss: 8.8539\n",
      "    -      history_passage loss: 1.9615\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0083\n",
      "    -                total loss: 20.6578\n",
      "    -             emb_val other: 0.42869541\n",
      "    -         eff_perturb other: 0.00000289\n",
      "\n",
      "Epoch: 0: Step: 7500/9802; Global_step=7500; lr=2.314e-05; train time per batch = 0.74\n",
      "Train: global step = 7500; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9071\n",
      "    -                  end loss: 3.9182\n",
      "    -                 span loss: 7.8253\n",
      "    -              passage loss: 1.9319\n",
      "    -         history_span loss: 8.7063\n",
      "    -      history_passage loss: 1.9691\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0068\n",
      "    -                total loss: 20.5420\n",
      "    -             emb_val other: 0.42668170\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15114.7557\n",
      "Epoch: 0: Step: 7600/9802; Global_step=7600; lr=2.303e-05; train time per batch = 0.74\n",
      "Train: global step = 7600; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9234\n",
      "    -                  end loss: 3.8924\n",
      "    -                 span loss: 7.8158\n",
      "    -              passage loss: 1.9537\n",
      "    -         history_span loss: 8.6665\n",
      "    -      history_passage loss: 1.9906\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5430\n",
      "    -             emb_val other: 0.42833674\n",
      "    -         eff_perturb other: 0.00000261\n",
      "\n",
      "Epoch: 0: Step: 7700/9802; Global_step=7700; lr=2.292e-05; train time per batch = 0.74\n",
      "Train: global step = 7700; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9157\n",
      "    -                  end loss: 3.8917\n",
      "    -                 span loss: 7.8073\n",
      "    -              passage loss: 1.9347\n",
      "    -         history_span loss: 8.7758\n",
      "    -      history_passage loss: 1.9862\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0077\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6161\n",
      "    -             emb_val other: 0.42624217\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 0: Step: 7800/9802; Global_step=7800; lr=2.282e-05; train time per batch = 0.74\n",
      "Train: global step = 7800; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9083\n",
      "    -                  end loss: 3.8908\n",
      "    -                 span loss: 7.7991\n",
      "    -              passage loss: 1.9592\n",
      "    -         history_span loss: 8.7372\n",
      "    -      history_passage loss: 1.9880\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6010\n",
      "    -             emb_val other: 0.42897651\n",
      "    -         eff_perturb other: 0.00000252\n",
      "\n",
      "Epoch: 0: Step: 7900/9802; Global_step=7900; lr=2.271e-05; train time per batch = 0.74\n",
      "Train: global step = 7900; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9292\n",
      "    -                  end loss: 3.9088\n",
      "    -                 span loss: 7.8379\n",
      "    -              passage loss: 1.8968\n",
      "    -         history_span loss: 8.9266\n",
      "    -      history_passage loss: 1.9511\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.7291\n",
      "    -             emb_val other: 0.42736876\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.15834.7917\n",
      "Epoch: 0: Step: 8000/9802; Global_step=8000; lr=2.261e-05; train time per batch = 0.74\n",
      "Train: global step = 8000; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9146\n",
      "    -                  end loss: 3.9179\n",
      "    -                 span loss: 7.8324\n",
      "    -              passage loss: 1.8662\n",
      "    -         history_span loss: 8.8221\n",
      "    -      history_passage loss: 1.9227\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5555\n",
      "    -             emb_val other: 0.43007869\n",
      "    -         eff_perturb other: 0.00000295\n",
      "\n",
      "Validation: Epoch: 0 Step: 8000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Epoch: 0: Step: 8100/9802; Global_step=8100; lr=2.250e-05; train time per batch = 0.74\n",
      "Train: global step = 8100; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9287\n",
      "    -                  end loss: 3.9090\n",
      "    -                 span loss: 7.8377\n",
      "    -              passage loss: 1.9021\n",
      "    -         history_span loss: 8.7218\n",
      "    -      history_passage loss: 1.9465\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5211\n",
      "    -             emb_val other: 0.42856652\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Epoch: 0: Step: 8200/9802; Global_step=8200; lr=2.240e-05; train time per batch = 0.74\n",
      "Train: global step = 8200; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9104\n",
      "    -                  end loss: 3.9045\n",
      "    -                 span loss: 7.8149\n",
      "    -              passage loss: 1.9516\n",
      "    -         history_span loss: 8.8807\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.7603\n",
      "    -             emb_val other: 0.42882705\n",
      "    -         eff_perturb other: 0.00000280\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.16524.8262\n",
      "Epoch: 0: Step: 8300/9802; Global_step=8300; lr=2.229e-05; train time per batch = 0.74\n",
      "Train: global step = 8300; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9274\n",
      "    -                  end loss: 3.9091\n",
      "    -                 span loss: 7.8365\n",
      "    -              passage loss: 1.9540\n",
      "    -         history_span loss: 8.6466\n",
      "    -      history_passage loss: 1.9982\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.5477\n",
      "    -             emb_val other: 0.42813668\n",
      "    -         eff_perturb other: 0.00000250\n",
      "\n",
      "Epoch: 0: Step: 8400/9802; Global_step=8400; lr=2.218e-05; train time per batch = 0.74\n",
      "Train: global step = 8400; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9168\n",
      "    -                  end loss: 3.9049\n",
      "    -                 span loss: 7.8217\n",
      "    -              passage loss: 1.9228\n",
      "    -         history_span loss: 8.7472\n",
      "    -      history_passage loss: 1.9772\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5830\n",
      "    -             emb_val other: 0.42779812\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 0: Step: 8500/9802; Global_step=8500; lr=2.208e-05; train time per batch = 0.74\n",
      "Train: global step = 8500; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9101\n",
      "    -                  end loss: 3.9013\n",
      "    -                 span loss: 7.8115\n",
      "    -              passage loss: 1.9034\n",
      "    -         history_span loss: 8.7761\n",
      "    -      history_passage loss: 1.9586\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5653\n",
      "    -             emb_val other: 0.42894062\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 0: Step: 8600/9802; Global_step=8600; lr=2.197e-05; train time per batch = 0.74\n",
      "Train: global step = 8600; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9206\n",
      "    -                  end loss: 3.9199\n",
      "    -                 span loss: 7.8404\n",
      "    -              passage loss: 1.9626\n",
      "    -         history_span loss: 8.7644\n",
      "    -      history_passage loss: 2.0034\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6843\n",
      "    -             emb_val other: 0.42775920\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.17280.8640\n",
      "Epoch: 0: Step: 8700/9802; Global_step=8700; lr=2.187e-05; train time per batch = 0.74\n",
      "Train: global step = 8700; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9271\n",
      "    -                  end loss: 3.8964\n",
      "    -                 span loss: 7.8235\n",
      "    -              passage loss: 1.9348\n",
      "    -         history_span loss: 8.7463\n",
      "    -      history_passage loss: 1.9908\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6093\n",
      "    -             emb_val other: 0.42870501\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 0: Step: 8800/9802; Global_step=8800; lr=2.176e-05; train time per batch = 0.74\n",
      "Train: global step = 8800; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9111\n",
      "    -                  end loss: 3.8988\n",
      "    -                 span loss: 7.8099\n",
      "    -              passage loss: 1.9431\n",
      "    -         history_span loss: 8.8195\n",
      "    -      history_passage loss: 1.9789\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6634\n",
      "    -             emb_val other: 0.42897069\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 0: Step: 8900/9802; Global_step=8900; lr=2.166e-05; train time per batch = 0.74\n",
      "Train: global step = 8900; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9162\n",
      "    -                  end loss: 3.9053\n",
      "    -                 span loss: 7.8215\n",
      "    -              passage loss: 1.9325\n",
      "    -         history_span loss: 8.5071\n",
      "    -      history_passage loss: 1.9831\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.3603\n",
      "    -             emb_val other: 0.42882431\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 0: Step: 9000/9802; Global_step=9000; lr=2.155e-05; train time per batch = 0.74\n",
      "Train: global step = 9000; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9191\n",
      "    -                  end loss: 3.9059\n",
      "    -                 span loss: 7.8250\n",
      "    -              passage loss: 1.9121\n",
      "    -         history_span loss: 8.5039\n",
      "    -      history_passage loss: 1.9650\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0076\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.3122\n",
      "    -             emb_val other: 0.42710331\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Validation: Epoch: 0 Step: 9000/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18002.9001\n",
      "Epoch: 0: Step: 9100/9802; Global_step=9100; lr=2.145e-05; train time per batch = 0.74\n",
      "Train: global step = 9100; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9172\n",
      "    -                  end loss: 3.9068\n",
      "    -                 span loss: 7.8240\n",
      "    -              passage loss: 1.9228\n",
      "    -         history_span loss: 8.8283\n",
      "    -      history_passage loss: 1.9870\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6816\n",
      "    -             emb_val other: 0.42784736\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 0: Step: 9200/9802; Global_step=9200; lr=2.134e-05; train time per batch = 0.74\n",
      "Train: global step = 9200; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9142\n",
      "    -                  end loss: 3.8987\n",
      "    -                 span loss: 7.8130\n",
      "    -              passage loss: 1.9514\n",
      "    -         history_span loss: 8.8073\n",
      "    -      history_passage loss: 2.0077\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0084\n",
      "    -                total loss: 20.6964\n",
      "    -             emb_val other: 0.42692840\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Epoch: 0: Step: 9300/9802; Global_step=9300; lr=2.123e-05; train time per batch = 0.74\n",
      "Train: global step = 9300; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9093\n",
      "    -                  end loss: 3.9153\n",
      "    -                 span loss: 7.8247\n",
      "    -              passage loss: 1.9449\n",
      "    -         history_span loss: 8.8577\n",
      "    -      history_passage loss: 1.9827\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.7300\n",
      "    -             emb_val other: 0.42783514\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.18768.9384\n",
      "Epoch: 0: Step: 9400/9802; Global_step=9400; lr=2.113e-05; train time per batch = 0.74\n",
      "Train: global step = 9400; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9167\n",
      "    -                  end loss: 3.8961\n",
      "    -                 span loss: 7.8128\n",
      "    -              passage loss: 1.9497\n",
      "    -         history_span loss: 8.8886\n",
      "    -      history_passage loss: 1.9860\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.7510\n",
      "    -             emb_val other: 0.42969790\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 0: Step: 9500/9802; Global_step=9500; lr=2.102e-05; train time per batch = 0.74\n",
      "Train: global step = 9500; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9102\n",
      "    -                  end loss: 3.9073\n",
      "    -                 span loss: 7.8174\n",
      "    -              passage loss: 1.9194\n",
      "    -         history_span loss: 8.9513\n",
      "    -      history_passage loss: 1.9679\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.7700\n",
      "    -             emb_val other: 0.42814079\n",
      "    -         eff_perturb other: 0.00000291\n",
      "\n",
      "Epoch: 0: Step: 9600/9802; Global_step=9600; lr=2.092e-05; train time per batch = 0.74\n",
      "Train: global step = 9600; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9150\n",
      "    -                 span loss: 7.8359\n",
      "    -              passage loss: 1.9562\n",
      "    -         history_span loss: 8.7896\n",
      "    -      history_passage loss: 1.9993\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6951\n",
      "    -             emb_val other: 0.42740539\n",
      "    -         eff_perturb other: 0.00000251\n",
      "\n",
      "Epoch: 0: Step: 9700/9802; Global_step=9700; lr=2.081e-05; train time per batch = 0.74\n",
      "Train: global step = 9700; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9177\n",
      "    -                  end loss: 3.9062\n",
      "    -                 span loss: 7.8240\n",
      "    -              passage loss: 1.9620\n",
      "    -         history_span loss: 8.6508\n",
      "    -      history_passage loss: 1.9935\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.5441\n",
      "    -             emb_val other: 0.42918155\n",
      "    -         eff_perturb other: 0.00000247\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.0.19542.9771\n",
      "Epoch: 0: Step: 9800/9802; Global_step=9800; lr=2.071e-05; train time per batch = 0.74\n",
      "Train: global step = 9800; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9091\n",
      "    -                  end loss: 3.9070\n",
      "    -                 span loss: 7.8160\n",
      "    -              passage loss: 1.9321\n",
      "    -         history_span loss: 8.8085\n",
      "    -      history_passage loss: 1.9877\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6561\n",
      "    -             emb_val other: 0.42692232\n",
      "    -         eff_perturb other: 0.00000250\n",
      "\n",
      "Avg. total Loss of epoch 0 =20.596\n",
      "================================================================================\n",
      "                                    Epoch 1\n",
      "================================================================================\n",
      "Epoch: 1: Step: 98/9802; Global_step=9900; lr=2.060e-05; train time per batch = 0.72\n",
      "Train: global step = 9902; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9207\n",
      "    -                  end loss: 3.9171\n",
      "    -                 span loss: 7.8378\n",
      "    -              passage loss: 1.9048\n",
      "    -         history_span loss: 8.5403\n",
      "    -      history_passage loss: 1.9738\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.3720\n",
      "    -             emb_val other: 0.42783329\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 1: Step: 198/9802; Global_step=10000; lr=2.049e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 10002; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9172\n",
      "    -                  end loss: 3.9037\n",
      "    -                 span loss: 7.8209\n",
      "    -              passage loss: 1.9074\n",
      "    -         history_span loss: 8.7799\n",
      "    -      history_passage loss: 1.9592\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5818\n",
      "    -             emb_val other: 0.42826790\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Epoch: 1: Step: 298/9802; Global_step=10100; lr=2.039e-05; train time per batch = 0.73\n",
      "Train: global step = 10102; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.8953\n",
      "    -                  end loss: 3.9077\n",
      "    -                 span loss: 7.8030\n",
      "    -              passage loss: 1.9523\n",
      "    -         history_span loss: 8.8565\n",
      "    -      history_passage loss: 1.9980\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7254\n",
      "    -             emb_val other: 0.42726412\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.688.10146\n",
      "Epoch: 1: Step: 398/9802; Global_step=10200; lr=2.028e-05; train time per batch = 0.72\n",
      "Train: global step = 10202; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9176\n",
      "    -                  end loss: 3.9078\n",
      "    -                 span loss: 7.8255\n",
      "    -              passage loss: 1.8950\n",
      "    -         history_span loss: 8.5887\n",
      "    -      history_passage loss: 1.9538\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0075\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.3755\n",
      "    -             emb_val other: 0.42689186\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Epoch: 1: Step: 498/9802; Global_step=10300; lr=2.018e-05; train time per batch = 0.72\n",
      "Train: global step = 10302; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9042\n",
      "    -                  end loss: 3.9041\n",
      "    -                 span loss: 7.8084\n",
      "    -              passage loss: 1.9687\n",
      "    -         history_span loss: 8.6835\n",
      "    -      history_passage loss: 1.9985\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5742\n",
      "    -             emb_val other: 0.42828819\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 1: Step: 598/9802; Global_step=10400; lr=2.007e-05; train time per batch = 0.72\n",
      "Train: global step = 10402; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9124\n",
      "    -                  end loss: 3.9196\n",
      "    -                 span loss: 7.8321\n",
      "    -              passage loss: 1.9189\n",
      "    -         history_span loss: 8.7452\n",
      "    -      history_passage loss: 1.9671\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.5814\n",
      "    -             emb_val other: 0.42729613\n",
      "    -         eff_perturb other: 0.00000277\n",
      "\n",
      "Epoch: 1: Step: 698/9802; Global_step=10500; lr=1.997e-05; train time per batch = 0.73\n",
      "Train: global step = 10502; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9174\n",
      "    -                  end loss: 3.9153\n",
      "    -                 span loss: 7.8326\n",
      "    -              passage loss: 1.9566\n",
      "    -         history_span loss: 8.7342\n",
      "    -      history_passage loss: 2.0075\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6443\n",
      "    -             emb_val other: 0.42602360\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.1468.10536\n",
      "Epoch: 1: Step: 798/9802; Global_step=10600; lr=1.986e-05; train time per batch = 0.73\n",
      "Train: global step = 10602; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9229\n",
      "    -                  end loss: 3.8981\n",
      "    -                 span loss: 7.8210\n",
      "    -              passage loss: 1.8850\n",
      "    -         history_span loss: 8.7876\n",
      "    -      history_passage loss: 1.9329\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.5418\n",
      "    -             emb_val other: 0.42790148\n",
      "    -         eff_perturb other: 0.00000298\n",
      "\n",
      "Epoch: 1: Step: 898/9802; Global_step=10700; lr=1.976e-05; train time per batch = 0.73\n",
      "Train: global step = 10702; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9183\n",
      "    -                  end loss: 3.9019\n",
      "    -                 span loss: 7.8202\n",
      "    -              passage loss: 1.9264\n",
      "    -         history_span loss: 8.7831\n",
      "    -      history_passage loss: 1.9647\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6124\n",
      "    -             emb_val other: 0.43008903\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 1: Step: 998/9802; Global_step=10800; lr=1.965e-05; train time per batch = 0.73\n",
      "Train: global step = 10802; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9121\n",
      "    -                  end loss: 3.9116\n",
      "    -                 span loss: 7.8237\n",
      "    -              passage loss: 1.8987\n",
      "    -         history_span loss: 8.8174\n",
      "    -      history_passage loss: 1.9642\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6180\n",
      "    -             emb_val other: 0.42697251\n",
      "    -         eff_perturb other: 0.00000297\n",
      "\n",
      "Epoch: 1: Step: 1098/9802; Global_step=10900; lr=1.954e-05; train time per batch = 0.73\n",
      "Train: global step = 10902; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9060\n",
      "    -                  end loss: 3.8987\n",
      "    -                 span loss: 7.8048\n",
      "    -              passage loss: 1.9675\n",
      "    -         history_span loss: 8.7478\n",
      "    -      history_passage loss: 2.0202\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6586\n",
      "    -             emb_val other: 0.42820337\n",
      "    -         eff_perturb other: 0.00000240\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2258.10931\n",
      "Epoch: 1: Step: 1198/9802; Global_step=11000; lr=1.944e-05; train time per batch = 0.73\n",
      "Validation: Epoch: 1 Step: 1198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 11002; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9132\n",
      "    -                  end loss: 3.9269\n",
      "    -                 span loss: 7.8400\n",
      "    -              passage loss: 1.9282\n",
      "    -         history_span loss: 8.6874\n",
      "    -      history_passage loss: 1.9725\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5420\n",
      "    -             emb_val other: 0.42834610\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 1: Step: 1298/9802; Global_step=11100; lr=1.933e-05; train time per batch = 0.72\n",
      "Train: global step = 11102; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9187\n",
      "    -                  end loss: 3.9052\n",
      "    -                 span loss: 7.8239\n",
      "    -              passage loss: 1.9103\n",
      "    -         history_span loss: 8.7272\n",
      "    -      history_passage loss: 1.9358\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0089\n",
      "    -        adv_relevance loss: 0.0067\n",
      "    -                total loss: 20.5117\n",
      "    -             emb_val other: 0.42975664\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 1: Step: 1398/9802; Global_step=11200; lr=1.923e-05; train time per batch = 0.72\n",
      "Train: global step = 11202; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9086\n",
      "    -                  end loss: 3.9062\n",
      "    -                 span loss: 7.8147\n",
      "    -              passage loss: 1.9272\n",
      "    -         history_span loss: 8.7639\n",
      "    -      history_passage loss: 1.9774\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5959\n",
      "    -             emb_val other: 0.42926955\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.2962.11283\n",
      "Epoch: 1: Step: 1498/9802; Global_step=11300; lr=1.912e-05; train time per batch = 0.72\n",
      "Train: global step = 11302; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9255\n",
      "    -                  end loss: 3.9126\n",
      "    -                 span loss: 7.8381\n",
      "    -              passage loss: 1.9104\n",
      "    -         history_span loss: 8.6689\n",
      "    -      history_passage loss: 1.9399\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.4708\n",
      "    -             emb_val other: 0.43006888\n",
      "    -         eff_perturb other: 0.00000278\n",
      "\n",
      "Epoch: 1: Step: 1598/9802; Global_step=11400; lr=1.902e-05; train time per batch = 0.72\n",
      "Train: global step = 11402; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9008\n",
      "    -                 span loss: 7.8218\n",
      "    -              passage loss: 1.9471\n",
      "    -         history_span loss: 8.9336\n",
      "    -      history_passage loss: 1.9780\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.8001\n",
      "    -             emb_val other: 0.42798808\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 1: Step: 1698/9802; Global_step=11500; lr=1.891e-05; train time per batch = 0.72\n",
      "Train: global step = 11502; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9226\n",
      "    -                  end loss: 3.9123\n",
      "    -                 span loss: 7.8349\n",
      "    -              passage loss: 1.9356\n",
      "    -         history_span loss: 8.7766\n",
      "    -      history_passage loss: 1.9531\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6156\n",
      "    -             emb_val other: 0.43037605\n",
      "    -         eff_perturb other: 0.00000294\n",
      "\n",
      "Epoch: 1: Step: 1798/9802; Global_step=11600; lr=1.881e-05; train time per batch = 0.72\n",
      "Train: global step = 11602; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9001\n",
      "    -                  end loss: 3.9070\n",
      "    -                 span loss: 7.8071\n",
      "    -              passage loss: 1.9207\n",
      "    -         history_span loss: 8.8191\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6236\n",
      "    -             emb_val other: 0.42885828\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.3748.11676\n",
      "Epoch: 1: Step: 1898/9802; Global_step=11700; lr=1.870e-05; train time per batch = 0.72\n",
      "Train: global step = 11702; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9161\n",
      "    -                  end loss: 3.8957\n",
      "    -                 span loss: 7.8118\n",
      "    -              passage loss: 1.9390\n",
      "    -         history_span loss: 8.7133\n",
      "    -      history_passage loss: 1.9805\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5614\n",
      "    -             emb_val other: 0.42648700\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 1: Step: 1998/9802; Global_step=11800; lr=1.859e-05; train time per batch = 0.72\n",
      "Train: global step = 11802; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9212\n",
      "    -                  end loss: 3.8988\n",
      "    -                 span loss: 7.8200\n",
      "    -              passage loss: 1.9303\n",
      "    -         history_span loss: 8.6803\n",
      "    -      history_passage loss: 1.9764\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5180\n",
      "    -             emb_val other: 0.43065226\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 1: Step: 2098/9802; Global_step=11900; lr=1.849e-05; train time per batch = 0.72\n",
      "Train: global step = 11902; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9049\n",
      "    -                  end loss: 3.9246\n",
      "    -                 span loss: 7.8295\n",
      "    -              passage loss: 1.8626\n",
      "    -         history_span loss: 8.9446\n",
      "    -      history_passage loss: 1.9154\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6675\n",
      "    -             emb_val other: 0.43113661\n",
      "    -         eff_perturb other: 0.00000311\n",
      "\n",
      "Epoch: 1: Step: 2198/9802; Global_step=12000; lr=1.838e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 2198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 12002; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9142\n",
      "    -                  end loss: 3.9055\n",
      "    -                 span loss: 7.8197\n",
      "    -              passage loss: 1.9563\n",
      "    -         history_span loss: 8.7720\n",
      "    -      history_passage loss: 2.0008\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6644\n",
      "    -             emb_val other: 0.42858410\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.4446.12025\n",
      "Epoch: 1: Step: 2298/9802; Global_step=12100; lr=1.828e-05; train time per batch = 0.72\n",
      "Train: global step = 12102; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9116\n",
      "    -                  end loss: 3.9206\n",
      "    -                 span loss: 7.8323\n",
      "    -              passage loss: 1.9226\n",
      "    -         history_span loss: 8.7360\n",
      "    -      history_passage loss: 1.9574\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5599\n",
      "    -             emb_val other: 0.42985073\n",
      "    -         eff_perturb other: 0.00000284\n",
      "\n",
      "Epoch: 1: Step: 2398/9802; Global_step=12200; lr=1.817e-05; train time per batch = 0.71\n",
      "Train: global step = 12202; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9216\n",
      "    -                  end loss: 3.9093\n",
      "    -                 span loss: 7.8310\n",
      "    -              passage loss: 1.8841\n",
      "    -         history_span loss: 8.7414\n",
      "    -      history_passage loss: 1.9433\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5118\n",
      "    -             emb_val other: 0.42797601\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Epoch: 1: Step: 2498/9802; Global_step=12300; lr=1.807e-05; train time per batch = 0.72\n",
      "Train: global step = 12302; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9120\n",
      "    -                  end loss: 3.9018\n",
      "    -                 span loss: 7.8138\n",
      "    -              passage loss: 1.9631\n",
      "    -         history_span loss: 8.7751\n",
      "    -      history_passage loss: 2.0124\n",
      "    -            adv_start loss: 0.0075\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6827\n",
      "    -             emb_val other: 0.42738834\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 1: Step: 2598/9802; Global_step=12400; lr=1.796e-05; train time per batch = 0.72\n",
      "Train: global step = 12402; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9150\n",
      "    -                  end loss: 3.9078\n",
      "    -                 span loss: 7.8228\n",
      "    -              passage loss: 1.9591\n",
      "    -         history_span loss: 8.6995\n",
      "    -      history_passage loss: 1.9984\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5985\n",
      "    -             emb_val other: 0.42766932\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.5234.12419\n",
      "Epoch: 1: Step: 2698/9802; Global_step=12500; lr=1.785e-05; train time per batch = 0.72\n",
      "Train: global step = 12502; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9333\n",
      "    -                  end loss: 3.9193\n",
      "    -                 span loss: 7.8526\n",
      "    -              passage loss: 1.9055\n",
      "    -         history_span loss: 8.8597\n",
      "    -      history_passage loss: 1.9544\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6832\n",
      "    -             emb_val other: 0.42783827\n",
      "    -         eff_perturb other: 0.00000278\n",
      "\n",
      "Epoch: 1: Step: 2798/9802; Global_step=12600; lr=1.775e-05; train time per batch = 0.72\n",
      "Train: global step = 12602; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9124\n",
      "    -                  end loss: 3.9054\n",
      "    -                 span loss: 7.8178\n",
      "    -              passage loss: 1.9249\n",
      "    -         history_span loss: 8.8149\n",
      "    -      history_passage loss: 1.9519\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6240\n",
      "    -             emb_val other: 0.43123370\n",
      "    -         eff_perturb other: 0.00000285\n",
      "\n",
      "Epoch: 1: Step: 2898/9802; Global_step=12700; lr=1.764e-05; train time per batch = 0.72\n",
      "Train: global step = 12702; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9043\n",
      "    -                  end loss: 3.8857\n",
      "    -                 span loss: 7.7900\n",
      "    -              passage loss: 1.9234\n",
      "    -         history_span loss: 8.6710\n",
      "    -      history_passage loss: 1.9720\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.4718\n",
      "    -             emb_val other: 0.42900032\n",
      "    -         eff_perturb other: 0.00000280\n",
      "\n",
      "Epoch: 1: Step: 2998/9802; Global_step=12800; lr=1.754e-05; train time per batch = 0.72\n",
      "Train: global step = 12802; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9106\n",
      "    -                  end loss: 3.9011\n",
      "    -                 span loss: 7.8117\n",
      "    -              passage loss: 1.9578\n",
      "    -         history_span loss: 8.7905\n",
      "    -      history_passage loss: 2.0104\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6847\n",
      "    -             emb_val other: 0.42870569\n",
      "    -         eff_perturb other: 0.00000249\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6010.12807\n",
      "Epoch: 1: Step: 3098/9802; Global_step=12900; lr=1.743e-05; train time per batch = 0.72\n",
      "Train: global step = 12902; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9185\n",
      "    -                  end loss: 3.9102\n",
      "    -                 span loss: 7.8287\n",
      "    -              passage loss: 1.9153\n",
      "    -         history_span loss: 8.6724\n",
      "    -      history_passage loss: 1.9740\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0089\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5099\n",
      "    -             emb_val other: 0.42780834\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 1: Step: 3198/9802; Global_step=13000; lr=1.733e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 3198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 13002; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9220\n",
      "    -                  end loss: 3.9093\n",
      "    -                 span loss: 7.8313\n",
      "    -              passage loss: 1.9198\n",
      "    -         history_span loss: 8.8341\n",
      "    -      history_passage loss: 1.9608\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6604\n",
      "    -             emb_val other: 0.42887810\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Epoch: 1: Step: 3298/9802; Global_step=13100; lr=1.722e-05; train time per batch = 0.72\n",
      "Train: global step = 13102; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9114\n",
      "    -                  end loss: 3.8928\n",
      "    -                 span loss: 7.8041\n",
      "    -              passage loss: 1.8876\n",
      "    -         history_span loss: 8.9417\n",
      "    -      history_passage loss: 1.9433\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.6880\n",
      "    -             emb_val other: 0.42765543\n",
      "    -         eff_perturb other: 0.00000306\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.6710.13157\n",
      "Epoch: 1: Step: 3398/9802; Global_step=13200; lr=1.712e-05; train time per batch = 0.71\n",
      "Train: global step = 13202; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9139\n",
      "    -                  end loss: 3.9092\n",
      "    -                 span loss: 7.8230\n",
      "    -              passage loss: 1.9060\n",
      "    -         history_span loss: 8.7789\n",
      "    -      history_passage loss: 1.9583\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.5828\n",
      "    -             emb_val other: 0.42822868\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Epoch: 1: Step: 3498/9802; Global_step=13300; lr=1.701e-05; train time per batch = 0.72\n",
      "Train: global step = 13302; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9261\n",
      "    -                  end loss: 3.9058\n",
      "    -                 span loss: 7.8318\n",
      "    -              passage loss: 1.9371\n",
      "    -         history_span loss: 8.7886\n",
      "    -      history_passage loss: 1.9720\n",
      "    -            adv_start loss: 0.0075\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6472\n",
      "    -             emb_val other: 0.42946714\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Epoch: 1: Step: 3598/9802; Global_step=13400; lr=1.690e-05; train time per batch = 0.72\n",
      "Train: global step = 13402; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9266\n",
      "    -                  end loss: 3.9111\n",
      "    -                 span loss: 7.8377\n",
      "    -              passage loss: 1.9273\n",
      "    -         history_span loss: 8.8363\n",
      "    -      history_passage loss: 1.9786\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6905\n",
      "    -             emb_val other: 0.43068686\n",
      "    -         eff_perturb other: 0.00000252\n",
      "\n",
      "Epoch: 1: Step: 3698/9802; Global_step=13500; lr=1.680e-05; train time per batch = 0.72\n",
      "Train: global step = 13502; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9031\n",
      "    -                  end loss: 3.9094\n",
      "    -                 span loss: 7.8125\n",
      "    -              passage loss: 1.9342\n",
      "    -         history_span loss: 8.9263\n",
      "    -      history_passage loss: 1.9753\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.7599\n",
      "    -             emb_val other: 0.42941013\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.7494.13549\n",
      "Epoch: 1: Step: 3798/9802; Global_step=13600; lr=1.669e-05; train time per batch = 0.72\n",
      "Train: global step = 13602; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9393\n",
      "    -                  end loss: 3.8873\n",
      "    -                 span loss: 7.8266\n",
      "    -              passage loss: 1.9201\n",
      "    -         history_span loss: 8.6740\n",
      "    -      history_passage loss: 1.9707\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5070\n",
      "    -             emb_val other: 0.42813659\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Epoch: 1: Step: 3898/9802; Global_step=13700; lr=1.659e-05; train time per batch = 0.71\n",
      "Train: global step = 13702; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9157\n",
      "    -                  end loss: 3.9013\n",
      "    -                 span loss: 7.8170\n",
      "    -              passage loss: 1.9006\n",
      "    -         history_span loss: 8.7046\n",
      "    -      history_passage loss: 1.9548\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4890\n",
      "    -             emb_val other: 0.42955703\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 1: Step: 3998/9802; Global_step=13800; lr=1.648e-05; train time per batch = 0.71\n",
      "Train: global step = 13802; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9158\n",
      "    -                  end loss: 3.9136\n",
      "    -                 span loss: 7.8294\n",
      "    -              passage loss: 1.9195\n",
      "    -         history_span loss: 8.7577\n",
      "    -      history_passage loss: 1.9428\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5593\n",
      "    -             emb_val other: 0.42939544\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Epoch: 1: Step: 4098/9802; Global_step=13900; lr=1.638e-05; train time per batch = 0.71\n",
      "Train: global step = 13902; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9156\n",
      "    -                  end loss: 3.9047\n",
      "    -                 span loss: 7.8202\n",
      "    -              passage loss: 1.9176\n",
      "    -         history_span loss: 8.8443\n",
      "    -      history_passage loss: 1.9575\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.6550\n",
      "    -             emb_val other: 0.43035185\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8296.13950\n",
      "Epoch: 1: Step: 4198/9802; Global_step=14000; lr=1.627e-05; train time per batch = 0.71\n",
      "Validation: Epoch: 1 Step: 4198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 14002; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9229\n",
      "    -                  end loss: 3.9115\n",
      "    -                 span loss: 7.8344\n",
      "    -              passage loss: 1.9051\n",
      "    -         history_span loss: 8.6322\n",
      "    -      history_passage loss: 1.9563\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.4377\n",
      "    -             emb_val other: 0.42725509\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 1: Step: 4298/9802; Global_step=14100; lr=1.616e-05; train time per batch = 0.71\n",
      "Train: global step = 14102; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9145\n",
      "    -                 span loss: 7.8355\n",
      "    -              passage loss: 1.9392\n",
      "    -         history_span loss: 8.5510\n",
      "    -      history_passage loss: 1.9768\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.4204\n",
      "    -             emb_val other: 0.42717981\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Epoch: 1: Step: 4398/9802; Global_step=14200; lr=1.606e-05; train time per batch = 0.71\n",
      "Train: global step = 14202; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9117\n",
      "    -                  end loss: 3.9051\n",
      "    -                 span loss: 7.8167\n",
      "    -              passage loss: 1.8767\n",
      "    -         history_span loss: 8.7478\n",
      "    -      history_passage loss: 1.9379\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.4935\n",
      "    -             emb_val other: 0.42997184\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.8988.14296\n",
      "Epoch: 1: Step: 4498/9802; Global_step=14300; lr=1.595e-05; train time per batch = 0.71\n",
      "Train: global step = 14302; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9084\n",
      "    -                  end loss: 3.9101\n",
      "    -                 span loss: 7.8185\n",
      "    -              passage loss: 1.9058\n",
      "    -         history_span loss: 8.8483\n",
      "    -      history_passage loss: 1.9626\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.6451\n",
      "    -             emb_val other: 0.42813498\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Epoch: 1: Step: 4598/9802; Global_step=14400; lr=1.585e-05; train time per batch = 0.71\n",
      "Train: global step = 14402; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9200\n",
      "    -                  end loss: 3.9146\n",
      "    -                 span loss: 7.8346\n",
      "    -              passage loss: 1.9611\n",
      "    -         history_span loss: 8.7364\n",
      "    -      history_passage loss: 1.9976\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6464\n",
      "    -             emb_val other: 0.42892948\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Epoch: 1: Step: 4698/9802; Global_step=14500; lr=1.574e-05; train time per batch = 0.71\n",
      "Train: global step = 14502; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9169\n",
      "    -                  end loss: 3.9138\n",
      "    -                 span loss: 7.8307\n",
      "    -              passage loss: 1.9431\n",
      "    -         history_span loss: 8.8020\n",
      "    -      history_passage loss: 1.9755\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6645\n",
      "    -             emb_val other: 0.42726469\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Epoch: 1: Step: 4798/9802; Global_step=14600; lr=1.564e-05; train time per batch = 0.71\n",
      "Train: global step = 14602; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9118\n",
      "    -                  end loss: 3.9152\n",
      "    -                 span loss: 7.8270\n",
      "    -              passage loss: 1.9347\n",
      "    -         history_span loss: 8.7825\n",
      "    -      history_passage loss: 1.9686\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6270\n",
      "    -             emb_val other: 0.42844054\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.9776.14690\n",
      "Epoch: 1: Step: 4898/9802; Global_step=14700; lr=1.553e-05; train time per batch = 0.71\n",
      "Train: global step = 14702; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9176\n",
      "    -                  end loss: 3.9084\n",
      "    -                 span loss: 7.8260\n",
      "    -              passage loss: 1.8996\n",
      "    -         history_span loss: 8.8184\n",
      "    -      history_passage loss: 1.9557\n",
      "    -            adv_start loss: 0.0063\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6095\n",
      "    -             emb_val other: 0.42626277\n",
      "    -         eff_perturb other: 0.00000293\n",
      "\n",
      "Epoch: 1: Step: 4998/9802; Global_step=14800; lr=1.543e-05; train time per batch = 0.71\n",
      "Train: global step = 14802; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9228\n",
      "    -                  end loss: 3.9064\n",
      "    -                 span loss: 7.8292\n",
      "    -              passage loss: 1.9358\n",
      "    -         history_span loss: 8.8197\n",
      "    -      history_passage loss: 1.9677\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0069\n",
      "    -                total loss: 20.6604\n",
      "    -             emb_val other: 0.42953521\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 1: Step: 5098/9802; Global_step=14900; lr=1.532e-05; train time per batch = 0.71\n",
      "Train: global step = 14902; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9183\n",
      "    -                  end loss: 3.9085\n",
      "    -                 span loss: 7.8268\n",
      "    -              passage loss: 1.9000\n",
      "    -         history_span loss: 9.0034\n",
      "    -      history_passage loss: 1.9471\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0077\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7889\n",
      "    -             emb_val other: 0.42872027\n",
      "    -         eff_perturb other: 0.00000290\n",
      "\n",
      "Epoch: 1: Step: 5198/9802; Global_step=15000; lr=1.521e-05; train time per batch = 0.71\n",
      "Validation: Epoch: 1 Step: 5198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 15002; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9190\n",
      "    -                  end loss: 3.9152\n",
      "    -                 span loss: 7.8342\n",
      "    -              passage loss: 1.9465\n",
      "    -         history_span loss: 8.6933\n",
      "    -      history_passage loss: 1.9827\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5728\n",
      "    -             emb_val other: 0.42689735\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.10462.15033\n",
      "Epoch: 1: Step: 5298/9802; Global_step=15100; lr=1.511e-05; train time per batch = 0.71\n",
      "Train: global step = 15102; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9097\n",
      "    -                  end loss: 3.9232\n",
      "    -                 span loss: 7.8329\n",
      "    -              passage loss: 1.9515\n",
      "    -         history_span loss: 8.7562\n",
      "    -      history_passage loss: 1.9866\n",
      "    -            adv_start loss: 0.0064\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6383\n",
      "    -             emb_val other: 0.42619830\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 1: Step: 5398/9802; Global_step=15200; lr=1.500e-05; train time per batch = 0.71\n",
      "Train: global step = 15202; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9109\n",
      "    -                  end loss: 3.9160\n",
      "    -                 span loss: 7.8269\n",
      "    -              passage loss: 1.8733\n",
      "    -         history_span loss: 8.6838\n",
      "    -      history_passage loss: 1.9335\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.4335\n",
      "    -             emb_val other: 0.42853114\n",
      "    -         eff_perturb other: 0.00000304\n",
      "\n",
      "Epoch: 1: Step: 5498/9802; Global_step=15300; lr=1.490e-05; train time per batch = 0.71\n",
      "Train: global step = 15302; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9136\n",
      "    -                  end loss: 3.8995\n",
      "    -                 span loss: 7.8132\n",
      "    -              passage loss: 1.9190\n",
      "    -         history_span loss: 8.7100\n",
      "    -      history_passage loss: 1.9574\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5134\n",
      "    -             emb_val other: 0.42842746\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Epoch: 1: Step: 5598/9802; Global_step=15400; lr=1.479e-05; train time per batch = 0.71\n",
      "Train: global step = 15402; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9231\n",
      "    -                  end loss: 3.9103\n",
      "    -                 span loss: 7.8334\n",
      "    -              passage loss: 1.9235\n",
      "    -         history_span loss: 8.8640\n",
      "    -      history_passage loss: 1.9851\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7214\n",
      "    -             emb_val other: 0.42808300\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Epoch: 1: Step: 5698/9802; Global_step=15500; lr=1.469e-05; train time per batch = 0.71\n",
      "Train: global step = 15502; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9224\n",
      "    -                  end loss: 3.9216\n",
      "    -                 span loss: 7.8440\n",
      "    -              passage loss: 1.9471\n",
      "    -         history_span loss: 8.6717\n",
      "    -      history_passage loss: 2.0010\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.5783\n",
      "    -             emb_val other: 0.42761162\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 1: Step: 5798/9802; Global_step=15600; lr=1.458e-05; train time per batch = 0.72\n",
      "Train: global step = 15602; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9118\n",
      "    -                  end loss: 3.9075\n",
      "    -                 span loss: 7.8192\n",
      "    -              passage loss: 1.9630\n",
      "    -         history_span loss: 8.8286\n",
      "    -      history_passage loss: 2.0060\n",
      "    -            adv_start loss: 0.0075\n",
      "    -              adv_end loss: 0.0089\n",
      "    -        adv_relevance loss: 0.0068\n",
      "    -                total loss: 20.7332\n",
      "    -             emb_val other: 0.43067309\n",
      "    -         eff_perturb other: 0.00000241\n",
      "\n",
      "Epoch: 1: Step: 5898/9802; Global_step=15700; lr=1.448e-05; train time per batch = 0.72\n",
      "Train: global step = 15702; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9263\n",
      "    -                  end loss: 3.9012\n",
      "    -                 span loss: 7.8275\n",
      "    -              passage loss: 1.9452\n",
      "    -         history_span loss: 8.7361\n",
      "    -      history_passage loss: 1.9829\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.6026\n",
      "    -             emb_val other: 0.42787308\n",
      "    -         eff_perturb other: 0.00000247\n",
      "\n",
      "Epoch: 1: Step: 5998/9802; Global_step=15800; lr=1.437e-05; train time per batch = 0.72\n",
      "Train: global step = 15802; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.9045\n",
      "    -                 span loss: 7.8233\n",
      "    -              passage loss: 1.9359\n",
      "    -         history_span loss: 9.0576\n",
      "    -      history_passage loss: 1.9679\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.8968\n",
      "    -             emb_val other: 0.42800269\n",
      "    -         eff_perturb other: 0.00000280\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12040.15822\n",
      "Epoch: 1: Step: 6098/9802; Global_step=15900; lr=1.426e-05; train time per batch = 0.72\n",
      "Train: global step = 15902; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9195\n",
      "    -                  end loss: 3.9061\n",
      "    -                 span loss: 7.8256\n",
      "    -              passage loss: 1.9761\n",
      "    -         history_span loss: 8.9495\n",
      "    -      history_passage loss: 2.0010\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.8694\n",
      "    -             emb_val other: 0.42900375\n",
      "    -         eff_perturb other: 0.00000254\n",
      "\n",
      "Epoch: 1: Step: 6198/9802; Global_step=16000; lr=1.416e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 6198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 16002; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9236\n",
      "    -                  end loss: 3.9178\n",
      "    -                 span loss: 7.8414\n",
      "    -              passage loss: 1.9594\n",
      "    -         history_span loss: 8.7703\n",
      "    -      history_passage loss: 2.0135\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7000\n",
      "    -             emb_val other: 0.42925072\n",
      "    -         eff_perturb other: 0.00000248\n",
      "\n",
      "Epoch: 1: Step: 6298/9802; Global_step=16100; lr=1.405e-05; train time per batch = 0.72\n",
      "Train: global step = 16102; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9126\n",
      "    -                  end loss: 3.9017\n",
      "    -                 span loss: 7.8142\n",
      "    -              passage loss: 1.9128\n",
      "    -         history_span loss: 8.8620\n",
      "    -      history_passage loss: 1.9593\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.6624\n",
      "    -             emb_val other: 0.42835099\n",
      "    -         eff_perturb other: 0.00000302\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.12738.16171\n",
      "Epoch: 1: Step: 6398/9802; Global_step=16200; lr=1.395e-05; train time per batch = 0.72\n",
      "Train: global step = 16202; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9254\n",
      "    -                  end loss: 3.9037\n",
      "    -                 span loss: 7.8291\n",
      "    -              passage loss: 1.9320\n",
      "    -         history_span loss: 8.6325\n",
      "    -      history_passage loss: 1.9958\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5057\n",
      "    -             emb_val other: 0.42721075\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 1: Step: 6498/9802; Global_step=16300; lr=1.384e-05; train time per batch = 0.72\n",
      "Train: global step = 16302; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9172\n",
      "    -                  end loss: 3.9067\n",
      "    -                 span loss: 7.8239\n",
      "    -              passage loss: 1.9036\n",
      "    -         history_span loss: 8.7984\n",
      "    -      history_passage loss: 1.9668\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6061\n",
      "    -             emb_val other: 0.42782187\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 1: Step: 6598/9802; Global_step=16400; lr=1.374e-05; train time per batch = 0.72\n",
      "Train: global step = 16402; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9214\n",
      "    -                  end loss: 3.9194\n",
      "    -                 span loss: 7.8408\n",
      "    -              passage loss: 1.9371\n",
      "    -         history_span loss: 8.7830\n",
      "    -      history_passage loss: 1.9670\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6451\n",
      "    -             emb_val other: 0.42909622\n",
      "    -         eff_perturb other: 0.00000266\n",
      "\n",
      "Epoch: 1: Step: 6698/9802; Global_step=16500; lr=1.363e-05; train time per batch = 0.72\n",
      "Train: global step = 16502; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9179\n",
      "    -                  end loss: 3.9133\n",
      "    -                 span loss: 7.8312\n",
      "    -              passage loss: 1.9179\n",
      "    -         history_span loss: 8.8903\n",
      "    -      history_passage loss: 1.9590\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.7118\n",
      "    -             emb_val other: 0.42896545\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.13526.16565\n",
      "Epoch: 1: Step: 6798/9802; Global_step=16600; lr=1.352e-05; train time per batch = 0.72\n",
      "Train: global step = 16602; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9041\n",
      "    -                  end loss: 3.9129\n",
      "    -                 span loss: 7.8170\n",
      "    -              passage loss: 1.9228\n",
      "    -         history_span loss: 8.8548\n",
      "    -      history_passage loss: 1.9858\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6914\n",
      "    -             emb_val other: 0.42741829\n",
      "    -         eff_perturb other: 0.00000281\n",
      "\n",
      "Epoch: 1: Step: 6898/9802; Global_step=16700; lr=1.342e-05; train time per batch = 0.72\n",
      "Train: global step = 16702; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9081\n",
      "    -                  end loss: 3.9045\n",
      "    -                 span loss: 7.8126\n",
      "    -              passage loss: 1.9362\n",
      "    -         history_span loss: 8.7196\n",
      "    -      history_passage loss: 1.9807\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5610\n",
      "    -             emb_val other: 0.42740089\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 1: Step: 6998/9802; Global_step=16800; lr=1.331e-05; train time per batch = 0.72\n",
      "Train: global step = 16802; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9118\n",
      "    -                  end loss: 3.8979\n",
      "    -                 span loss: 7.8097\n",
      "    -              passage loss: 1.9530\n",
      "    -         history_span loss: 8.8620\n",
      "    -      history_passage loss: 1.9844\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7195\n",
      "    -             emb_val other: 0.42910919\n",
      "    -         eff_perturb other: 0.00000254\n",
      "\n",
      "Epoch: 1: Step: 7098/9802; Global_step=16900; lr=1.321e-05; train time per batch = 0.72\n",
      "Train: global step = 16902; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9214\n",
      "    -                  end loss: 3.8908\n",
      "    -                 span loss: 7.8122\n",
      "    -              passage loss: 1.9176\n",
      "    -         history_span loss: 8.7607\n",
      "    -      history_passage loss: 1.9625\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5627\n",
      "    -             emb_val other: 0.42843220\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14262.16933\n",
      "Epoch: 1: Step: 7198/9802; Global_step=17000; lr=1.310e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 7198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.10\n",
      "Eval step 200 / 993; eval time per batch = 0.11\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 17002; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.8977\n",
      "    -                 span loss: 7.8187\n",
      "    -              passage loss: 1.9270\n",
      "    -         history_span loss: 8.8216\n",
      "    -      history_passage loss: 1.9880\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6692\n",
      "    -             emb_val other: 0.42676315\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 1: Step: 7298/9802; Global_step=17100; lr=1.300e-05; train time per batch = 0.72\n",
      "Train: global step = 17102; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9060\n",
      "    -                  end loss: 3.9089\n",
      "    -                 span loss: 7.8150\n",
      "    -              passage loss: 1.9421\n",
      "    -         history_span loss: 8.6069\n",
      "    -      history_passage loss: 1.9879\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0069\n",
      "    -                total loss: 20.4637\n",
      "    -             emb_val other: 0.42641988\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Epoch: 1: Step: 7398/9802; Global_step=17200; lr=1.289e-05; train time per batch = 0.72\n",
      "Train: global step = 17202; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9084\n",
      "    -                  end loss: 3.8871\n",
      "    -                 span loss: 7.7956\n",
      "    -              passage loss: 1.9049\n",
      "    -         history_span loss: 8.7209\n",
      "    -      history_passage loss: 1.9456\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0076\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.4759\n",
      "    -             emb_val other: 0.42870387\n",
      "    -         eff_perturb other: 0.00000287\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.14908.17256\n",
      "Epoch: 1: Step: 7498/9802; Global_step=17300; lr=1.279e-05; train time per batch = 0.72\n",
      "Train: global step = 17302; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9173\n",
      "    -                  end loss: 3.9056\n",
      "    -                 span loss: 7.8229\n",
      "    -              passage loss: 1.8964\n",
      "    -         history_span loss: 8.8413\n",
      "    -      history_passage loss: 1.9627\n",
      "    -            adv_start loss: 0.0062\n",
      "    -              adv_end loss: 0.0076\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6300\n",
      "    -             emb_val other: 0.42660144\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Epoch: 1: Step: 7598/9802; Global_step=17400; lr=1.268e-05; train time per batch = 0.72\n",
      "Train: global step = 17402; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9219\n",
      "    -                  end loss: 3.9024\n",
      "    -                 span loss: 7.8243\n",
      "    -              passage loss: 1.9503\n",
      "    -         history_span loss: 8.7213\n",
      "    -      history_passage loss: 2.0177\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6273\n",
      "    -             emb_val other: 0.42644227\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 1: Step: 7698/9802; Global_step=17500; lr=1.257e-05; train time per batch = 0.72\n",
      "Train: global step = 17502; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.9000\n",
      "    -                 span loss: 7.8187\n",
      "    -              passage loss: 1.9352\n",
      "    -         history_span loss: 8.8499\n",
      "    -      history_passage loss: 1.9732\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6919\n",
      "    -             emb_val other: 0.42959517\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 1: Step: 7798/9802; Global_step=17600; lr=1.247e-05; train time per batch = 0.72\n",
      "Train: global step = 17602; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9021\n",
      "    -                  end loss: 3.9002\n",
      "    -                 span loss: 7.8024\n",
      "    -              passage loss: 1.9173\n",
      "    -         history_span loss: 8.7005\n",
      "    -      history_passage loss: 1.9715\n",
      "    -            adv_start loss: 0.0064\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5026\n",
      "    -             emb_val other: 0.42988929\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.15628.17616\n",
      "Epoch: 1: Step: 7898/9802; Global_step=17700; lr=1.236e-05; train time per batch = 0.72\n",
      "Train: global step = 17702; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9219\n",
      "    -                  end loss: 3.9040\n",
      "    -                 span loss: 7.8259\n",
      "    -              passage loss: 1.9275\n",
      "    -         history_span loss: 8.7992\n",
      "    -      history_passage loss: 1.9762\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6448\n",
      "    -             emb_val other: 0.42890146\n",
      "    -         eff_perturb other: 0.00000249\n",
      "\n",
      "Epoch: 1: Step: 7998/9802; Global_step=17800; lr=1.226e-05; train time per batch = 0.72\n",
      "Train: global step = 17802; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9230\n",
      "    -                  end loss: 3.8942\n",
      "    -                 span loss: 7.8172\n",
      "    -              passage loss: 1.9138\n",
      "    -         history_span loss: 8.5799\n",
      "    -      history_passage loss: 1.9742\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.4005\n",
      "    -             emb_val other: 0.42875671\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Epoch: 1: Step: 8098/9802; Global_step=17900; lr=1.215e-05; train time per batch = 0.72\n",
      "Train: global step = 17902; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9183\n",
      "    -                  end loss: 3.9140\n",
      "    -                 span loss: 7.8323\n",
      "    -              passage loss: 1.9630\n",
      "    -         history_span loss: 8.8249\n",
      "    -      history_passage loss: 1.9901\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.7229\n",
      "    -             emb_val other: 0.42745507\n",
      "    -         eff_perturb other: 0.00000242\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.16360.17982\n",
      "Epoch: 1: Step: 8198/9802; Global_step=18000; lr=1.205e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 8198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 18002; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9190\n",
      "    -                  end loss: 3.9150\n",
      "    -                 span loss: 7.8340\n",
      "    -              passage loss: 1.9159\n",
      "    -         history_span loss: 8.6722\n",
      "    -      history_passage loss: 1.9594\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.4968\n",
      "    -             emb_val other: 0.42757639\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Epoch: 1: Step: 8298/9802; Global_step=18100; lr=1.194e-05; train time per batch = 0.72\n",
      "Train: global step = 18102; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9140\n",
      "    -                  end loss: 3.9110\n",
      "    -                 span loss: 7.8251\n",
      "    -              passage loss: 1.9596\n",
      "    -         history_span loss: 8.7144\n",
      "    -      history_passage loss: 1.9926\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6078\n",
      "    -             emb_val other: 0.42784399\n",
      "    -         eff_perturb other: 0.00000266\n",
      "\n",
      "Epoch: 1: Step: 8398/9802; Global_step=18200; lr=1.183e-05; train time per batch = 0.72\n",
      "Train: global step = 18202; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9021\n",
      "    -                  end loss: 3.8942\n",
      "    -                 span loss: 7.7963\n",
      "    -              passage loss: 1.8876\n",
      "    -         history_span loss: 8.6188\n",
      "    -      history_passage loss: 1.9512\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.3652\n",
      "    -             emb_val other: 0.42866701\n",
      "    -         eff_perturb other: 0.00000300\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.16994.18299\n",
      "Epoch: 1: Step: 8498/9802; Global_step=18300; lr=1.173e-05; train time per batch = 0.72\n",
      "Train: global step = 18302; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9260\n",
      "    -                  end loss: 3.9144\n",
      "    -                 span loss: 7.8404\n",
      "    -              passage loss: 1.9188\n",
      "    -         history_span loss: 8.6869\n",
      "    -      history_passage loss: 1.9811\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5469\n",
      "    -             emb_val other: 0.42900959\n",
      "    -         eff_perturb other: 0.00000266\n",
      "\n",
      "Epoch: 1: Step: 8598/9802; Global_step=18400; lr=1.162e-05; train time per batch = 0.72\n",
      "Train: global step = 18402; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9223\n",
      "    -                  end loss: 3.8967\n",
      "    -                 span loss: 7.8190\n",
      "    -              passage loss: 1.9258\n",
      "    -         history_span loss: 8.6123\n",
      "    -      history_passage loss: 1.9849\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.4560\n",
      "    -             emb_val other: 0.42689365\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 1: Step: 8698/9802; Global_step=18500; lr=1.152e-05; train time per batch = 0.72\n",
      "Train: global step = 18502; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9173\n",
      "    -                  end loss: 3.9163\n",
      "    -                 span loss: 7.8336\n",
      "    -              passage loss: 1.9323\n",
      "    -         history_span loss: 8.6494\n",
      "    -      history_passage loss: 1.9873\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5208\n",
      "    -             emb_val other: 0.42945126\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 1: Step: 8798/9802; Global_step=18600; lr=1.141e-05; train time per batch = 0.72\n",
      "Train: global step = 18602; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9108\n",
      "    -                  end loss: 3.9082\n",
      "    -                 span loss: 7.8190\n",
      "    -              passage loss: 1.9326\n",
      "    -         history_span loss: 8.7318\n",
      "    -      history_passage loss: 1.9654\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0075\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.5602\n",
      "    -             emb_val other: 0.42827314\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.17718.18661\n",
      "Epoch: 1: Step: 8898/9802; Global_step=18700; lr=1.131e-05; train time per batch = 0.72\n",
      "Train: global step = 18702; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9092\n",
      "    -                  end loss: 3.9029\n",
      "    -                 span loss: 7.8121\n",
      "    -              passage loss: 1.9160\n",
      "    -         history_span loss: 8.8390\n",
      "    -      history_passage loss: 1.9732\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.6571\n",
      "    -             emb_val other: 0.42581454\n",
      "    -         eff_perturb other: 0.00000281\n",
      "\n",
      "Epoch: 1: Step: 8998/9802; Global_step=18800; lr=1.120e-05; train time per batch = 0.72\n",
      "Train: global step = 18802; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9148\n",
      "    -                 span loss: 7.8358\n",
      "    -              passage loss: 1.9510\n",
      "    -         history_span loss: 8.7088\n",
      "    -      history_passage loss: 2.0046\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.6181\n",
      "    -             emb_val other: 0.42693660\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 1: Step: 9098/9802; Global_step=18900; lr=1.110e-05; train time per batch = 0.72\n",
      "Train: global step = 18902; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9192\n",
      "    -                  end loss: 3.9131\n",
      "    -                 span loss: 7.8324\n",
      "    -              passage loss: 1.9192\n",
      "    -         history_span loss: 8.7312\n",
      "    -      history_passage loss: 1.9655\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5611\n",
      "    -             emb_val other: 0.42816770\n",
      "    -         eff_perturb other: 0.00000298\n",
      "\n",
      "Epoch: 1: Step: 9198/9802; Global_step=19000; lr=1.099e-05; train time per batch = 0.72\n",
      "Validation: Epoch: 1 Step: 9198/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.18398.19001\n",
      "Train: global step = 19002; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9203\n",
      "    -                  end loss: 3.9008\n",
      "    -                 span loss: 7.8211\n",
      "    -              passage loss: 1.9780\n",
      "    -         history_span loss: 8.8530\n",
      "    -      history_passage loss: 2.0161\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0091\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.7870\n",
      "    -             emb_val other: 0.42947975\n",
      "    -         eff_perturb other: 0.00000236\n",
      "\n",
      "Epoch: 1: Step: 9298/9802; Global_step=19100; lr=1.088e-05; train time per batch = 0.72\n",
      "Train: global step = 19102; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9013\n",
      "    -                  end loss: 3.9145\n",
      "    -                 span loss: 7.8159\n",
      "    -              passage loss: 1.9495\n",
      "    -         history_span loss: 8.7562\n",
      "    -      history_passage loss: 1.9940\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6330\n",
      "    -             emb_val other: 0.42672688\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 1: Step: 9398/9802; Global_step=19200; lr=1.078e-05; train time per batch = 0.72\n",
      "Train: global step = 19202; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9068\n",
      "    -                  end loss: 3.8931\n",
      "    -                 span loss: 7.8000\n",
      "    -              passage loss: 1.9249\n",
      "    -         history_span loss: 8.8282\n",
      "    -      history_passage loss: 1.9755\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6414\n",
      "    -             emb_val other: 0.42714548\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 1: Step: 9498/9802; Global_step=19300; lr=1.067e-05; train time per batch = 0.72\n",
      "Train: global step = 19302; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9152\n",
      "    -                  end loss: 3.9125\n",
      "    -                 span loss: 7.8277\n",
      "    -              passage loss: 1.9130\n",
      "    -         history_span loss: 8.7672\n",
      "    -      history_passage loss: 1.9682\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5933\n",
      "    -             emb_val other: 0.42830405\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.1.19106.19355\n",
      "Epoch: 1: Step: 9598/9802; Global_step=19400; lr=1.057e-05; train time per batch = 0.72\n",
      "Train: global step = 19402; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9236\n",
      "    -                  end loss: 3.9013\n",
      "    -                 span loss: 7.8249\n",
      "    -              passage loss: 1.9441\n",
      "    -         history_span loss: 8.5420\n",
      "    -      history_passage loss: 1.9874\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.4165\n",
      "    -             emb_val other: 0.42812279\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Epoch: 1: Step: 9698/9802; Global_step=19500; lr=1.046e-05; train time per batch = 0.72\n",
      "Train: global step = 19502; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9243\n",
      "    -                  end loss: 3.9040\n",
      "    -                 span loss: 7.8283\n",
      "    -              passage loss: 1.9657\n",
      "    -         history_span loss: 8.7685\n",
      "    -      history_passage loss: 2.0186\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0084\n",
      "    -                total loss: 20.7027\n",
      "    -             emb_val other: 0.42664921\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 1: Step: 9798/9802; Global_step=19600; lr=1.036e-05; train time per batch = 0.72\n",
      "Train: global step = 19602; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9200\n",
      "    -                  end loss: 3.9013\n",
      "    -                 span loss: 7.8213\n",
      "    -              passage loss: 1.9253\n",
      "    -         history_span loss: 8.7836\n",
      "    -      history_passage loss: 1.9777\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6258\n",
      "    -             emb_val other: 0.42811128\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Avg. total Loss of epoch 1 =20.602\n",
      "================================================================================\n",
      "                                    Epoch 2\n",
      "================================================================================\n",
      "Epoch: 2: Step: 96/9802; Global_step=19700; lr=1.025e-05; train time per batch = 0.76\n",
      "Train: global step = 19704; step = 100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9128\n",
      "    -                  end loss: 3.9147\n",
      "    -                 span loss: 7.8275\n",
      "    -              passage loss: 1.9297\n",
      "    -         history_span loss: 8.8460\n",
      "    -      history_passage loss: 1.9773\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6964\n",
      "    -             emb_val other: 0.42886207\n",
      "    -         eff_perturb other: 0.00000244\n",
      "\n",
      "Epoch: 2: Step: 196/9802; Global_step=19800; lr=1.015e-05; train time per batch = 0.76\n",
      "Train: global step = 19804; step = 200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9095\n",
      "    -                  end loss: 3.8881\n",
      "    -                 span loss: 7.7976\n",
      "    -              passage loss: 1.9149\n",
      "    -         history_span loss: 8.7097\n",
      "    -      history_passage loss: 1.9635\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5015\n",
      "    -             emb_val other: 0.42842323\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Epoch: 2: Step: 296/9802; Global_step=19900; lr=1.004e-05; train time per batch = 0.76\n",
      "Train: global step = 19904; step = 300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9116\n",
      "    -                  end loss: 3.9020\n",
      "    -                 span loss: 7.8137\n",
      "    -              passage loss: 1.9351\n",
      "    -         history_span loss: 8.6256\n",
      "    -      history_passage loss: 1.9790\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.4667\n",
      "    -             emb_val other: 0.42848864\n",
      "    -         eff_perturb other: 0.00000285\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.710.19959\n",
      "Epoch: 2: Step: 396/9802; Global_step=20000; lr=9.934e-06; train time per batch = 0.75\n",
      "Validation: Epoch: 2 Step: 396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 20004; step = 400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9228\n",
      "    -                  end loss: 3.9032\n",
      "    -                 span loss: 7.8260\n",
      "    -              passage loss: 1.9110\n",
      "    -         history_span loss: 8.6550\n",
      "    -      history_passage loss: 1.9590\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4625\n",
      "    -             emb_val other: 0.42751062\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 2: Step: 496/9802; Global_step=20100; lr=9.828e-06; train time per batch = 0.76\n",
      "Train: global step = 20104; step = 500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9184\n",
      "    -                  end loss: 3.9066\n",
      "    -                 span loss: 7.8250\n",
      "    -              passage loss: 1.9404\n",
      "    -         history_span loss: 8.7236\n",
      "    -      history_passage loss: 1.9715\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5750\n",
      "    -             emb_val other: 0.42918822\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 2: Step: 596/9802; Global_step=20200; lr=9.723e-06; train time per batch = 0.76\n",
      "Train: global step = 20204; step = 600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9173\n",
      "    -                  end loss: 3.9094\n",
      "    -                 span loss: 7.8267\n",
      "    -              passage loss: 1.9108\n",
      "    -         history_span loss: 8.8078\n",
      "    -      history_passage loss: 1.9598\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6194\n",
      "    -             emb_val other: 0.42650843\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.1336.20272\n",
      "Epoch: 2: Step: 696/9802; Global_step=20300; lr=9.617e-06; train time per batch = 0.76\n",
      "Train: global step = 20304; step = 700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9159\n",
      "    -                  end loss: 3.8954\n",
      "    -                 span loss: 7.8113\n",
      "    -              passage loss: 1.9221\n",
      "    -         history_span loss: 8.7728\n",
      "    -      history_passage loss: 1.9798\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6017\n",
      "    -             emb_val other: 0.42697844\n",
      "    -         eff_perturb other: 0.00000291\n",
      "\n",
      "Epoch: 2: Step: 796/9802; Global_step=20400; lr=9.511e-06; train time per batch = 0.76\n",
      "Train: global step = 20404; step = 800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9088\n",
      "    -                  end loss: 3.8969\n",
      "    -                 span loss: 7.8057\n",
      "    -              passage loss: 1.9540\n",
      "    -         history_span loss: 8.7776\n",
      "    -      history_passage loss: 2.0006\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6523\n",
      "    -             emb_val other: 0.42868194\n",
      "    -         eff_perturb other: 0.00000252\n",
      "\n",
      "Epoch: 2: Step: 896/9802; Global_step=20500; lr=9.406e-06; train time per batch = 0.76\n",
      "Train: global step = 20504; step = 900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9141\n",
      "    -                  end loss: 3.8966\n",
      "    -                 span loss: 7.8107\n",
      "    -              passage loss: 1.9469\n",
      "    -         history_span loss: 8.5610\n",
      "    -      history_passage loss: 2.0095\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.4407\n",
      "    -             emb_val other: 0.42533785\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 2: Step: 996/9802; Global_step=20600; lr=9.300e-06; train time per batch = 0.76\n",
      "Train: global step = 20604; step = 1000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9159\n",
      "    -                  end loss: 3.9054\n",
      "    -                 span loss: 7.8213\n",
      "    -              passage loss: 1.9197\n",
      "    -         history_span loss: 8.7288\n",
      "    -      history_passage loss: 1.9774\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5625\n",
      "    -             emb_val other: 0.42816859\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2060.20634\n",
      "Epoch: 2: Step: 1096/9802; Global_step=20700; lr=9.195e-06; train time per batch = 0.76\n",
      "Train: global step = 20704; step = 1100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9055\n",
      "    -                  end loss: 3.9212\n",
      "    -                 span loss: 7.8267\n",
      "    -              passage loss: 1.9751\n",
      "    -         history_span loss: 8.8487\n",
      "    -      history_passage loss: 2.0146\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7816\n",
      "    -             emb_val other: 0.42960107\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 2: Step: 1196/9802; Global_step=20800; lr=9.089e-06; train time per batch = 0.75\n",
      "Train: global step = 20804; step = 1200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9159\n",
      "    -                  end loss: 3.9096\n",
      "    -                 span loss: 7.8255\n",
      "    -              passage loss: 1.9133\n",
      "    -         history_span loss: 8.9027\n",
      "    -      history_passage loss: 1.9588\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0074\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7089\n",
      "    -             emb_val other: 0.42755157\n",
      "    -         eff_perturb other: 0.00000284\n",
      "\n",
      "Epoch: 2: Step: 1296/9802; Global_step=20900; lr=8.983e-06; train time per batch = 0.75\n",
      "Train: global step = 20904; step = 1300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9253\n",
      "    -                  end loss: 3.9026\n",
      "    -                 span loss: 7.8278\n",
      "    -              passage loss: 1.9259\n",
      "    -         history_span loss: 8.6648\n",
      "    -      history_passage loss: 1.9745\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.5093\n",
      "    -             emb_val other: 0.42859820\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.2784.20996\n",
      "Epoch: 2: Step: 1396/9802; Global_step=21000; lr=8.878e-06; train time per batch = 0.75\n",
      "Validation: Epoch: 2 Step: 1396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 21004; step = 1400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.8985\n",
      "    -                  end loss: 3.8958\n",
      "    -                 span loss: 7.7943\n",
      "    -              passage loss: 1.9065\n",
      "    -         history_span loss: 8.9023\n",
      "    -      history_passage loss: 1.9562\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6776\n",
      "    -             emb_val other: 0.42859149\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Epoch: 2: Step: 1496/9802; Global_step=21100; lr=8.772e-06; train time per batch = 0.76\n",
      "Train: global step = 21104; step = 1500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9069\n",
      "    -                  end loss: 3.8990\n",
      "    -                 span loss: 7.8059\n",
      "    -              passage loss: 1.9480\n",
      "    -         history_span loss: 8.6345\n",
      "    -      history_passage loss: 1.9951\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.4945\n",
      "    -             emb_val other: 0.42871398\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 2: Step: 1596/9802; Global_step=21200; lr=8.666e-06; train time per batch = 0.77\n",
      "Train: global step = 21204; step = 1600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9147\n",
      "    -                  end loss: 3.9068\n",
      "    -                 span loss: 7.8215\n",
      "    -              passage loss: 1.9606\n",
      "    -         history_span loss: 8.6309\n",
      "    -      history_passage loss: 2.0012\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5302\n",
      "    -             emb_val other: 0.42796957\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.3284.21246\n",
      "Epoch: 2: Step: 1696/9802; Global_step=21300; lr=8.561e-06; train time per batch = 0.77\n",
      "Train: global step = 21304; step = 1700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9117\n",
      "    -                  end loss: 3.9075\n",
      "    -                 span loss: 7.8193\n",
      "    -              passage loss: 1.9362\n",
      "    -         history_span loss: 8.8830\n",
      "    -      history_passage loss: 1.9918\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0089\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.7500\n",
      "    -             emb_val other: 0.42895910\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 2: Step: 1796/9802; Global_step=21400; lr=8.455e-06; train time per batch = 0.77\n",
      "Train: global step = 21404; step = 1800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9135\n",
      "    -                  end loss: 3.9062\n",
      "    -                 span loss: 7.8197\n",
      "    -              passage loss: 1.9130\n",
      "    -         history_span loss: 8.6401\n",
      "    -      history_passage loss: 1.9646\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.4553\n",
      "    -             emb_val other: 0.42797476\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 2: Step: 1896/9802; Global_step=21500; lr=8.350e-06; train time per batch = 0.77\n",
      "Train: global step = 21504; step = 1900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9287\n",
      "    -                  end loss: 3.9148\n",
      "    -                 span loss: 7.8436\n",
      "    -              passage loss: 1.9191\n",
      "    -         history_span loss: 8.5880\n",
      "    -      history_passage loss: 1.9688\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.4340\n",
      "    -             emb_val other: 0.42864445\n",
      "    -         eff_perturb other: 0.00000279\n",
      "\n",
      "Epoch: 2: Step: 1996/9802; Global_step=21600; lr=8.244e-06; train time per batch = 0.76\n",
      "Train: global step = 21604; step = 2000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9166\n",
      "    -                  end loss: 3.9127\n",
      "    -                 span loss: 7.8294\n",
      "    -              passage loss: 1.9555\n",
      "    -         history_span loss: 8.5896\n",
      "    -      history_passage loss: 1.9872\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.4741\n",
      "    -             emb_val other: 0.42991126\n",
      "    -         eff_perturb other: 0.00000270\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.4074.21641\n",
      "Epoch: 2: Step: 2096/9802; Global_step=21700; lr=8.138e-06; train time per batch = 0.76\n",
      "Train: global step = 21704; step = 2100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9322\n",
      "    -                  end loss: 3.8966\n",
      "    -                 span loss: 7.8288\n",
      "    -              passage loss: 1.9749\n",
      "    -         history_span loss: 8.6642\n",
      "    -      history_passage loss: 2.0076\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.5891\n",
      "    -             emb_val other: 0.42878670\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Epoch: 2: Step: 2196/9802; Global_step=21800; lr=8.033e-06; train time per batch = 0.76\n",
      "Train: global step = 21804; step = 2200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9203\n",
      "    -                  end loss: 3.9007\n",
      "    -                 span loss: 7.8210\n",
      "    -              passage loss: 1.8986\n",
      "    -         history_span loss: 8.6192\n",
      "    -      history_passage loss: 1.9439\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.3934\n",
      "    -             emb_val other: 0.42689028\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Epoch: 2: Step: 2296/9802; Global_step=21900; lr=7.927e-06; train time per batch = 0.76\n",
      "Train: global step = 21904; step = 2300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9212\n",
      "    -                  end loss: 3.9033\n",
      "    -                 span loss: 7.8245\n",
      "    -              passage loss: 1.9315\n",
      "    -         history_span loss: 8.9857\n",
      "    -      history_passage loss: 1.9632\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0069\n",
      "    -                total loss: 20.8181\n",
      "    -             emb_val other: 0.42854640\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 2: Step: 2396/9802; Global_step=22000; lr=7.822e-06; train time per batch = 0.75\n",
      "Validation: Epoch: 2 Step: 2396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.4794.22001\n",
      "Train: global step = 22004; step = 2400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9176\n",
      "    -                  end loss: 3.8860\n",
      "    -                 span loss: 7.8036\n",
      "    -              passage loss: 1.9406\n",
      "    -         history_span loss: 8.6899\n",
      "    -      history_passage loss: 1.9747\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5229\n",
      "    -             emb_val other: 0.42898306\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Epoch: 2: Step: 2496/9802; Global_step=22100; lr=7.716e-06; train time per batch = 0.75\n",
      "Train: global step = 22104; step = 2500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9187\n",
      "    -                  end loss: 3.9167\n",
      "    -                 span loss: 7.8354\n",
      "    -              passage loss: 1.9434\n",
      "    -         history_span loss: 8.5909\n",
      "    -      history_passage loss: 1.9852\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.4716\n",
      "    -             emb_val other: 0.42627028\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 2: Step: 2596/9802; Global_step=22200; lr=7.610e-06; train time per batch = 0.75\n",
      "Train: global step = 22204; step = 2600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9175\n",
      "    -                  end loss: 3.9071\n",
      "    -                 span loss: 7.8246\n",
      "    -              passage loss: 1.9198\n",
      "    -         history_span loss: 8.7559\n",
      "    -      history_passage loss: 1.9694\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5825\n",
      "    -             emb_val other: 0.42786521\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Epoch: 2: Step: 2696/9802; Global_step=22300; lr=7.505e-06; train time per batch = 0.75\n",
      "Train: global step = 22304; step = 2700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9232\n",
      "    -                  end loss: 3.9001\n",
      "    -                 span loss: 7.8233\n",
      "    -              passage loss: 1.9007\n",
      "    -         history_span loss: 8.9205\n",
      "    -      history_passage loss: 1.9700\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.7262\n",
      "    -             emb_val other: 0.42712379\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.5576.22392\n",
      "Epoch: 2: Step: 2796/9802; Global_step=22400; lr=7.399e-06; train time per batch = 0.75\n",
      "Train: global step = 22404; step = 2800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9190\n",
      "    -                  end loss: 3.9037\n",
      "    -                 span loss: 7.8226\n",
      "    -              passage loss: 1.9155\n",
      "    -         history_span loss: 8.8781\n",
      "    -      history_passage loss: 1.9815\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.7095\n",
      "    -             emb_val other: 0.42793354\n",
      "    -         eff_perturb other: 0.00000287\n",
      "\n",
      "Epoch: 2: Step: 2896/9802; Global_step=22500; lr=7.294e-06; train time per batch = 0.75\n",
      "Train: global step = 22504; step = 2900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9193\n",
      "    -                  end loss: 3.9219\n",
      "    -                 span loss: 7.8412\n",
      "    -              passage loss: 1.9666\n",
      "    -         history_span loss: 8.5895\n",
      "    -      history_passage loss: 2.0145\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0090\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.5302\n",
      "    -             emb_val other: 0.42722142\n",
      "    -         eff_perturb other: 0.00000249\n",
      "\n",
      "Epoch: 2: Step: 2996/9802; Global_step=22600; lr=7.188e-06; train time per batch = 0.75\n",
      "Train: global step = 22604; step = 3000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9047\n",
      "    -                  end loss: 3.9123\n",
      "    -                 span loss: 7.8170\n",
      "    -              passage loss: 1.9194\n",
      "    -         history_span loss: 8.7078\n",
      "    -      history_passage loss: 1.9580\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.5149\n",
      "    -             emb_val other: 0.43014637\n",
      "    -         eff_perturb other: 0.00000276\n",
      "\n",
      "Epoch: 2: Step: 3096/9802; Global_step=22700; lr=7.082e-06; train time per batch = 0.75\n",
      "Train: global step = 22704; step = 3100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9186\n",
      "    -                  end loss: 3.9110\n",
      "    -                 span loss: 7.8296\n",
      "    -              passage loss: 1.9133\n",
      "    -         history_span loss: 8.6400\n",
      "    -      history_passage loss: 1.9577\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.4491\n",
      "    -             emb_val other: 0.42834160\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.6348.22778\n",
      "Epoch: 2: Step: 3196/9802; Global_step=22800; lr=6.977e-06; train time per batch = 0.75\n",
      "Train: global step = 22804; step = 3200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9132\n",
      "    -                  end loss: 3.9116\n",
      "    -                 span loss: 7.8248\n",
      "    -              passage loss: 1.9284\n",
      "    -         history_span loss: 8.5265\n",
      "    -      history_passage loss: 1.9857\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.3781\n",
      "    -             emb_val other: 0.42858517\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 2: Step: 3296/9802; Global_step=22900; lr=6.871e-06; train time per batch = 0.75\n",
      "Train: global step = 22904; step = 3300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9065\n",
      "    -                  end loss: 3.8929\n",
      "    -                 span loss: 7.7994\n",
      "    -              passage loss: 1.9331\n",
      "    -         history_span loss: 8.7002\n",
      "    -      history_passage loss: 1.9855\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5300\n",
      "    -             emb_val other: 0.42783928\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 2: Step: 3396/9802; Global_step=23000; lr=6.765e-06; train time per batch = 0.75\n",
      "Validation: Epoch: 2 Step: 3396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 23004; step = 3400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9317\n",
      "    -                  end loss: 3.9012\n",
      "    -                 span loss: 7.8329\n",
      "    -              passage loss: 1.9050\n",
      "    -         history_span loss: 8.6858\n",
      "    -      history_passage loss: 1.9666\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5072\n",
      "    -             emb_val other: 0.42707652\n",
      "    -         eff_perturb other: 0.00000289\n",
      "\n",
      "Epoch: 2: Step: 3496/9802; Global_step=23100; lr=6.660e-06; train time per batch = 0.75\n",
      "Train: global step = 23104; step = 3500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9086\n",
      "    -                  end loss: 3.9057\n",
      "    -                 span loss: 7.8143\n",
      "    -              passage loss: 1.9480\n",
      "    -         history_span loss: 8.7502\n",
      "    -      history_passage loss: 1.9819\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6077\n",
      "    -             emb_val other: 0.42899567\n",
      "    -         eff_perturb other: 0.00000245\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7034.23121\n",
      "Epoch: 2: Step: 3596/9802; Global_step=23200; lr=6.554e-06; train time per batch = 0.75\n",
      "Train: global step = 23204; step = 3600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9340\n",
      "    -                  end loss: 3.9082\n",
      "    -                 span loss: 7.8422\n",
      "    -              passage loss: 1.9160\n",
      "    -         history_span loss: 8.7195\n",
      "    -      history_passage loss: 1.9722\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5644\n",
      "    -             emb_val other: 0.42795181\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 2: Step: 3696/9802; Global_step=23300; lr=6.449e-06; train time per batch = 0.74\n",
      "Train: global step = 23304; step = 3700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9027\n",
      "    -                  end loss: 3.9007\n",
      "    -                 span loss: 7.8035\n",
      "    -              passage loss: 1.8905\n",
      "    -         history_span loss: 8.8950\n",
      "    -      history_passage loss: 1.9279\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.6267\n",
      "    -             emb_val other: 0.42878813\n",
      "    -         eff_perturb other: 0.00000289\n",
      "\n",
      "Epoch: 2: Step: 3796/9802; Global_step=23400; lr=6.343e-06; train time per batch = 0.75\n",
      "Train: global step = 23404; step = 3800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9002\n",
      "    -                  end loss: 3.9030\n",
      "    -                 span loss: 7.8032\n",
      "    -              passage loss: 1.9411\n",
      "    -         history_span loss: 8.8273\n",
      "    -      history_passage loss: 1.9726\n",
      "    -            adv_start loss: 0.0075\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6621\n",
      "    -             emb_val other: 0.42792436\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Epoch: 2: Step: 3896/9802; Global_step=23500; lr=6.237e-06; train time per batch = 0.74\n",
      "Train: global step = 23504; step = 3900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9306\n",
      "    -                  end loss: 3.9157\n",
      "    -                 span loss: 7.8463\n",
      "    -              passage loss: 1.9370\n",
      "    -         history_span loss: 8.7574\n",
      "    -      history_passage loss: 1.9727\n",
      "    -            adv_start loss: 0.0075\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6327\n",
      "    -             emb_val other: 0.42927039\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.7822.23515\n",
      "Epoch: 2: Step: 3996/9802; Global_step=23600; lr=6.132e-06; train time per batch = 0.74\n",
      "Train: global step = 23604; step = 4000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9252\n",
      "    -                  end loss: 3.9047\n",
      "    -                 span loss: 7.8299\n",
      "    -              passage loss: 1.9276\n",
      "    -         history_span loss: 8.9103\n",
      "    -      history_passage loss: 1.9918\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.7744\n",
      "    -             emb_val other: 0.42776129\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Epoch: 2: Step: 4096/9802; Global_step=23700; lr=6.026e-06; train time per batch = 0.74\n",
      "Train: global step = 23704; step = 4100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9048\n",
      "    -                  end loss: 3.9014\n",
      "    -                 span loss: 7.8062\n",
      "    -              passage loss: 1.9470\n",
      "    -         history_span loss: 8.7008\n",
      "    -      history_passage loss: 1.9996\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5685\n",
      "    -             emb_val other: 0.42667532\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 2: Step: 4196/9802; Global_step=23800; lr=5.921e-06; train time per batch = 0.74\n",
      "Train: global step = 23804; step = 4200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.8974\n",
      "    -                  end loss: 3.8975\n",
      "    -                 span loss: 7.7948\n",
      "    -              passage loss: 1.9091\n",
      "    -         history_span loss: 8.8617\n",
      "    -      history_passage loss: 1.9594\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6381\n",
      "    -             emb_val other: 0.42945281\n",
      "    -         eff_perturb other: 0.00000280\n",
      "\n",
      "Epoch: 2: Step: 4296/9802; Global_step=23900; lr=5.815e-06; train time per batch = 0.74\n",
      "Train: global step = 23904; step = 4300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9119\n",
      "    -                  end loss: 3.9341\n",
      "    -                 span loss: 7.8460\n",
      "    -              passage loss: 1.9189\n",
      "    -         history_span loss: 8.6685\n",
      "    -      history_passage loss: 1.9638\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.5091\n",
      "    -             emb_val other: 0.42915753\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.8610.23909\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 24004; step = 4400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9215\n",
      "    -                  end loss: 3.9183\n",
      "    -                 span loss: 7.8398\n",
      "    -              passage loss: 1.9368\n",
      "    -         history_span loss: 8.6696\n",
      "    -      history_passage loss: 1.9929\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5535\n",
      "    -             emb_val other: 0.42696372\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 2: Step: 4496/9802; Global_step=24100; lr=5.604e-06; train time per batch = 0.74\n",
      "Train: global step = 24104; step = 4500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9102\n",
      "    -                  end loss: 3.8979\n",
      "    -                 span loss: 7.8080\n",
      "    -              passage loss: 1.9379\n",
      "    -         history_span loss: 8.8368\n",
      "    -      history_passage loss: 1.9965\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6962\n",
      "    -             emb_val other: 0.42878181\n",
      "    -         eff_perturb other: 0.00000247\n",
      "\n",
      "Epoch: 2: Step: 4596/9802; Global_step=24200; lr=5.498e-06; train time per batch = 0.74\n",
      "Train: global step = 24204; step = 4600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9120\n",
      "    -                  end loss: 3.9004\n",
      "    -                 span loss: 7.8124\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 8.8067\n",
      "    -      history_passage loss: 1.9915\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.6683\n",
      "    -             emb_val other: 0.42739403\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.9296.24252\n",
      "Epoch: 2: Step: 4696/9802; Global_step=24300; lr=5.393e-06; train time per batch = 0.74\n",
      "Train: global step = 24304; step = 4700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9155\n",
      "    -                  end loss: 3.9249\n",
      "    -                 span loss: 7.8404\n",
      "    -              passage loss: 1.9299\n",
      "    -         history_span loss: 8.7454\n",
      "    -      history_passage loss: 1.9812\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6129\n",
      "    -             emb_val other: 0.43081421\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 2: Step: 4796/9802; Global_step=24400; lr=5.287e-06; train time per batch = 0.74\n",
      "Train: global step = 24404; step = 4800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9103\n",
      "    -                  end loss: 3.9238\n",
      "    -                 span loss: 7.8341\n",
      "    -              passage loss: 1.8766\n",
      "    -         history_span loss: 8.7422\n",
      "    -      history_passage loss: 1.9246\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.4902\n",
      "    -             emb_val other: 0.42825252\n",
      "    -         eff_perturb other: 0.00000307\n",
      "\n",
      "Epoch: 2: Step: 4896/9802; Global_step=24500; lr=5.181e-06; train time per batch = 0.74\n",
      "Train: global step = 24504; step = 4900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9156\n",
      "    -                  end loss: 3.9079\n",
      "    -                 span loss: 7.8235\n",
      "    -              passage loss: 1.9208\n",
      "    -         history_span loss: 8.6308\n",
      "    -      history_passage loss: 1.9989\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0082\n",
      "    -                total loss: 20.4874\n",
      "    -             emb_val other: 0.42673007\n",
      "    -         eff_perturb other: 0.00000289\n",
      "\n",
      "Epoch: 2: Step: 4996/9802; Global_step=24600; lr=5.076e-06; train time per batch = 0.74\n",
      "Train: global step = 24604; step = 5000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9176\n",
      "    -                  end loss: 3.9062\n",
      "    -                 span loss: 7.8239\n",
      "    -              passage loss: 1.9343\n",
      "    -         history_span loss: 8.9444\n",
      "    -      history_passage loss: 1.9615\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.7779\n",
      "    -             emb_val other: 0.42877471\n",
      "    -         eff_perturb other: 0.00000275\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.10084.24646\n",
      "Epoch: 2: Step: 5096/9802; Global_step=24700; lr=4.970e-06; train time per batch = 0.74\n",
      "Train: global step = 24704; step = 5100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9215\n",
      "    -                  end loss: 3.9055\n",
      "    -                 span loss: 7.8270\n",
      "    -              passage loss: 1.8945\n",
      "    -         history_span loss: 8.7265\n",
      "    -      history_passage loss: 1.9515\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5156\n",
      "    -             emb_val other: 0.42857492\n",
      "    -         eff_perturb other: 0.00000282\n",
      "\n",
      "Epoch: 2: Step: 5196/9802; Global_step=24800; lr=4.864e-06; train time per batch = 0.74\n",
      "Train: global step = 24804; step = 5200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9161\n",
      "    -                  end loss: 3.8751\n",
      "    -                 span loss: 7.7913\n",
      "    -              passage loss: 1.9194\n",
      "    -         history_span loss: 8.9953\n",
      "    -      history_passage loss: 1.9763\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.7992\n",
      "    -             emb_val other: 0.42857349\n",
      "    -         eff_perturb other: 0.00000261\n",
      "\n",
      "Epoch: 2: Step: 5296/9802; Global_step=24900; lr=4.759e-06; train time per batch = 0.74\n",
      "Train: global step = 24904; step = 5300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9136\n",
      "    -                  end loss: 3.8971\n",
      "    -                 span loss: 7.8107\n",
      "    -              passage loss: 1.9415\n",
      "    -         history_span loss: 8.8785\n",
      "    -      history_passage loss: 2.0007\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.7441\n",
      "    -             emb_val other: 0.42705157\n",
      "    -         eff_perturb other: 0.00000263\n",
      "\n",
      "Epoch: 2: Step: 5396/9802; Global_step=25000; lr=4.653e-06; train time per batch = 0.74\n",
      "Validation: Epoch: 2 Step: 5396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.10794.25001\n",
      "Train: global step = 25004; step = 5400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9263\n",
      "    -                  end loss: 3.9263\n",
      "    -                 span loss: 7.8525\n",
      "    -              passage loss: 1.8944\n",
      "    -         history_span loss: 8.7483\n",
      "    -      history_passage loss: 1.9635\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.5735\n",
      "    -             emb_val other: 0.42585921\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 2: Step: 5496/9802; Global_step=25100; lr=4.548e-06; train time per batch = 0.74\n",
      "Train: global step = 25104; step = 5500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9221\n",
      "    -                  end loss: 3.9105\n",
      "    -                 span loss: 7.8326\n",
      "    -              passage loss: 1.9288\n",
      "    -         history_span loss: 8.9294\n",
      "    -      history_passage loss: 1.9805\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.7816\n",
      "    -             emb_val other: 0.42713669\n",
      "    -         eff_perturb other: 0.00000260\n",
      "\n",
      "Epoch: 2: Step: 5596/9802; Global_step=25200; lr=4.442e-06; train time per batch = 0.74\n",
      "Train: global step = 25204; step = 5600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9092\n",
      "    -                  end loss: 3.9017\n",
      "    -                 span loss: 7.8109\n",
      "    -              passage loss: 1.9420\n",
      "    -         history_span loss: 8.8042\n",
      "    -      history_passage loss: 2.0004\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.6754\n",
      "    -             emb_val other: 0.42893350\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 2: Step: 5696/9802; Global_step=25300; lr=4.336e-06; train time per batch = 0.74\n",
      "Train: global step = 25304; step = 5700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9164\n",
      "    -                  end loss: 3.9022\n",
      "    -                 span loss: 7.8186\n",
      "    -              passage loss: 1.9156\n",
      "    -         history_span loss: 8.7626\n",
      "    -      history_passage loss: 1.9441\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5562\n",
      "    -             emb_val other: 0.42793399\n",
      "    -         eff_perturb other: 0.00000298\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.11576.25392\n",
      "Epoch: 2: Step: 5796/9802; Global_step=25400; lr=4.231e-06; train time per batch = 0.74\n",
      "Train: global step = 25404; step = 5800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9286\n",
      "    -                  end loss: 3.9012\n",
      "    -                 span loss: 7.8298\n",
      "    -              passage loss: 1.9318\n",
      "    -         history_span loss: 8.7408\n",
      "    -      history_passage loss: 1.9842\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.6018\n",
      "    -             emb_val other: 0.42959327\n",
      "    -         eff_perturb other: 0.00000271\n",
      "\n",
      "Epoch: 2: Step: 5896/9802; Global_step=25500; lr=4.125e-06; train time per batch = 0.74\n",
      "Train: global step = 25504; step = 5900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9034\n",
      "    -                  end loss: 3.9069\n",
      "    -                 span loss: 7.8103\n",
      "    -              passage loss: 1.9651\n",
      "    -         history_span loss: 8.8279\n",
      "    -      history_passage loss: 1.9962\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7178\n",
      "    -             emb_val other: 0.42795038\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Epoch: 2: Step: 5996/9802; Global_step=25600; lr=4.020e-06; train time per batch = 0.74\n",
      "Train: global step = 25604; step = 6000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9178\n",
      "    -                  end loss: 3.9023\n",
      "    -                 span loss: 7.8200\n",
      "    -              passage loss: 1.8938\n",
      "    -         history_span loss: 8.9154\n",
      "    -      history_passage loss: 1.9507\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6946\n",
      "    -             emb_val other: 0.42788717\n",
      "    -         eff_perturb other: 0.00000275\n",
      "\n",
      "Epoch: 2: Step: 6096/9802; Global_step=25700; lr=3.914e-06; train time per batch = 0.74\n",
      "Train: global step = 25704; step = 6100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9079\n",
      "    -                  end loss: 3.9091\n",
      "    -                 span loss: 7.8170\n",
      "    -              passage loss: 1.9536\n",
      "    -         history_span loss: 8.8557\n",
      "    -      history_passage loss: 2.0022\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7434\n",
      "    -             emb_val other: 0.42842641\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.12354.25781\n",
      "Epoch: 2: Step: 6196/9802; Global_step=25800; lr=3.808e-06; train time per batch = 0.74\n",
      "Train: global step = 25804; step = 6200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9161\n",
      "    -                  end loss: 3.9177\n",
      "    -                 span loss: 7.8339\n",
      "    -              passage loss: 1.9101\n",
      "    -         history_span loss: 8.8286\n",
      "    -      history_passage loss: 1.9709\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0070\n",
      "    -                total loss: 20.6566\n",
      "    -             emb_val other: 0.43025741\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Epoch: 2: Step: 6296/9802; Global_step=25900; lr=3.703e-06; train time per batch = 0.74\n",
      "Train: global step = 25904; step = 6300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9065\n",
      "    -                  end loss: 3.9060\n",
      "    -                 span loss: 7.8125\n",
      "    -              passage loss: 1.9480\n",
      "    -         history_span loss: 8.6582\n",
      "    -      history_passage loss: 2.0000\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0087\n",
      "    -        adv_relevance loss: 0.0067\n",
      "    -                total loss: 20.5321\n",
      "    -             emb_val other: 0.42813414\n",
      "    -         eff_perturb other: 0.00000274\n",
      "\n",
      "Epoch: 2: Step: 6396/9802; Global_step=26000; lr=3.597e-06; train time per batch = 0.74\n",
      "Validation: Epoch: 2 Step: 6396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 26004; step = 6400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9143\n",
      "    -                  end loss: 3.8969\n",
      "    -                 span loss: 7.8112\n",
      "    -              passage loss: 1.9223\n",
      "    -         history_span loss: 8.7325\n",
      "    -      history_passage loss: 1.9637\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.5497\n",
      "    -             emb_val other: 0.42966124\n",
      "    -         eff_perturb other: 0.00000277\n",
      "\n",
      "Epoch: 2: Step: 6496/9802; Global_step=26100; lr=3.492e-06; train time per batch = 0.74\n",
      "Train: global step = 26104; step = 6500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9210\n",
      "    -                  end loss: 3.9049\n",
      "    -                 span loss: 7.8259\n",
      "    -              passage loss: 1.9068\n",
      "    -         history_span loss: 8.8112\n",
      "    -      history_passage loss: 1.9516\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.6045\n",
      "    -             emb_val other: 0.42623603\n",
      "    -         eff_perturb other: 0.00000292\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.13040.26124\n",
      "Epoch: 2: Step: 6596/9802; Global_step=26200; lr=3.386e-06; train time per batch = 0.74\n",
      "Train: global step = 26204; step = 6600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9159\n",
      "    -                  end loss: 3.9143\n",
      "    -                 span loss: 7.8302\n",
      "    -              passage loss: 1.9011\n",
      "    -         history_span loss: 8.7738\n",
      "    -      history_passage loss: 1.9635\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.5809\n",
      "    -             emb_val other: 0.42685705\n",
      "    -         eff_perturb other: 0.00000285\n",
      "\n",
      "Epoch: 2: Step: 6696/9802; Global_step=26300; lr=3.280e-06; train time per batch = 0.74\n",
      "Train: global step = 26304; step = 6700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9226\n",
      "    -                  end loss: 3.9148\n",
      "    -                 span loss: 7.8374\n",
      "    -              passage loss: 1.9405\n",
      "    -         history_span loss: 8.8099\n",
      "    -      history_passage loss: 1.9619\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.6676\n",
      "    -             emb_val other: 0.42784917\n",
      "    -         eff_perturb other: 0.00000269\n",
      "\n",
      "Epoch: 2: Step: 6796/9802; Global_step=26400; lr=3.175e-06; train time per batch = 0.74\n",
      "Train: global step = 26404; step = 6800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9171\n",
      "    -                  end loss: 3.9102\n",
      "    -                 span loss: 7.8273\n",
      "    -              passage loss: 1.9565\n",
      "    -         history_span loss: 8.7907\n",
      "    -      history_passage loss: 1.9991\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6905\n",
      "    -             emb_val other: 0.42859566\n",
      "    -         eff_perturb other: 0.00000256\n",
      "\n",
      "Epoch: 2: Step: 6896/9802; Global_step=26500; lr=3.069e-06; train time per batch = 0.74\n",
      "Train: global step = 26504; step = 6900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9125\n",
      "    -                  end loss: 3.9005\n",
      "    -                 span loss: 7.8130\n",
      "    -              passage loss: 1.9395\n",
      "    -         history_span loss: 8.6189\n",
      "    -      history_passage loss: 1.9810\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4691\n",
      "    -             emb_val other: 0.42957470\n",
      "    -         eff_perturb other: 0.00000258\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.13810.26509\n",
      "Epoch: 2: Step: 6996/9802; Global_step=26600; lr=2.963e-06; train time per batch = 0.74\n",
      "Train: global step = 26604; step = 7000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9206\n",
      "    -                  end loss: 3.9024\n",
      "    -                 span loss: 7.8230\n",
      "    -              passage loss: 1.9440\n",
      "    -         history_span loss: 8.8297\n",
      "    -      history_passage loss: 1.9936\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7088\n",
      "    -             emb_val other: 0.42774150\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Epoch: 2: Step: 7096/9802; Global_step=26700; lr=2.858e-06; train time per batch = 0.73\n",
      "Train: global step = 26704; step = 7100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9095\n",
      "    -                  end loss: 3.9094\n",
      "    -                 span loss: 7.8189\n",
      "    -              passage loss: 1.9045\n",
      "    -         history_span loss: 8.5127\n",
      "    -      history_passage loss: 1.9535\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0074\n",
      "    -                total loss: 20.3041\n",
      "    -             emb_val other: 0.42904785\n",
      "    -         eff_perturb other: 0.00000285\n",
      "\n",
      "Epoch: 2: Step: 7196/9802; Global_step=26800; lr=2.752e-06; train time per batch = 0.73\n",
      "Train: global step = 26804; step = 7200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9247\n",
      "    -                  end loss: 3.9202\n",
      "    -                 span loss: 7.8450\n",
      "    -              passage loss: 1.9597\n",
      "    -         history_span loss: 8.8659\n",
      "    -      history_passage loss: 2.0001\n",
      "    -            adv_start loss: 0.0068\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.7864\n",
      "    -             emb_val other: 0.42954749\n",
      "    -         eff_perturb other: 0.00000245\n",
      "\n",
      "Epoch: 2: Step: 7296/9802; Global_step=26900; lr=2.647e-06; train time per batch = 0.73\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.14594.26901\n",
      "Train: global step = 26904; step = 7300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9252\n",
      "    -                  end loss: 3.8981\n",
      "    -                 span loss: 7.8233\n",
      "    -              passage loss: 1.9238\n",
      "    -         history_span loss: 8.8804\n",
      "    -      history_passage loss: 1.9711\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0088\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.7163\n",
      "    -             emb_val other: 0.42900455\n",
      "    -         eff_perturb other: 0.00000262\n",
      "\n",
      "Epoch: 2: Step: 7396/9802; Global_step=27000; lr=2.541e-06; train time per batch = 0.73\n",
      "Validation: Epoch: 2 Step: 7396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.10\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 27004; step = 7400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9104\n",
      "    -                  end loss: 3.9048\n",
      "    -                 span loss: 7.8152\n",
      "    -              passage loss: 1.8584\n",
      "    -         history_span loss: 8.6977\n",
      "    -      history_passage loss: 1.9081\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0080\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.3873\n",
      "    -             emb_val other: 0.42848957\n",
      "    -         eff_perturb other: 0.00000292\n",
      "\n",
      "Epoch: 2: Step: 7496/9802; Global_step=27100; lr=2.435e-06; train time per batch = 0.73\n",
      "Train: global step = 27104; step = 7500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9227\n",
      "    -                  end loss: 3.9145\n",
      "    -                 span loss: 7.8372\n",
      "    -              passage loss: 1.9500\n",
      "    -         history_span loss: 8.7302\n",
      "    -      history_passage loss: 2.0100\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0067\n",
      "    -                total loss: 20.6354\n",
      "    -             emb_val other: 0.42724997\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Epoch: 2: Step: 7596/9802; Global_step=27200; lr=2.330e-06; train time per batch = 0.73\n",
      "Train: global step = 27204; step = 7600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9208\n",
      "    -                  end loss: 3.9088\n",
      "    -                 span loss: 7.8296\n",
      "    -              passage loss: 1.9073\n",
      "    -         history_span loss: 8.7214\n",
      "    -      history_passage loss: 1.9625\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5344\n",
      "    -             emb_val other: 0.42999780\n",
      "    -         eff_perturb other: 0.00000255\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.15300.27254\n",
      "Epoch: 2: Step: 7696/9802; Global_step=27300; lr=2.224e-06; train time per batch = 0.73\n",
      "Train: global step = 27304; step = 7700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.8996\n",
      "    -                  end loss: 3.9023\n",
      "    -                 span loss: 7.8019\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 8.6713\n",
      "    -      history_passage loss: 1.9963\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.5312\n",
      "    -             emb_val other: 0.42833143\n",
      "    -         eff_perturb other: 0.00000248\n",
      "\n",
      "Epoch: 2: Step: 7796/9802; Global_step=27400; lr=2.119e-06; train time per batch = 0.73\n",
      "Train: global step = 27404; step = 7800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9188\n",
      "    -                  end loss: 3.9104\n",
      "    -                 span loss: 7.8292\n",
      "    -              passage loss: 1.8953\n",
      "    -         history_span loss: 9.1242\n",
      "    -      history_passage loss: 1.9316\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.8987\n",
      "    -             emb_val other: 0.42934167\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 2: Step: 7896/9802; Global_step=27500; lr=2.013e-06; train time per batch = 0.73\n",
      "Train: global step = 27504; step = 7900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9142\n",
      "    -                  end loss: 3.9060\n",
      "    -                 span loss: 7.8201\n",
      "    -              passage loss: 1.9052\n",
      "    -         history_span loss: 8.8204\n",
      "    -      history_passage loss: 1.9585\n",
      "    -            adv_start loss: 0.0065\n",
      "    -              adv_end loss: 0.0076\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6141\n",
      "    -             emb_val other: 0.42570937\n",
      "    -         eff_perturb other: 0.00000261\n",
      "\n",
      "Epoch: 2: Step: 7996/9802; Global_step=27600; lr=1.907e-06; train time per batch = 0.73\n",
      "Train: global step = 27604; step = 8000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9067\n",
      "    -                  end loss: 3.9055\n",
      "    -                 span loss: 7.8122\n",
      "    -              passage loss: 1.9068\n",
      "    -         history_span loss: 8.6493\n",
      "    -      history_passage loss: 1.9628\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0086\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.4460\n",
      "    -             emb_val other: 0.42908332\n",
      "    -         eff_perturb other: 0.00000268\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.16098.27653\n",
      "Epoch: 2: Step: 8096/9802; Global_step=27700; lr=1.802e-06; train time per batch = 0.73\n",
      "Train: global step = 27704; step = 8100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9049\n",
      "    -                  end loss: 3.9059\n",
      "    -                 span loss: 7.8108\n",
      "    -              passage loss: 1.9691\n",
      "    -         history_span loss: 8.7734\n",
      "    -      history_passage loss: 2.0179\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.6857\n",
      "    -             emb_val other: 0.42846331\n",
      "    -         eff_perturb other: 0.00000250\n",
      "\n",
      "Epoch: 2: Step: 8196/9802; Global_step=27800; lr=1.696e-06; train time per batch = 0.73\n",
      "Train: global step = 27804; step = 8200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9178\n",
      "    -                  end loss: 3.8933\n",
      "    -                 span loss: 7.8111\n",
      "    -              passage loss: 1.9157\n",
      "    -         history_span loss: 8.8703\n",
      "    -      history_passage loss: 1.9484\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0069\n",
      "    -                total loss: 20.6539\n",
      "    -             emb_val other: 0.42892608\n",
      "    -         eff_perturb other: 0.00000304\n",
      "\n",
      "Epoch: 2: Step: 8296/9802; Global_step=27900; lr=1.591e-06; train time per batch = 0.73\n",
      "Train: global step = 27904; step = 8300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9133\n",
      "    -                  end loss: 3.9061\n",
      "    -                 span loss: 7.8194\n",
      "    -              passage loss: 1.9235\n",
      "    -         history_span loss: 8.8546\n",
      "    -      history_passage loss: 1.9539\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.6623\n",
      "    -             emb_val other: 0.42820829\n",
      "    -         eff_perturb other: 0.00000266\n",
      "\n",
      "Epoch: 2: Step: 8396/9802; Global_step=28000; lr=1.485e-06; train time per batch = 0.73\n",
      "Validation: Epoch: 2 Step: 8396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.16794.28001\n",
      "Train: global step = 28004; step = 8400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9149\n",
      "    -                  end loss: 3.9248\n",
      "    -                 span loss: 7.8397\n",
      "    -              passage loss: 1.9413\n",
      "    -         history_span loss: 8.8789\n",
      "    -      history_passage loss: 1.9734\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0078\n",
      "    -                total loss: 20.7471\n",
      "    -             emb_val other: 0.42778704\n",
      "    -         eff_perturb other: 0.00000249\n",
      "\n",
      "Epoch: 2: Step: 8496/9802; Global_step=28100; lr=1.379e-06; train time per batch = 0.73\n",
      "Train: global step = 28104; step = 8500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9036\n",
      "    -                  end loss: 3.9065\n",
      "    -                 span loss: 7.8101\n",
      "    -              passage loss: 1.9648\n",
      "    -         history_span loss: 8.7420\n",
      "    -      history_passage loss: 1.9938\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0085\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6264\n",
      "    -             emb_val other: 0.42921981\n",
      "    -         eff_perturb other: 0.00000257\n",
      "\n",
      "Epoch: 2: Step: 8596/9802; Global_step=28200; lr=1.274e-06; train time per batch = 0.73\n",
      "Train: global step = 28204; step = 8600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9175\n",
      "    -                  end loss: 3.9041\n",
      "    -                 span loss: 7.8216\n",
      "    -              passage loss: 1.9518\n",
      "    -         history_span loss: 8.7538\n",
      "    -      history_passage loss: 1.9977\n",
      "    -            adv_start loss: 0.0072\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.6416\n",
      "    -             emb_val other: 0.42702559\n",
      "    -         eff_perturb other: 0.00000265\n",
      "\n",
      "Epoch: 2: Step: 8696/9802; Global_step=28300; lr=1.168e-06; train time per batch = 0.73\n",
      "Train: global step = 28304; step = 8700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9157\n",
      "    -                  end loss: 3.9046\n",
      "    -                 span loss: 7.8203\n",
      "    -              passage loss: 1.9263\n",
      "    -         history_span loss: 8.7598\n",
      "    -      history_passage loss: 1.9859\n",
      "    -            adv_start loss: 0.0071\n",
      "    -              adv_end loss: 0.0079\n",
      "    -        adv_relevance loss: 0.0080\n",
      "    -                total loss: 20.6072\n",
      "    -             emb_val other: 0.42785120\n",
      "    -         eff_perturb other: 0.00000280\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.17568.28388\n",
      "Epoch: 2: Step: 8796/9802; Global_step=28400; lr=1.062e-06; train time per batch = 0.73\n",
      "Train: global step = 28404; step = 8800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9143\n",
      "    -                  end loss: 3.9143\n",
      "    -                 span loss: 7.8286\n",
      "    -              passage loss: 1.9235\n",
      "    -         history_span loss: 8.5988\n",
      "    -      history_passage loss: 1.9782\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.4430\n",
      "    -             emb_val other: 0.42834127\n",
      "    -         eff_perturb other: 0.00000273\n",
      "\n",
      "Epoch: 2: Step: 8896/9802; Global_step=28500; lr=9.568e-07; train time per batch = 0.73\n",
      "Train: global step = 28504; step = 8900\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9132\n",
      "    -                  end loss: 3.9146\n",
      "    -                 span loss: 7.8278\n",
      "    -              passage loss: 1.9043\n",
      "    -         history_span loss: 8.7442\n",
      "    -      history_passage loss: 1.9721\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5613\n",
      "    -             emb_val other: 0.42817351\n",
      "    -         eff_perturb other: 0.00000253\n",
      "\n",
      "Epoch: 2: Step: 8996/9802; Global_step=28600; lr=8.512e-07; train time per batch = 0.73\n",
      "Train: global step = 28604; step = 9000\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9108\n",
      "    -                  end loss: 3.9042\n",
      "    -                 span loss: 7.8150\n",
      "    -              passage loss: 1.9533\n",
      "    -         history_span loss: 8.7999\n",
      "    -      history_passage loss: 2.0078\n",
      "    -            adv_start loss: 0.0066\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0071\n",
      "    -                total loss: 20.6859\n",
      "    -             emb_val other: 0.42584887\n",
      "    -         eff_perturb other: 0.00000246\n",
      "\n",
      "Epoch: 2: Step: 9096/9802; Global_step=28700; lr=7.456e-07; train time per batch = 0.73\n",
      "Train: global step = 28704; step = 9100\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9168\n",
      "    -                  end loss: 3.9028\n",
      "    -                 span loss: 7.8196\n",
      "    -              passage loss: 1.9359\n",
      "    -         history_span loss: 8.8717\n",
      "    -      history_passage loss: 1.9872\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0084\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.7321\n",
      "    -             emb_val other: 0.42812502\n",
      "    -         eff_perturb other: 0.00000288\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.18336.28772\n",
      "Epoch: 2: Step: 9196/9802; Global_step=28800; lr=6.400e-07; train time per batch = 0.73\n",
      "Train: global step = 28804; step = 9200\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9175\n",
      "    -                  end loss: 3.9011\n",
      "    -                 span loss: 7.8186\n",
      "    -              passage loss: 1.9458\n",
      "    -         history_span loss: 8.6904\n",
      "    -      history_passage loss: 1.9839\n",
      "    -            adv_start loss: 0.0070\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0072\n",
      "    -                total loss: 20.5501\n",
      "    -             emb_val other: 0.42894936\n",
      "    -         eff_perturb other: 0.00000264\n",
      "\n",
      "Epoch: 2: Step: 9296/9802; Global_step=28900; lr=5.344e-07; train time per batch = 0.73\n",
      "Train: global step = 28904; step = 9300\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9114\n",
      "    -                  end loss: 3.9021\n",
      "    -                 span loss: 7.8135\n",
      "    -              passage loss: 1.9206\n",
      "    -         history_span loss: 8.6971\n",
      "    -      history_passage loss: 1.9654\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0075\n",
      "    -                total loss: 20.5086\n",
      "    -             emb_val other: 0.42777193\n",
      "    -         eff_perturb other: 0.00000259\n",
      "\n",
      "Epoch: 2: Step: 9396/9802; Global_step=29000; lr=4.288e-07; train time per batch = 0.73\n",
      "Validation: Epoch: 2 Step: 9396/9802\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.09\n",
      "Eval step 200 / 993; eval time per batch = 0.10\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.11\n",
      "Eval step 500 / 993; eval time per batch = 0.10\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.09\n",
      "Eval step 800 / 993; eval time per batch = 0.09\n",
      "Eval step 900 / 993; eval time per batch = 0.09\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Curr EM 1.36\n",
      "Curr F1 12.90\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n",
      "Train: global step = 29004; step = 9400\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9236\n",
      "    -                  end loss: 3.9069\n",
      "    -                 span loss: 7.8306\n",
      "    -              passage loss: 1.9506\n",
      "    -         history_span loss: 8.6511\n",
      "    -      history_passage loss: 1.9772\n",
      "    -            adv_start loss: 0.0073\n",
      "    -              adv_end loss: 0.0083\n",
      "    -        adv_relevance loss: 0.0077\n",
      "    -                total loss: 20.5260\n",
      "    -             emb_val other: 0.42867634\n",
      "    -         eff_perturb other: 0.00000267\n",
      "\n",
      "Epoch: 2: Step: 9496/9802; Global_step=29100; lr=3.232e-07; train time per batch = 0.73\n",
      "Train: global step = 29104; step = 9500\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9178\n",
      "    -                  end loss: 3.9085\n",
      "    -                 span loss: 7.8263\n",
      "    -              passage loss: 1.9301\n",
      "    -         history_span loss: 8.8499\n",
      "    -      history_passage loss: 1.9757\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0082\n",
      "    -        adv_relevance loss: 0.0081\n",
      "    -                total loss: 20.6971\n",
      "    -             emb_val other: 0.42743200\n",
      "    -         eff_perturb other: 0.00000283\n",
      "\n",
      "Save checkpoint every 15 minutes.\n",
      "Saved checkpoint to ./dialdoc/exp/dialki.2.19030.29119\n",
      "Epoch: 2: Step: 9596/9802; Global_step=29200; lr=2.176e-07; train time per batch = 0.73\n",
      "Train: global step = 29204; step = 9600\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9158\n",
      "    -                  end loss: 3.9178\n",
      "    -                 span loss: 7.8335\n",
      "    -              passage loss: 1.9657\n",
      "    -         history_span loss: 8.9878\n",
      "    -      history_passage loss: 2.0117\n",
      "    -            adv_start loss: 0.0074\n",
      "    -              adv_end loss: 0.0090\n",
      "    -        adv_relevance loss: 0.0079\n",
      "    -                total loss: 20.9200\n",
      "    -             emb_val other: 0.42884651\n",
      "    -         eff_perturb other: 0.00000252\n",
      "\n",
      "Epoch: 2: Step: 9696/9802; Global_step=29300; lr=1.119e-07; train time per batch = 0.73\n",
      "Train: global step = 29304; step = 9700\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9282\n",
      "    -                  end loss: 3.9002\n",
      "    -                 span loss: 7.8284\n",
      "    -              passage loss: 1.9031\n",
      "    -         history_span loss: 8.7505\n",
      "    -      history_passage loss: 1.9522\n",
      "    -            adv_start loss: 0.0069\n",
      "    -              adv_end loss: 0.0078\n",
      "    -        adv_relevance loss: 0.0076\n",
      "    -                total loss: 20.5457\n",
      "    -             emb_val other: 0.42867884\n",
      "    -         eff_perturb other: 0.00000286\n",
      "\n",
      "Epoch: 2: Step: 9796/9802; Global_step=29400; lr=6.337e-09; train time per batch = 0.73\n",
      "Train: global step = 29404; step = 9800\n",
      "Avg. loss and other in the recent 100 batches: \n",
      "    -                start loss: 3.9067\n",
      "    -                  end loss: 3.8820\n",
      "    -                 span loss: 7.7887\n",
      "    -              passage loss: 1.9234\n",
      "    -         history_span loss: 8.8260\n",
      "    -      history_passage loss: 1.9570\n",
      "    -            adv_start loss: 0.0067\n",
      "    -              adv_end loss: 0.0081\n",
      "    -        adv_relevance loss: 0.0073\n",
      "    -                total loss: 20.6059\n",
      "    -             emb_val other: 0.42726508\n",
      "    -         eff_perturb other: 0.00000272\n",
      "\n",
      "Avg. total Loss of epoch 2 =20.603\n",
      "================================================================================\n",
      "                               Training finished.\n",
      "================================================================================\n",
      "Best EM 1.36 path = dialki.0.10000.5000\n",
      "Best F1 12.90 path = dialki.0.10000.5000\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/train.sh dialdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75cac0",
   "metadata": {},
   "source": [
    "Lakukan inference pada baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa02c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized host wawatlocal_rank = -1 device = device(type='cuda') n_gpu = 1 word_size = 116-bits training: True\n",
      "================================================================================\n",
      "                 ****************CONFIGURATION****************\n",
      "================================================================================\n",
      "adam_betas                     -->   (0.9, 0.999)\n",
      "adam_eps                       -->   1e-08\n",
      "adv_calc_logits_keys           -->   ['start', 'end', 'relevance']\n",
      "adv_epsilon                    -->   1e-06\n",
      "adv_k                          -->   1\n",
      "adv_loss_type                  -->   js\n",
      "adv_loss_weight                -->   5.0\n",
      "adv_noise_var                  -->   1e-05\n",
      "adv_norm_level                 -->   0\n",
      "adv_norm_p                     -->   inf\n",
      "adv_step_size                  -->   1e-05\n",
      "auto_resume                    -->   False\n",
      "batch_size                     -->   2\n",
      "best_metric                    -->   None\n",
      "checkpoint_file                -->   dialdoc/exp-finalbert/dialki.2.19030.29119\n",
      "checkpoint_filename_prefix     -->   dialki\n",
      "compute_da_loss                -->   False\n",
      "coordinator_heads              -->   3\n",
      "coordinator_layers             -->   1\n",
      "data_name                      -->   dialdoc\n",
      "decision_function              -->   1\n",
      "dev_batch_size                 -->   4\n",
      "dev_file                       -->   ./dialdoc/cache/cls_bert/dev\n",
      "device                         -->   cuda\n",
      "distributed_world_size         -->   1\n",
      "do_lower_case                  -->   True\n",
      "dropout                        -->   0.1\n",
      "eval_step                      -->   1000\n",
      "eval_top_docs                  -->   [20]\n",
      "fp16                           -->   True\n",
      "fp16_opt_level                 -->   O2\n",
      "gradient_accumulation_steps    -->   1\n",
      "hist_loss_weight               -->   1.0\n",
      "ignore_token_type              -->   True\n",
      "inference_only                 -->   False\n",
      "learning_rate                  -->   3e-05\n",
      "local_rank                     -->   -1\n",
      "log_batch_step                 -->   100\n",
      "marker_after_steps             -->   0\n",
      "max_answer_length              -->   5\n",
      "max_grad_norm                  -->   1.0\n",
      "max_num_answers                -->   2\n",
      "max_seq_len                    -->   512\n",
      "n_gpu                          -->   1\n",
      "num_token_types                -->   10\n",
      "num_train_epochs               -->   20.0\n",
      "output_dir                     -->   ./dialdoc/exp\n",
      "passage_attend_history         -->   False\n",
      "passages_per_question          -->   8\n",
      "passages_per_question_predict  -->   20\n",
      "prediction_results_file        -->   dialdoc/inference_bert\n",
      "pretrained_model_cfg           -->   ./dialdoc/pretrained_models/bert-base-uncased\n",
      "projection_dim                 -->   0\n",
      "save_checkpoint_every_minutes  -->   15\n",
      "seed                           -->   42\n",
      "skip_mark_last_user            -->   False\n",
      "span_marker                    -->   False\n",
      "special_attention              -->   False\n",
      "topk_em                        -->   2\n",
      "topk_f1                        -->   2\n",
      "train_file                     -->   None\n",
      "train_rolling_loss_step        -->   100\n",
      "use_coordinator                -->   False\n",
      "use_z_attn                     -->   True\n",
      "user2agent_loss_weight         -->   0\n",
      "warmup_steps                   -->   1000\n",
      "weight_decay                   -->   0.0\n",
      "================================================================================\n",
      "                      Initializing components for training\n",
      "================================================================================\n",
      "================================================================================\n",
      "                            Restore from checkpoint\n",
      "================================================================================\n",
      "Checkpoint files dialdoc/exp-finalbert/dialki.2.19030.29119\n",
      "Reading saved model from dialdoc/exp-finalbert/dialki.2.19030.29119\n",
      "model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'amp_dict', 'offset', 'epoch', 'global_step', 'encoder_params'])\n",
      "Overriding args parameter value from checkpoint state. param = 'do_lower_case', value = True\n",
      "Overriding args parameter value from checkpoint state. param = 'max_seq_len', value = 512\n",
      "Resize embedding from 30522 to 30526\n",
      "Use apex opt level = O2\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Loading checkpoint @epoch = 2, offset = 19030, global_step = 29119, \n",
      "Loading model weights from saved state ...\n",
      "No train files are specified. Run validation.\n",
      "Validation ...\n",
      "Data dir: ./dialdoc/cache/cls_bert/dev\n",
      "Data paths: ['./dialdoc/cache/cls_bert/dev/2.pkl', './dialdoc/cache/cls_bert/dev/0.pkl', './dialdoc/cache/cls_bert/dev/1.pkl', './dialdoc/cache/cls_bert/dev/3.pkl']\n",
      "Total data size: 3972\n",
      "Eval step 100 / 993; eval time per batch = 0.10\n",
      "Eval step 200 / 993; eval time per batch = 0.11\n",
      "Eval step 300 / 993; eval time per batch = 0.11\n",
      "Eval step 400 / 993; eval time per batch = 0.12\n",
      "Eval step 500 / 993; eval time per batch = 0.11\n",
      "Eval step 600 / 993; eval time per batch = 0.10\n",
      "Eval step 700 / 993; eval time per batch = 0.10\n",
      "Eval step 800 / 993; eval time per batch = 0.10\n",
      "Eval step 900 / 993; eval time per batch = 0.10\n",
      "eval_top_docs = 20\n",
      "F1 = 12.90\n",
      "Passage@1 = 11.61; Passage@2 = 26.09; Passage@3 = 36.96; \n",
      "Rank 1 passage: EM@1 = 1.36; EM@2 = 2.59; EM@3 = 3.52; \n",
      "Rank 2 passage: EM@1 = 1.28; EM@2 = 2.39; EM@3 = 3.78; \n",
      "Rank 3 passage: EM@1 = 1.18; EM@2 = 2.29; EM@3 = 3.17; \n",
      "\n",
      "Saving prediction results to  dialdoc/inference_bert\n"
     ]
    }
   ],
   "source": [
    "!bash run_eval.sh 'dialdoc dialdoc/exp-finalbert/dialki.2.19030.29119' 'dialdoc/inference_bert'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bee23",
   "metadata": {},
   "source": [
    "Hasil menunjukkan baseline (DIALKI) memiliki Exact Match = 1,36 dan F1 Score = 12,90. Nilai ini lebih kecil dibandingkan sistem usulan yang memiliki nilai Exact Match = 1,64 dan F1 score = 14,27."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dialki",
   "language": "python",
   "name": "dialki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
